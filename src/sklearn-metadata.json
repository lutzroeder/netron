[
  {
    "name": "Binarizer",
    "schema": {
      "attributes": [
        {
          "default": true,
          "description": "set to False to perform inplace binarization and avoid a copy (if\nthe input is already a numpy array or a scipy.sparse CSR matrix).\n",
          "name": "copy",
          "option": "optional",
          "type": "boolean"
        },
        {
          "default": 0.0,
          "description": "Feature values below or equal to this are replaced by 0, above it by 1.\nThreshold may not be less than 0 for operations on sparse matrices.\n",
          "name": "threshold",
          "option": "optional",
          "type": "float32"
        }
      ],
      "description": "Binarize data (set feature values to 0 or 1) according to a threshold\n\nValues greater than the threshold map to 1, while values less than\nor equal to the threshold map to 0. With the default threshold of 0,\nonly positive values map to 1.\n\nBinarization is a common operation on text count data where the\nanalyst can decide to only consider the presence or absence of a\nfeature rather than a quantified number of occurrences for instance.\n\nIt can also be used as a pre-processing step for estimators that\nconsider boolean random variables (e.g. modelled using the Bernoulli\ndistribution in a Bayesian setting).\n\nRead more in the :ref:`User Guide <preprocessing_binarization>`.\n",
      "package": "sklearn.preprocessing"
    }
  },
  {
    "name": "MultiLabelBinarizer",
    "schema": {
      "attributes": [
        {
          "description": "Indicates an ordering for the class labels.\nAll entries should be unique (cannot contain duplicate classes).\n",
          "name": "classes",
          "option": "optional"
        },
        {
          "description": "Set to true if output binary array is desired in CSR sparse format\n",
          "name": "sparse_output"
        }
      ],
      "description": "Transform between iterable of iterables and a multilabel format\n\nAlthough a list of sets or tuples is a very intuitive format for multilabel\ndata, it is unwieldy to process. This transformer converts between this\nintuitive format and the supported multilabel format: a (samples x classes)\nbinary matrix indicating the presence of a class label.\n",
      "package": "sklearn.preprocessing"
    }
  },
  {
    "name": "LabelEncoder",
    "schema": {
      "description": "Encode target labels with value between 0 and n_classes-1.\n\nThis transformer should be used to encode target values, *i.e.* `y`, and\nnot the input `X`.\n\nRead more in the :ref:`User Guide <preprocessing_targets>`.\n\n.. versionadded:: 0.12\n",
      "package": "sklearn.preprocessing"
    }
  },
  {
    "name": "SVC",
    "schema": {
      "attributes": [
        {
          "default": 1.0,
          "description": "Regularization parameter. The strength of the regularization is\ninversely proportional to C. Must be strictly positive. The penalty\nis a squared l2 penalty.\n",
          "name": "C",
          "option": "optional",
          "type": "float32"
        },
        {
          "default": "rbf",
          "description": "Specifies the kernel type to be used in the algorithm.\nIt must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\na callable.\nIf none is given, 'rbf' will be used. If a callable is given it is\nused to pre-compute the kernel matrix from data matrices; that matrix\nshould be an array of shape ``(n_samples, n_samples)``.\n",
          "name": "kernel",
          "option": "optional",
          "type": "string"
        },
        {
          "default": 3,
          "description": "Degree of the polynomial kernel function ('poly').\nIgnored by all other kernels.\n",
          "name": "degree",
          "option": "optional",
          "type": "int32"
        },
        {
          "default": "auto",
          "description": "Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n\n- if ``gamma='scale'`` (default) is passed then it uses\n1 / (n_features * X.var()) as value of gamma,\n- if 'auto', uses 1 / n_features.\n\n.. versionchanged:: 0.22\nThe default value of ``gamma`` changed from 'auto' to 'scale'.\n",
          "name": "gamma",
          "option": "optional",
          "type": "float32"
        },
        {
          "default": 0.0,
          "description": "Independent term in kernel function.\nIt is only significant in 'poly' and 'sigmoid'.\n",
          "name": "coef0",
          "option": "optional",
          "type": "float32"
        },
        {
          "default": false,
          "description": "Whether to enable probability estimates. This must be enabled prior\nto calling `fit`, will slow down that method as it internally uses\n5-fold cross-validation, and `predict_proba` may be inconsistent with\n`predict`. Read more in the :ref:`User Guide <scores_probabilities>`.\n",
          "name": "probability",
          "option": "optional",
          "type": "boolean"
        },
        {
          "default": true,
          "description": "Whether to use the shrinking heuristic.\n",
          "name": "shrinking",
          "option": "optional",
          "type": "boolean"
        },
        {
          "default": 0.001,
          "description": "Tolerance for stopping criterion.\n",
          "name": "tol",
          "option": "optional",
          "type": "float32"
        },
        {
          "default": 200.0,
          "description": "Specify the size of the kernel cache (in MB).\n",
          "name": "cache_size",
          "option": "optional",
          "type": "float32"
        },
        {
          "default": null,
          "description": "Set the parameter C of class i to class_weight[i]*C for\nSVC. If not given, all classes are supposed to have\nweight one.\nThe \"balanced\" mode uses the values of y to automatically adjust\nweights inversely proportional to class frequencies in the input data\nas ``n_samples / (n_classes * np.bincount(y))``\n",
          "name": "class_weight",
          "option": "optional"
        },
        {
          "default": false,
          "description": "Enable verbose output. Note that this setting takes advantage of a\nper-process runtime setting in libsvm that, if enabled, may not work\nproperly in a multithreaded context.\n",
          "name": "verbose",
          "type": "boolean"
        },
        {
          "default": -1,
          "description": "Hard limit on iterations within solver, or -1 for no limit.\n",
          "name": "max_iter",
          "option": "optional",
          "type": "int32"
        },
        {
          "default": "ovr",
          "description": "Whether to return a one-vs-rest ('ovr') decision function of shape\n(n_samples, n_classes) as all other classifiers, or the original\none-vs-one ('ovo') decision function of libsvm which has shape\n(n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one\n('ovo') is always used as multi-class strategy.\n\n.. versionchanged:: 0.19\ndecision_function_shape is 'ovr' by default.\n\n.. versionadded:: 0.17\n*decision_function_shape='ovr'* is recommended.\n\n.. versionchanged:: 0.17\nDeprecated *decision_function_shape='ovo' and None*.\n",
          "name": "decision_function_shape"
        },
        {
          "default": null,
          "description": "The seed of the pseudo random number generator used when shuffling\nthe data for probability estimates. If int, random_state is the\nseed used by the random number generator; If RandomState instance,\nrandom_state is the random number generator; If None, the random\nnumber generator is the RandomState instance used by `np.random`.\n",
          "name": "random_state",
          "option": "optional",
          "type": "int32"
        },
        {
          "default": false,
          "description": "If true, ``decision_function_shape='ovr'``, and number of classes > 2,\n:term:`predict` will break ties according to the confidence values of\n:term:`decision_function`; otherwise the first class among the tied\nclasses is returned. Please note that breaking ties comes at a\nrelatively high computational cost compared to a simple predict.\n\n.. versionadded:: 0.22\n",
          "name": "break_ties",
          "option": "optional",
          "type": "boolean"
        }
      ],
      "description": "C-Support Vector Classification.\n\nThe implementation is based on libsvm. The fit time scales at least\nquadratically with the number of samples and may be impractical\nbeyond tens of thousands of samples. For large datasets\nconsider using :class:`sklearn.svm.LinearSVC` or\n:class:`sklearn.linear_model.SGDClassifier` instead, possibly after a\n:class:`sklearn.kernel_approximation.Nystroem` transformer.\n\nThe multiclass support is handled according to a one-vs-one scheme.\n\nFor details on the precise mathematical formulation of the provided\nkernel functions and how `gamma`, `coef0` and `degree` affect each\nother, see the corresponding section in the narrative documentation:\n:ref:`svm_kernels`.\n\nRead more in the :ref:`User Guide <svm_classification>`.\n",
      "package": "sklearn.svm"
    }
  },
  {
    "name": "SVC",
    "schema": {
      "attributes": [
        {
          "default": 1.0,
          "description": "Regularization parameter. The strength of the regularization is\ninversely proportional to C. Must be strictly positive. The penalty\nis a squared l2 penalty.\n",
          "name": "C",
          "option": "optional",
          "type": "float32"
        },
        {
          "default": "rbf",
          "description": "Specifies the kernel type to be used in the algorithm.\nIt must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\na callable.\nIf none is given, 'rbf' will be used. If a callable is given it is\nused to pre-compute the kernel matrix from data matrices; that matrix\nshould be an array of shape ``(n_samples, n_samples)``.\n",
          "name": "kernel",
          "option": "optional",
          "type": "string"
        },
        {
          "default": 3,
          "description": "Degree of the polynomial kernel function ('poly').\nIgnored by all other kernels.\n",
          "name": "degree",
          "option": "optional",
          "type": "int32"
        },
        {
          "default": "auto",
          "description": "Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n\n- if ``gamma='scale'`` (default) is passed then it uses\n1 / (n_features * X.var()) as value of gamma,\n- if 'auto', uses 1 / n_features.\n\n.. versionchanged:: 0.22\nThe default value of ``gamma`` changed from 'auto' to 'scale'.\n",
          "name": "gamma",
          "option": "optional",
          "type": "float32"
        },
        {
          "default": 0.0,
          "description": "Independent term in kernel function.\nIt is only significant in 'poly' and 'sigmoid'.\n",
          "name": "coef0",
          "option": "optional",
          "type": "float32"
        },
        {
          "default": true,
          "description": "Whether to use the shrinking heuristic.\n",
          "name": "shrinking",
          "option": "optional",
          "type": "boolean"
        },
        {
          "default": false,
          "description": "Whether to enable probability estimates. This must be enabled prior\nto calling `fit`, will slow down that method as it internally uses\n5-fold cross-validation, and `predict_proba` may be inconsistent with\n`predict`. Read more in the :ref:`User Guide <scores_probabilities>`.\n",
          "name": "probability",
          "option": "optional",
          "type": "boolean"
        },
        {
          "default": 0.001,
          "description": "Tolerance for stopping criterion.\n",
          "name": "tol",
          "option": "optional",
          "type": "float32"
        },
        {
          "default": 200.0,
          "description": "Specify the size of the kernel cache (in MB).\n",
          "name": "cache_size",
          "option": "optional",
          "type": "float32"
        },
        {
          "default": null,
          "description": "Set the parameter C of class i to class_weight[i]*C for\nSVC. If not given, all classes are supposed to have\nweight one.\nThe \"balanced\" mode uses the values of y to automatically adjust\nweights inversely proportional to class frequencies in the input data\nas ``n_samples / (n_classes * np.bincount(y))``\n",
          "name": "class_weight",
          "option": "optional"
        },
        {
          "default": false,
          "description": "Enable verbose output. Note that this setting takes advantage of a\nper-process runtime setting in libsvm that, if enabled, may not work\nproperly in a multithreaded context.\n",
          "name": "verbose",
          "type": "boolean"
        },
        {
          "default": -1,
          "description": "Hard limit on iterations within solver, or -1 for no limit.\n",
          "name": "max_iter",
          "option": "optional",
          "type": "int32"
        },
        {
          "default": "ovr",
          "description": "Whether to return a one-vs-rest ('ovr') decision function of shape\n(n_samples, n_classes) as all other classifiers, or the original\none-vs-one ('ovo') decision function of libsvm which has shape\n(n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one\n('ovo') is always used as multi-class strategy.\n\n.. versionchanged:: 0.19\ndecision_function_shape is 'ovr' by default.\n\n.. versionadded:: 0.17\n*decision_function_shape='ovr'* is recommended.\n\n.. versionchanged:: 0.17\nDeprecated *decision_function_shape='ovo' and None*.\n",
          "name": "decision_function_shape"
        },
        {
          "default": null,
          "description": "The seed of the pseudo random number generator used when shuffling\nthe data for probability estimates. If int, random_state is the\nseed used by the random number generator; If RandomState instance,\nrandom_state is the random number generator; If None, the random\nnumber generator is the RandomState instance used by `np.random`.\n",
          "name": "random_state",
          "option": "optional"
        },
        {
          "default": false,
          "description": "If true, ``decision_function_shape='ovr'``, and number of classes > 2,\n:term:`predict` will break ties according to the confidence values of\n:term:`decision_function`; otherwise the first class among the tied\nclasses is returned. Please note that breaking ties comes at a\nrelatively high computational cost compared to a simple predict.\n\n.. versionadded:: 0.22\n",
          "name": "break_ties",
          "option": "optional",
          "type": "boolean"
        }
      ],
      "description": "C-Support Vector Classification.\n\nThe implementation is based on libsvm. The fit time scales at least\nquadratically with the number of samples and may be impractical\nbeyond tens of thousands of samples. For large datasets\nconsider using :class:`sklearn.svm.LinearSVC` or\n:class:`sklearn.linear_model.SGDClassifier` instead, possibly after a\n:class:`sklearn.kernel_approximation.Nystroem` transformer.\n\nThe multiclass support is handled according to a one-vs-one scheme.\n\nFor details on the precise mathematical formulation of the provided\nkernel functions and how `gamma`, `coef0` and `degree` affect each\nother, see the corresponding section in the narrative documentation:\n:ref:`svm_kernels`.\n\nRead more in the :ref:`User Guide <svm_classification>`.\n",
      "package": "sklearn.svm"
    }
  },
  {
    "name": "LogisticRegression",
    "schema": {
      "attributes": [
        {
          "default": "l2",
          "description": "Used to specify the norm used in the penalization. The 'newton-cg',\n'sag' and 'lbfgs' solvers support only l2 penalties. 'elasticnet' is\nonly supported by the 'saga' solver. If 'none' (not supported by the\nliblinear solver), no regularization is applied.\n\n.. versionadded:: 0.19\nl1 penalty with SAGA solver (allowing 'multinomial' + L1)\n",
          "name": "penalty",
          "option": "optional"
        },
        {
          "default": false,
          "description": "Dual or primal formulation. Dual formulation is only implemented for\nl2 penalty with liblinear solver. Prefer dual=False when\nn_samples > n_features.\n",
          "name": "dual",
          "option": "optional",
          "type": "boolean"
        },
        {
          "default": 0.0001,
          "description": "Tolerance for stopping criteria.\n",
          "name": "tol",
          "option": "optional",
          "type": "float32"
        },
        {
          "default": 1.0,
          "description": "Inverse of regularization strength; must be a positive float.\nLike in support vector machines, smaller values specify stronger\nregularization.\n",
          "name": "C",
          "option": "optional",
          "type": "float32"
        },
        {
          "default": true,
          "description": "Specifies if a constant (a.k.a. bias or intercept) should be\nadded to the decision function.\n",
          "name": "fit_intercept",
          "option": "optional",
          "type": "boolean"
        },
        {
          "default": 1.0,
          "description": "Useful only when the solver 'liblinear' is used\nand self.fit_intercept is set to True. In this case, x becomes\n[x, self.intercept_scaling],\ni.e. a \"synthetic\" feature with constant value equal to\nintercept_scaling is appended to the instance vector.\nThe intercept becomes ``intercept_scaling * synthetic_feature_weight``.\n\nNote! the synthetic feature weight is subject to l1/l2 regularization\nas all other features.\nTo lessen the effect of regularization on synthetic feature weight\n(and therefore on the intercept) intercept_scaling has to be increased.\n",
          "name": "intercept_scaling",
          "option": "optional",
          "type": "float32"
        },
        {
          "default": null,
          "description": "Weights associated with classes in the form ``{class_label: weight}``.\nIf not given, all classes are supposed to have weight one.\n\nThe \"balanced\" mode uses the values of y to automatically adjust\nweights inversely proportional to class frequencies in the input data\nas ``n_samples / (n_classes * np.bincount(y))``.\n\nNote that these weights will be multiplied with sample_weight (passed\nthrough the fit method) if sample_weight is specified.\n\n.. versionadded:: 0.17\n*class_weight='balanced'*\n",
          "name": "class_weight",
          "option": "optional"
        },
        {
          "default": null,
          "description": "The seed of the pseudo random number generator to use when shuffling\nthe data.  If int, random_state is the seed used by the random number\ngenerator; If RandomState instance, random_state is the random number\ngenerator; If None, the random number generator is the RandomState\ninstance used by `np.random`. Used when ``solver`` == 'sag' or\n'liblinear'.\n",
          "name": "random_state",
          "option": "optional",
          "type": "int32"
        },
        {
          "default": "lbfgs",
          "description": "\nAlgorithm to use in the optimization problem.\n\n- For small datasets, 'liblinear' is a good choice, whereas 'sag' and\n'saga' are faster for large ones.\n- For multiclass problems, only 'newton-cg', 'sag', 'saga' and 'lbfgs'\nhandle multinomial loss; 'liblinear' is limited to one-versus-rest\nschemes.\n- 'newton-cg', 'lbfgs', 'sag' and 'saga' handle L2 or no penalty\n- 'liblinear' and 'saga' also handle L1 penalty\n- 'saga' also supports 'elasticnet' penalty\n- 'liblinear' does not support setting ``penalty='none'``\n\nNote that 'sag' and 'saga' fast convergence is only guaranteed on\nfeatures with approximately the same scale. You can\npreprocess the data with a scaler from sklearn.preprocessing.\n\n.. versionadded:: 0.17\nStochastic Average Gradient descent solver.\n.. versionadded:: 0.19\nSAGA solver.\n.. versionchanged:: 0.22\nThe default solver changed from 'liblinear' to 'lbfgs' in 0.22.\n",
          "name": "solver",
          "option": "optional"
        },
        {
          "default": 100,
          "description": "Maximum number of iterations taken for the solvers to converge.\n",
          "name": "max_iter",
          "option": "optional",
          "type": "int32"
        },
        {
          "default": "auto",
          "description": "If the option chosen is 'ovr', then a binary problem is fit for each\nlabel. For 'multinomial' the loss minimised is the multinomial loss fit\nacross the entire probability distribution, *even when the data is\nbinary*. 'multinomial' is unavailable when solver='liblinear'.\n'auto' selects 'ovr' if the data is binary, or if solver='liblinear',\nand otherwise selects 'multinomial'.\n\n.. versionadded:: 0.18\nStochastic Average Gradient descent solver for 'multinomial' case.\n.. versionchanged:: 0.22\nDefault changed from 'ovr' to 'auto' in 0.22.\n",
          "name": "multi_class",
          "option": "optional"
        },
        {
          "default": 0,
          "description": "For the liblinear and lbfgs solvers set verbose to any positive\nnumber for verbosity.\n",
          "name": "verbose",
          "option": "optional",
          "type": "int32"
        },
        {
          "default": false,
          "description": "When set to True, reuse the solution of the previous call to fit as\ninitialization, otherwise, just erase the previous solution.\nUseless for liblinear solver. See :term:`the Glossary <warm_start>`.\n\n.. versionadded:: 0.17\n*warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.\n",
          "name": "warm_start",
          "option": "optional",
          "type": "boolean"
        },
        {
          "default": null,
          "description": "Number of CPU cores used when parallelizing over classes if\nmulti_class='ovr'\". This parameter is ignored when the ``solver`` is\nset to 'liblinear' regardless of whether 'multi_class' is specified or\nnot. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\ncontext. ``-1`` means using all processors.\nSee :term:`Glossary <n_jobs>` for more details.\n",
          "name": "n_jobs",
          "option": "optional",
          "type": "int32"
        },
        {
          "default": null,
          "description": "The Elastic-Net mixing parameter, with ``0 <= l1_ratio <= 1``. Only\nused if ``penalty='elasticnet'`. Setting ``l1_ratio=0`` is equivalent\nto using ``penalty='l2'``, while setting ``l1_ratio=1`` is equivalent\nto using ``penalty='l1'``. For ``0 < l1_ratio <1``, the penalty is a\ncombination of L1 and L2.\n",
          "name": "l1_ratio",
          "option": "optional",
          "type": "float32"
        }
      ],
      "description": "\nLogistic Regression (aka logit, MaxEnt) classifier.\n\nIn the multiclass case, the training algorithm uses the one-vs-rest (OvR)\nscheme if the 'multi_class' option is set to 'ovr', and uses the\ncross-entropy loss if the 'multi_class' option is set to 'multinomial'.\n(Currently the 'multinomial' option is supported only by the 'lbfgs',\n'sag', 'saga' and 'newton-cg' solvers.)\n\nThis class implements regularized logistic regression using the\n'liblinear' library, 'newton-cg', 'sag', 'saga' and 'lbfgs' solvers. **Note\nthat regularization is applied by default**. It can handle both dense\nand sparse input. Use C-ordered arrays or CSR matrices containing 64-bit\nfloats for optimal performance; any other input format will be converted\n(and copied).\n\nThe 'newton-cg', 'sag', and 'lbfgs' solvers support only L2 regularization\nwith primal formulation, or no regularization. The 'liblinear' solver\nsupports both L1 and L2 regularization, with a dual formulation only for\nthe L2 penalty. The Elastic-Net regularization is only supported by the\n'saga' solver.\n\nRead more in the :ref:`User Guide <logistic_regression>`.\n",
      "package": "sklearn.linear_model"
    }
  },
  {
    "name": "BernoulliNB",
    "schema": {
      "attributes": [
        {
          "default": 1.0,
          "description": "Additive (Laplace/Lidstone) smoothing parameter\n(0 for no smoothing).\n",
          "name": "alpha",
          "option": "optional",
          "type": "float32"
        },
        {
          "default": "0.0",
          "description": "Threshold for binarizing (mapping to booleans) of sample features.\nIf None, input is presumed to already consist of binary vectors.\n",
          "name": "binarize",
          "option": "optional"
        },
        {
          "default": true,
          "description": "Whether to learn class prior probabilities or not.\nIf false, a uniform prior will be used.\n",
          "name": "fit_prior",
          "option": "optional",
          "type": "boolean"
        },
        {
          "default": null,
          "description": "Prior probabilities of the classes. If specified the priors are not\nadjusted according to the data.\n",
          "name": "class_prior",
          "option": "optional"
        }
      ],
      "description": "Naive Bayes classifier for multivariate Bernoulli models.\n\nLike MultinomialNB, this classifier is suitable for discrete data. The\ndifference is that while MultinomialNB works with occurrence counts,\nBernoulliNB is designed for binary/boolean features.\n\nRead more in the :ref:`User Guide <bernoulli_naive_bayes>`.\n",
      "package": "sklearn.naive_bayes"
    }
  },
  {
    "name": "ComplementNB",
    "schema": {
      "attributes": [
        {
          "default": 1.0,
          "description": "Additive (Laplace/Lidstone) smoothing parameter (0 for no smoothing).\n",
          "name": "alpha",
          "option": "optional",
          "type": "float32"
        },
        {
          "default": true,
          "description": "Only used in edge case with a single class in the training set.\n",
          "name": "fit_prior",
          "option": "optional",
          "type": "boolean"
        },
        {
          "default": null,
          "description": "Prior probabilities of the classes. Not used.\n",
          "name": "class_prior",
          "option": "optional"
        },
        {
          "default": false,
          "description": "Whether or not a second normalization of the weights is performed. The\ndefault behavior mirrors the implementations found in Mahout and Weka,\nwhich do not follow the full algorithm described in Table 9 of the\npaper.\n",
          "name": "norm",
          "option": "optional",
          "type": "boolean"
        }
      ],
      "description": "The Complement Naive Bayes classifier described in Rennie et al. (2003).\n\nThe Complement Naive Bayes classifier was designed to correct the \"severe\nassumptions\" made by the standard Multinomial Naive Bayes classifier. It is\nparticularly suited for imbalanced data sets.\n\nRead more in the :ref:`User Guide <complement_naive_bayes>`.\n",
      "package": "sklearn.naive_bayes"
    }
  },
  {
    "name": "MultinomialNB",
    "schema": {
      "attributes": [
        {
          "default": 1.0,
          "description": "Additive (Laplace/Lidstone) smoothing parameter\n(0 for no smoothing).\n",
          "name": "alpha",
          "option": "optional",
          "type": "float32"
        },
        {
          "default": true,
          "description": "Whether to learn class prior probabilities or not.\nIf false, a uniform prior will be used.\n",
          "name": "fit_prior",
          "option": "optional",
          "type": "boolean"
        },
        {
          "default": null,
          "description": "Prior probabilities of the classes. If specified the priors are not\nadjusted according to the data.\n",
          "name": "class_prior",
          "option": "optional"
        }
      ],
      "description": "\nNaive Bayes classifier for multinomial models\n\nThe multinomial Naive Bayes classifier is suitable for classification with\ndiscrete features (e.g., word counts for text classification). The\nmultinomial distribution normally requires integer feature counts. However,\nin practice, fractional counts such as tf-idf may also work.\n\nRead more in the :ref:`User Guide <multinomial_naive_bayes>`.\n",
      "package": "sklearn.naive_bayes"
    }
  },
  {
    "name": "KNeighborsClassifier",
    "schema": {
      "attributes": [
        {
          "default": 5,
          "description": "Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
          "name": "n_neighbors",
          "option": "optional",
          "type": "int32"
        },
        {
          "default": "uniform",
          "description": "weight function used in prediction.  Possible values:\n\n- 'uniform' : uniform weights.  All points in each neighborhood\nare weighted equally.\n- 'distance' : weight points by the inverse of their distance.\nin this case, closer neighbors of a query point will have a\ngreater influence than neighbors which are further away.\n- [callable] : a user-defined function which accepts an\narray of distances, and returns an array of the same shape\ncontaining the weights.\n",
          "name": "weights",
          "option": "optional"
        },
        {
          "default": "auto",
          "description": "Algorithm used to compute the nearest neighbors:\n\n- 'ball_tree' will use :class:`BallTree`\n- 'kd_tree' will use :class:`KDTree`\n- 'brute' will use a brute-force search.\n- 'auto' will attempt to decide the most appropriate algorithm\nbased on the values passed to :meth:`fit` method.\n\nNote: fitting on sparse input will override the setting of\nthis parameter, using brute force.\n",
          "name": "algorithm",
          "option": "optional"
        },
        {
          "default": 30,
          "description": "Leaf size passed to BallTree or KDTree.  This can affect the\nspeed of the construction and query, as well as the memory\nrequired to store the tree.  The optimal value depends on the\nnature of the problem.\n",
          "name": "leaf_size",
          "option": "optional",
          "type": "int32"
        },
        {
          "default": "2",
          "description": "Power parameter for the Minkowski metric. When p = 1, this is\nequivalent to using manhattan_distance (l1), and euclidean_distance\n(l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
          "name": "p",
          "option": "optional",
          "type": "int32"
        },
        {
          "default": "minkowski",
          "description": "the distance metric to use for the tree.  The default metric is\nminkowski, and with p=2 is equivalent to the standard Euclidean\nmetric. See the documentation of the DistanceMetric class for a\nlist of available metrics.\nIf metric is \"precomputed\", X is assumed to be a distance matrix and\nmust be square during fit. X may be a :term:`Glossary <sparse graph>`,\nin which case only \"nonzero\" elements may be considered neighbors.\n",
          "name": "metric"
        },
        {
          "default": null,
          "description": "Additional keyword arguments for the metric function.\n",
          "name": "metric_params",
          "option": "optional"
        },
        {
          "default": null,
          "description": "The number of parallel jobs to run for neighbors search.\n``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n``-1`` means using all processors. See :term:`Glossary <n_jobs>`\nfor more details.\nDoesn't affect :meth:`fit` method.\n",
          "name": "n_jobs",
          "option": "optional",
          "type": "int32"
        }
      ],
      "description": "Classifier implementing the k-nearest neighbors vote.\n\nRead more in the :ref:`User Guide <classification>`.\n",
      "package": "sklearn.neighbors"
    }
  },
  {
    "name": "KNeighborsRegressor",
    "schema": {
      "attributes": [
        {
          "default": 5,
          "description": "Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
          "name": "n_neighbors",
          "option": "optional",
          "type": "int32"
        },
        {
          "description": "weight function used in prediction.  Possible values:\n\n- 'uniform' : uniform weights.  All points in each neighborhood\nare weighted equally.\n- 'distance' : weight points by the inverse of their distance.\nin this case, closer neighbors of a query point will have a\ngreater influence than neighbors which are further away.\n- [callable] : a user-defined function which accepts an\narray of distances, and returns an array of the same shape\ncontaining the weights.\n\nUniform weights are used by default.\n",
          "name": "weights"
        },
        {
          "default": "auto",
          "description": "Algorithm used to compute the nearest neighbors:\n\n- 'ball_tree' will use :class:`BallTree`\n- 'kd_tree' will use :class:`KDTree`\n- 'brute' will use a brute-force search.\n- 'auto' will attempt to decide the most appropriate algorithm\nbased on the values passed to :meth:`fit` method.\n\nNote: fitting on sparse input will override the setting of\nthis parameter, using brute force.\n",
          "name": "algorithm",
          "option": "optional"
        },
        {
          "default": 30,
          "description": "Leaf size passed to BallTree or KDTree.  This can affect the\nspeed of the construction and query, as well as the memory\nrequired to store the tree.  The optimal value depends on the\nnature of the problem.\n",
          "name": "leaf_size",
          "option": "optional",
          "type": "int32"
        },
        {
          "default": "2",
          "description": "Power parameter for the Minkowski metric. When p = 1, this is\nequivalent to using manhattan_distance (l1), and euclidean_distance\n(l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
          "name": "p",
          "option": "optional",
          "type": "int32"
        },
        {
          "default": "minkowski",
          "description": "the distance metric to use for the tree.  The default metric is\nminkowski, and with p=2 is equivalent to the standard Euclidean\nmetric. See the documentation of the DistanceMetric class for a\nlist of available metrics.\nIf metric is \"precomputed\", X is assumed to be a distance matrix and\nmust be square during fit. X may be a :term:`Glossary <sparse graph>`,\nin which case only \"nonzero\" elements may be considered neighbors.\n",
          "name": "metric"
        },
        {
          "default": null,
          "description": "Additional keyword arguments for the metric function.\n",
          "name": "metric_params",
          "option": "optional"
        },
        {
          "default": null,
          "description": "The number of parallel jobs to run for neighbors search.\n``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n``-1`` means using all processors. See :term:`Glossary <n_jobs>`\nfor more details.\nDoesn't affect :meth:`fit` method.\n",
          "name": "n_jobs",
          "option": "optional",
          "type": "int32"
        }
      ],
      "description": "Regression based on k-nearest neighbors.\n\nThe target is predicted by local interpolation of the targets\nassociated of the nearest neighbors in the training set.\n\nRead more in the :ref:`User Guide <regression>`.\n\n.. versionadded:: 0.9\n",
      "package": "sklearn.neighbors"
    }
  },
  {
    "name": "LassoLars",
    "schema": {
      "attributes": [
        {
          "default": 1.0,
          "description": "Constant that multiplies the penalty term. Defaults to 1.0.\n``alpha = 0`` is equivalent to an ordinary least square, solved\nby :class:`LinearRegression`. For numerical reasons, using\n``alpha = 0`` with the LassoLars object is not advised and you\nshould prefer the LinearRegression object.\n",
          "name": "alpha",
          "type": "float32"
        },
        {
          "default": true,
          "description": "whether to calculate the intercept for this model. If set\nto false, no intercept will be used in calculations\n(i.e. data is expected to be centered).\n",
          "name": "fit_intercept",
          "type": "boolean"
        },
        {
          "default": "False",
          "description": "Sets the verbosity amount\n",
          "name": "verbose",
          "option": "optional"
        },
        {
          "default": true,
          "description": "This parameter is ignored when ``fit_intercept`` is set to False.\nIf True, the regressors X will be normalized before regression by\nsubtracting the mean and dividing by the l2-norm.\nIf you wish to standardize, please use\n:class:`sklearn.preprocessing.StandardScaler` before calling ``fit``\non an estimator with ``normalize=False``.\n",
          "name": "normalize",
          "option": "optional",
          "type": "boolean"
        },
        {
          "default": "auto",
          "description": "Whether to use a precomputed Gram matrix to speed up\ncalculations. If set to ``'auto'`` let us decide. The Gram\nmatrix can also be passed as argument.\n",
          "name": "precompute",
          "type": "boolean"
        },
        {
          "default": 500,
          "description": "Maximum number of iterations to perform.\n",
          "name": "max_iter",
          "option": "optional",
          "type": "int32"
        },
        {
          "description": "The machine-precision regularization in the computation of the\nCholesky diagonal factors. Increase this for very ill-conditioned\nsystems. Unlike the ``tol`` parameter in some iterative\noptimization-based algorithms, this parameter does not control\nthe tolerance of the optimization.\nBy default, ``np.finfo(np.float).eps`` is used.\n",
          "name": "eps",
          "option": "optional",
          "type": "float32"
        },
        {
          "default": true,
          "description": "If True, X will be copied; else, it may be overwritten.\n",
          "name": "copy_X",
          "option": "optional",
          "type": "boolean"
        },
        {
          "default": true,
          "description": "If ``True`` the full path is stored in the ``coef_path_`` attribute.\nIf you compute the solution for a large problem or many targets,\nsetting ``fit_path`` to ``False`` will lead to a speedup, especially\nwith a small alpha.\n",
          "name": "fit_path",
          "type": "boolean"
        },
        {
          "default": false,
          "description": "Restrict coefficients to be >= 0. Be aware that you might want to\nremove fit_intercept which is set True by default.\nUnder the positive restriction the model coefficients will not converge\nto the ordinary-least-squares solution for small values of alpha.\nOnly coefficients up to the smallest alpha value (``alphas_[alphas_ >\n0.].min()`` when fit_path=True) reached by the stepwise Lars-Lasso\nalgorithm are typically in congruence with the solution of the\ncoordinate descent Lasso estimator.\n",
          "name": "positive",
          "type": "boolean"
        }
      ],
      "description": "Lasso model fit with Least Angle Regression a.k.a. Lars\n\nIt is a Linear Model trained with an L1 prior as regularizer.\n\nThe optimization objective for Lasso is::\n\n(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1\n\nRead more in the :ref:`User Guide <least_angle_regression>`.\n",
      "package": "sklearn.linear_model"
    }
  },
  {
    "name": "PCA",
    "schema": {
      "attributes": [
        {
          "description": "Number of components to keep.\nif n_components is not set all components are kept::\n\nn_components == min(n_samples, n_features)\n\nIf ``n_components == 'mle'`` and ``svd_solver == 'full'``, Minka's\nMLE is used to guess the dimension. Use of ``n_components == 'mle'``\nwill interpret ``svd_solver == 'auto'`` as ``svd_solver == 'full'``.\n\nIf ``0 < n_components < 1`` and ``svd_solver == 'full'``, select the\nnumber of components such that the amount of variance that needs to be\nexplained is greater than the percentage specified by n_components.\n\nIf ``svd_solver == 'arpack'``, the number of components must be\nstrictly less than the minimum of n_features and n_samples.\n\nHence, the None case results in::\n\nn_components == min(n_samples, n_features) - 1\n",
          "name": "n_components"
        },
        {
          "default": true,
          "description": "If False, data passed to fit are overwritten and running\nfit(X).transform(X) will not yield the expected results,\nuse fit_transform(X) instead.\n",
          "name": "copy",
          "type": "boolean"
        },
        {
          "default": false,
          "description": "When True (False by default) the `components_` vectors are multiplied\nby the square root of n_samples and then divided by the singular values\nto ensure uncorrelated outputs with unit component-wise variances.\n\nWhitening will remove some information from the transformed signal\n(the relative variance scales of the components) but can sometime\nimprove the predictive accuracy of the downstream estimators by\nmaking their data respect some hard-wired assumptions.\n",
          "name": "whiten",
          "option": "optional",
          "type": "boolean"
        },
        {
          "description": "If auto :\nThe solver is selected by a default policy based on `X.shape` and\n`n_components`: if the input data is larger than 500x500 and the\nnumber of components to extract is lower than 80% of the smallest\ndimension of the data, then the more efficient 'randomized'\nmethod is enabled. Otherwise the exact full SVD is computed and\noptionally truncated afterwards.\nIf full :\nrun exact full SVD calling the standard LAPACK solver via\n`scipy.linalg.svd` and select the components by postprocessing\nIf arpack :\nrun SVD truncated to n_components calling ARPACK solver via\n`scipy.sparse.linalg.svds`. It requires strictly\n0 < n_components < min(X.shape)\nIf randomized :\nrun randomized SVD by the method of Halko et al.\n\n.. versionadded:: 0.18.0\n",
          "name": "svd_solver",
          "type": "string"
        },
        {
          "default": ".0",
          "description": "Tolerance for singular values computed by svd_solver == 'arpack'.\n\n.. versionadded:: 0.18.0\n",
          "name": "tol",
          "option": "optional"
        },
        {
          "default": "auto",
          "description": "Number of iterations for the power method computed by\nsvd_solver == 'randomized'.\n\n.. versionadded:: 0.18.0\n",
          "name": "iterated_power"
        },
        {
          "default": null,
          "description": "If int, random_state is the seed used by the random number generator;\nIf RandomState instance, random_state is the random number generator;\nIf None, the random number generator is the RandomState instance used\nby `np.random`. Used when ``svd_solver`` == 'arpack' or 'randomized'.\n\n.. versionadded:: 0.18.0\n",
          "name": "random_state",
          "option": "optional",
          "type": "int32"
        }
      ],
      "description": "Principal component analysis (PCA).\n\nLinear dimensionality reduction using Singular Value Decomposition of the\ndata to project it to a lower dimensional space. The input data is centered\nbut not scaled for each feature before applying the SVD.\n\nIt uses the LAPACK implementation of the full SVD or a randomized truncated\nSVD by the method of Halko et al. 2009, depending on the shape of the input\ndata and the number of components to extract.\n\nIt can also use the scipy.sparse.linalg ARPACK implementation of the\ntruncated SVD.\n\nNotice that this class does not support sparse input. See\n:class:`TruncatedSVD` for an alternative with sparse data.\n\nRead more in the :ref:`User Guide <PCA>`.\n",
      "package": "sklearn.decomposition"
    }
  },
  {
    "name": "CalibratedClassifierCV",
    "schema": {
      "attributes": [
        {
          "description": "The classifier whose output decision function needs to be calibrated\nto offer more accurate predict_proba outputs. If cv=prefit, the\nclassifier must have been fit already on data.\n",
          "name": "base_estimator"
        },
        {
          "description": "The method to use for calibration. Can be 'sigmoid' which\ncorresponds to Platt's method or 'isotonic' which is a\nnon-parametric approach. It is not advised to use isotonic calibration\nwith too few calibration samples ``(<<1000)`` since it tends to\noverfit.\nUse sigmoids (Platt's calibration) in this case.\n",
          "name": "method"
        },
        {
          "description": "Determines the cross-validation splitting strategy.\nPossible inputs for cv are:\n\n- None, to use the default 5-fold cross-validation,\n- integer, to specify the number of folds.\n- :term:`CV splitter`,\n- An iterable yielding (train, test) splits as arrays of indices.\n\nFor integer/None inputs, if ``y`` is binary or multiclass,\n:class:`sklearn.model_selection.StratifiedKFold` is used. If ``y`` is\nneither binary nor multiclass, :class:`sklearn.model_selection.KFold`\nis used.\n\nRefer :ref:`User Guide <cross_validation>` for the various\ncross-validation strategies that can be used here.\n\nIf \"prefit\" is passed, it is assumed that base_estimator has been\nfitted already and all data is used for calibration.\n\n.. versionchanged:: 0.22\n``cv`` default value if None changed from 3-fold to 5-fold.\n",
          "name": "cv",
          "option": "optional"
        }
      ],
      "description": "Probability calibration with isotonic regression or sigmoid.\n\nSee glossary entry for :term:`cross-validation estimator`.\n\nWith this class, the base_estimator is fit on the train set of the\ncross-validation generator and the test set is used for calibration.\nThe probabilities for each of the folds are then averaged\nfor prediction. In case that cv=\"prefit\" is passed to __init__,\nit is assumed that base_estimator has been fitted already and all\ndata is used for calibration. Note that data for fitting the\nclassifier and for calibrating it must be disjoint.\n\nRead more in the :ref:`User Guide <calibration>`.\n",
      "package": "sklearn.calibration"
    }
  },
  {
    "name": "CountVectorizer",
    "schema": {
      "attributes": [
        {
          "default": "content",
          "description": "If 'filename', the sequence passed as an argument to fit is\nexpected to be a list of filenames that need reading to fetch\nthe raw content to analyze.\n\nIf 'file', the sequence items must have a 'read' method (file-like\nobject) that is called to fetch the bytes in memory.\n\nOtherwise the input is expected to be a sequence of items that\ncan be of type string or byte.\n",
          "name": "input",
          "type": "string"
        },
        {
          "default": "utf-8",
          "description": "If bytes or files are given to analyze, this encoding is used to\ndecode.\n",
          "name": "encoding",
          "type": "string"
        },
        {
          "default": "strict",
          "description": "Instruction on what to do if a byte sequence is given to analyze that\ncontains characters not of the given `encoding`. By default, it is\n'strict', meaning that a UnicodeDecodeError will be raised. Other\nvalues are 'ignore' and 'replace'.\n",
          "name": "decode_error"
        },
        {
          "default": null,
          "description": "Remove accents and perform other character normalization\nduring the preprocessing step.\n'ascii' is a fast method that only works on characters that have\nan direct ASCII mapping.\n'unicode' is a slightly slower method that works on any characters.\nNone (default) does nothing.\n\nBoth 'ascii' and 'unicode' use NFKD normalization from\n:func:`unicodedata.normalize`.\n",
          "name": "strip_accents"
        },
        {
          "default": true,
          "description": "Convert all characters to lowercase before tokenizing.\n",
          "name": "lowercase",
          "type": "boolean"
        },
        {
          "default": null,
          "description": "Override the preprocessing (string transformation) stage while\npreserving the tokenizing and n-grams generation steps.\nOnly applies if ``analyzer is not callable``.\n",
          "name": "preprocessor"
        },
        {
          "default": null,
          "description": "Override the string tokenization step while preserving the\npreprocessing and n-grams generation steps.\nOnly applies if ``analyzer == 'word'``.\n",
          "name": "tokenizer"
        },
        {
          "default": "None",
          "description": "If 'english', a built-in stop word list for English is used.\nThere are several known issues with 'english' and you should\nconsider an alternative (see :ref:`stop_words`).\n\nIf a list, that list is assumed to contain stop words, all of which\nwill be removed from the resulting tokens.\nOnly applies if ``analyzer == 'word'``.\n\nIf None, no stop words will be used. max_df can be set to a value\nin the range [0.7, 1.0) to automatically detect and filter stop\nwords based on intra corpus document frequency of terms.\n",
          "name": "stop_words",
          "type": "string"
        },
        {
          "description": "Regular expression denoting what constitutes a \"token\", only used\nif ``analyzer == 'word'``. The default regexp select tokens of 2\nor more alphanumeric characters (punctuation is completely ignored\nand always treated as a token separator).\n",
          "name": "token_pattern",
          "type": "string"
        },
        {
          "default": "(1, 1)",
          "description": "The lower and upper boundary of the range of n-values for different\nword n-grams or char n-grams to be extracted. All values of n such\nsuch that min_n <= n <= max_n will be used. For example an\n``ngram_range`` of ``(1, 1)`` means only unigrams, ``(1, 2)`` means\nunigrams and bigrams, and ``(2, 2)`` means only bigrams.\nOnly applies if ``analyzer is not callable``.\n",
          "name": "ngram_range"
        },
        {
          "default": "word",
          "description": "Whether the feature should be made of word n-gram or character\nn-grams.\nOption 'char_wb' creates character n-grams only from text inside\nword boundaries; n-grams at the edges of words are padded with space.\n\nIf a callable is passed it is used to extract the sequence of features\nout of the raw, unprocessed input.\n\n.. versionchanged:: 0.21\n\nSince v0.21, if ``input`` is ``filename`` or ``file``, the data is\nfirst read from the file and then passed to the given callable\nanalyzer.\n",
          "name": "analyzer",
          "type": "string"
        },
        {
          "default": "1.0",
          "description": "When building the vocabulary ignore terms that have a document\nfrequency strictly higher than the given threshold (corpus-specific\nstop words).\nIf float, the parameter represents a proportion of documents, integer\nabsolute counts.\nThis parameter is ignored if vocabulary is not None.\n",
          "name": "max_df"
        },
        {
          "default": "1",
          "description": "When building the vocabulary ignore terms that have a document\nfrequency strictly lower than the given threshold. This value is also\ncalled cut-off in the literature.\nIf float, the parameter represents a proportion of documents, integer\nabsolute counts.\nThis parameter is ignored if vocabulary is not None.\n",
          "name": "min_df"
        },
        {
          "default": null,
          "description": "If not None, build a vocabulary that only consider the top\nmax_features ordered by term frequency across the corpus.\n\nThis parameter is ignored if vocabulary is not None.\n",
          "name": "max_features",
          "type": "int32"
        },
        {
          "default": null,
          "description": "Either a Mapping (e.g., a dict) where keys are terms and values are\nindices in the feature matrix, or an iterable over terms. If not\ngiven, a vocabulary is determined from the input documents. Indices\nin the mapping should not be repeated and should not have any gap\nbetween 0 and the largest index.\n",
          "name": "vocabulary",
          "option": "optional"
        },
        {
          "default": false,
          "description": "If True, all non zero counts are set to 1. This is useful for discrete\nprobabilistic models that model binary events rather than integer\ncounts.\n",
          "name": "binary",
          "type": "boolean"
        },
        {
          "default": "np.int64",
          "description": "Type of the matrix returned by fit_transform() or transform().\n",
          "name": "dtype",
          "option": "optional"
        }
      ],
      "description": "Convert a collection of text documents to a matrix of token counts\n\nThis implementation produces a sparse representation of the counts using\nscipy.sparse.csr_matrix.\n\nIf you do not provide an a-priori dictionary and you do not use an analyzer\nthat does some kind of feature selection then the number of features will\nbe equal to the vocabulary size found by analyzing the data.\n\nRead more in the :ref:`User Guide <text_feature_extraction>`.\n",
      "package": "sklearn.feature_extraction.text"
    }
  },
  {
    "name": "TfidfVectorizer",
    "schema": {
      "attributes": [
        {
          "default": "content",
          "description": "If 'filename', the sequence passed as an argument to fit is\nexpected to be a list of filenames that need reading to fetch\nthe raw content to analyze.\n\nIf 'file', the sequence items must have a 'read' method (file-like\nobject) that is called to fetch the bytes in memory.\n\nOtherwise the input is expected to be a sequence of items that\ncan be of type string or byte.\n",
          "name": "input",
          "type": "string"
        },
        {
          "default": "utf-8",
          "description": "If bytes or files are given to analyze, this encoding is used to\ndecode.\n",
          "name": "encoding",
          "type": "string"
        },
        {
          "default": "strict",
          "description": "Instruction on what to do if a byte sequence is given to analyze that\ncontains characters not of the given `encoding`. By default, it is\n'strict', meaning that a UnicodeDecodeError will be raised. Other\nvalues are 'ignore' and 'replace'.\n",
          "name": "decode_error"
        },
        {
          "default": null,
          "description": "Remove accents and perform other character normalization\nduring the preprocessing step.\n'ascii' is a fast method that only works on characters that have\nan direct ASCII mapping.\n'unicode' is a slightly slower method that works on any characters.\nNone (default) does nothing.\n\nBoth 'ascii' and 'unicode' use NFKD normalization from\n:func:`unicodedata.normalize`.\n",
          "name": "strip_accents"
        },
        {
          "default": true,
          "description": "Convert all characters to lowercase before tokenizing.\n",
          "name": "lowercase",
          "type": "boolean"
        },
        {
          "default": null,
          "description": "Override the preprocessing (string transformation) stage while\npreserving the tokenizing and n-grams generation steps.\nOnly applies if ``analyzer is not callable``.\n",
          "name": "preprocessor"
        },
        {
          "default": null,
          "description": "Override the string tokenization step while preserving the\npreprocessing and n-grams generation steps.\nOnly applies if ``analyzer == 'word'``.\n",
          "name": "tokenizer"
        },
        {
          "description": "Whether the feature should be made of word or character n-grams.\nOption 'char_wb' creates character n-grams only from text inside\nword boundaries; n-grams at the edges of words are padded with space.\n\nIf a callable is passed it is used to extract the sequence of features\nout of the raw, unprocessed input.\n\n.. versionchanged:: 0.21\n\nSince v0.21, if ``input`` is ``filename`` or ``file``, the data is\nfirst read from the file and then passed to the given callable\nanalyzer.\n",
          "name": "analyzer"
        },
        {
          "default": null,
          "description": "If a string, it is passed to _check_stop_list and the appropriate stop\nlist is returned. 'english' is currently the only supported string\nvalue.\nThere are several known issues with 'english' and you should\nconsider an alternative (see :ref:`stop_words`).\n\nIf a list, that list is assumed to contain stop words, all of which\nwill be removed from the resulting tokens.\nOnly applies if ``analyzer == 'word'``.\n\nIf None, no stop words will be used. max_df can be set to a value\nin the range [0.7, 1.0) to automatically detect and filter stop\nwords based on intra corpus document frequency of terms.\n",
          "name": "stop_words"
        },
        {
          "description": "Regular expression denoting what constitutes a \"token\", only used\nif ``analyzer == 'word'``. The default regexp selects tokens of 2\nor more alphanumeric characters (punctuation is completely ignored\nand always treated as a token separator).\n",
          "name": "token_pattern",
          "type": "string"
        },
        {
          "default": "(1, 1)",
          "description": "The lower and upper boundary of the range of n-values for different\nn-grams to be extracted. All values of n such that min_n <= n <= max_n\nwill be used. For example an ``ngram_range`` of ``(1, 1)`` means only\nunigrams, ``(1, 2)`` means unigrams and bigrams, and ``(2, 2)`` means\nonly bigrams.\nOnly applies if ``analyzer is not callable``.\n",
          "name": "ngram_range"
        },
        {
          "default": "1.0",
          "description": "When building the vocabulary ignore terms that have a document\nfrequency strictly higher than the given threshold (corpus-specific\nstop words).\nIf float, the parameter represents a proportion of documents, integer\nabsolute counts.\nThis parameter is ignored if vocabulary is not None.\n",
          "name": "max_df"
        },
        {
          "default": "1",
          "description": "When building the vocabulary ignore terms that have a document\nfrequency strictly lower than the given threshold. This value is also\ncalled cut-off in the literature.\nIf float, the parameter represents a proportion of documents, integer\nabsolute counts.\nThis parameter is ignored if vocabulary is not None.\n",
          "name": "min_df"
        },
        {
          "default": null,
          "description": "If not None, build a vocabulary that only consider the top\nmax_features ordered by term frequency across the corpus.\n\nThis parameter is ignored if vocabulary is not None.\n",
          "name": "max_features",
          "type": "int32"
        },
        {
          "default": null,
          "description": "Either a Mapping (e.g., a dict) where keys are terms and values are\nindices in the feature matrix, or an iterable over terms. If not\ngiven, a vocabulary is determined from the input documents.\n",
          "name": "vocabulary",
          "option": "optional"
        },
        {
          "default": false,
          "description": "If True, all non-zero term counts are set to 1. This does not mean\noutputs will have only 0/1 values, only that the tf term in tf-idf\nis binary. (Set idf and normalization to False to get 0/1 outputs).\n",
          "name": "binary",
          "type": "boolean"
        },
        {
          "default": "float64",
          "description": "Type of the matrix returned by fit_transform() or transform().\n",
          "name": "dtype",
          "option": "optional"
        },
        {
          "default": "l2",
          "description": "Each output row will have unit norm, either:\n* 'l2': Sum of squares of vector elements is 1. The cosine\nsimilarity between two vectors is their dot product when l2 norm has\nbeen applied.\n* 'l1': Sum of absolute values of vector elements is 1.\nSee :func:`preprocessing.normalize`.\n",
          "name": "norm"
        },
        {
          "default": true,
          "description": "Enable inverse-document-frequency reweighting.\n",
          "name": "use_idf",
          "type": "boolean"
        },
        {
          "default": true,
          "description": "Smooth idf weights by adding one to document frequencies, as if an\nextra document was seen containing every term in the collection\nexactly once. Prevents zero divisions.\n",
          "name": "smooth_idf",
          "type": "boolean"
        },
        {
          "default": false,
          "description": "Apply sublinear tf scaling, i.e. replace tf with 1 + log(tf).\n",
          "name": "sublinear_tf",
          "type": "boolean"
        }
      ],
      "description": "Convert a collection of raw documents to a matrix of TF-IDF features.\n\nEquivalent to :class:`CountVectorizer` followed by\n:class:`TfidfTransformer`.\n\nRead more in the :ref:`User Guide <text_feature_extraction>`.\n",
      "package": "sklearn.feature_extraction.text"
    }
  },
  {
    "name": "LGBMRegressor",
    "schema": {
      "attributes": [
        {
          "default": "gbdt",
          "name": "boosting_type",
          "type": "string"
        },
        {
          "default": null,
          "name": "class_weight"
        },
        {
          "default": 1.0,
          "name": "colsample_bytree"
        },
        {
          "default": 0.05,
          "name": "learning_rate"
        },
        {
          "default": -1,
          "name": "max_depth"
        },
        {
          "default": 20,
          "name": "min_child_samples"
        },
        {
          "default": 0.001,
          "name": "min_child_weight"
        },
        {
          "default": 0.0,
          "name": "min_split_gain"
        },
        {
          "default": 100,
          "name": "n_estimators"
        },
        {
          "default": -1,
          "name": "n_jobs"
        },
        {
          "default": 31,
          "name": "num_leaves"
        },
        {
          "default": null,
          "name": "random_state"
        },
        {
          "default": 0,
          "name": "reg_alpha"
        },
        {
          "default": 0,
          "name": "reg_lambda"
        },
        {
          "default": true,
          "name": "silent",
          "type": "boolean"
        },
        {
          "default": 200000,
          "name": "subsample_for_bin"
        },
        {
          "default": 0,
          "name": "subsample_freq"
        },
        {
          "default": 1.0,
          "name": "subsample"
        }
      ]
    }
  },
  {
    "name": "LGBMClassifier",
    "schema": {
      "attributes": [
        {
          "default": "gbdt",
          "name": "boosting_type",
          "type": "string"
        },
        {
          "default": null,
          "name": "class_weight"
        },
        {
          "default": 1.0,
          "name": "colsample_bytree"
        },
        {
          "default": 0.05,
          "name": "learning_rate"
        },
        {
          "default": -1,
          "name": "max_depth"
        },
        {
          "default": 20,
          "name": "min_child_samples"
        },
        {
          "default": 0.001,
          "name": "min_child_weight"
        },
        {
          "default": 0.0,
          "name": "min_split_gain"
        },
        {
          "default": 100,
          "name": "n_estimators"
        },
        {
          "default": -1,
          "name": "n_jobs"
        },
        {
          "default": 31,
          "name": "num_leaves"
        },
        {
          "default": null,
          "name": "random_state"
        },
        {
          "default": 0,
          "name": "reg_alpha"
        },
        {
          "default": 0,
          "name": "reg_lambda"
        },
        {
          "default": true,
          "name": "silent",
          "type": "boolean"
        },
        {
          "default": 200000,
          "name": "subsample_for_bin"
        },
        {
          "default": 0,
          "name": "subsample_freq"
        },
        {
          "default": 1.0,
          "name": "subsample"
        }
      ]
    }
  },
  {
    "name": "Booster",
    "schema": {
      "attributes": [
        {
          "default": -1,
          "name": "best_iteration"
        },
        {
          "default": false,
          "name": "network"
        },
        {
          "default": null,
          "name": "train_set"
        },
        {
          "default": false,
          "name": "stride"
        },
        {
          "default": null,
          "name": "model_file"
        },
        {
          "default": null,
          "name": "params"
        },
        {
          "default": null,
          "name": "pandas_categorical"
        }
      ]
    }
  },
  {
    "name": "LinearRegression",
    "schema": {
      "attributes": [
        {
          "default": true,
          "description": "Whether to calculate the intercept for this model. If set\nto False, no intercept will be used in calculations\n(i.e. data is expected to be centered).\n",
          "name": "fit_intercept",
          "option": "optional",
          "type": "boolean"
        },
        {
          "default": false,
          "description": "This parameter is ignored when ``fit_intercept`` is set to False.\nIf True, the regressors X will be normalized before regression by\nsubtracting the mean and dividing by the l2-norm.\nIf you wish to standardize, please use\n:class:`sklearn.preprocessing.StandardScaler` before calling ``fit`` on\nan estimator with ``normalize=False``.\n",
          "name": "normalize",
          "option": "optional",
          "type": "boolean"
        },
        {
          "default": true,
          "description": "If True, X will be copied; else, it may be overwritten.\n",
          "name": "copy_X",
          "option": "optional",
          "type": "boolean"
        },
        {
          "default": null,
          "description": "The number of jobs to use for the computation. This will only provide\nspeedup for n_targets > 1 and sufficient large problems.\n``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n``-1`` means using all processors. See :term:`Glossary <n_jobs>`\nfor more details.\n",
          "name": "n_jobs",
          "option": "optional",
          "type": "int32"
        }
      ],
      "description": "\nOrdinary least squares Linear Regression.\n\nLinearRegression fits a linear model with coefficients w = (w1, ..., wp)\nto minimize the residual sum of squares between the observed targets in\nthe dataset, and the targets predicted by the linear approximation.\n",
      "package": "sklearn.linear_model"
    }
  }
]
