[
  {
    "name": "Activation",
    "module": "keras.layers",
    "description": "Applies an activation function to an output.",
    "attributes": [
      {
        "description": "Activation function. It could be a callable, or the name of\n        an activation from the `keras.activations` namespace.",
        "name": "activation"
      },
      {
        "name": "**kwargs",
        "description": "Base layer keyword arguments, such as `name` and `dtype`."
      }
    ],
    "inputs": [
      {
        "description": "Arbitrary. Use the keyword argument `input_shape`\n(tuple of integers, does not include the batch axis)\nwhen using this layer as the first layer in a model.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "Same shape as input.",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> layer = keras.layers.Activation('relu')\n>>> layer([-3.0, -1.0, 0.0, 2.0])\n[0.0, 0.0, 0.0, 2.0]\n>>> layer = keras.layers.Activation(keras.activations.relu)\n>>> layer([-3.0, -1.0, 0.0, 2.0])\n[0.0, 0.0, 0.0, 2.0]"
      }
    ]
  },
  {
    "name": "ActivityRegularization",
    "module": "keras.layers",
    "description": "Layer that applies an update to the cost function based input activity.",
    "attributes": [
      {
        "description": "L1 regularization factor (positive float).",
        "name": "l1"
      },
      {
        "description": "L2 regularization factor (positive float).",
        "name": "l2"
      }
    ],
    "inputs": [
      {
        "description": "Arbitrary. Use the keyword argument `input_shape`\n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "Same shape as input.",
        "name": "output"
      }
    ]
  },
  {
    "name": "Add",
    "module": "keras.layers",
    "description": "Performs elementwise addition operation.\n\nIt takes as input a list of tensors, all of the same shape,\nand returns a single tensor (also of the same shape).",
    "inputs": [
      {
        "name": "inputs",
        "list": true
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> input_shape = (2, 3, 4)\n>>> x1 = np.random.rand(*input_shape)\n>>> x2 = np.random.rand(*input_shape)\n>>> y = keras.layers.Add()([x1, x2])"
      },
      {
        "summary": "Usage in a Keras model:",
        "code": ">>> input1 = keras.layers.Input(shape=(16,))\n>>> x1 = keras.layers.Dense(8, activation='relu')(input1)\n>>> input2 = keras.layers.Input(shape=(32,))\n>>> x2 = keras.layers.Dense(8, activation='relu')(input2)\n>>> # equivalent to `added = keras.layers.add([x1, x2])`\n>>> added = keras.layers.Add()([x1, x2])\n>>> out = keras.layers.Dense(4)(added)\n>>> model = keras.models.Model(inputs=[input1, input2], outputs=out)"
      }
    ]
  },
  {
    "name": "Attention",
    "module": "keras.layers",
    "description": "Dot-product attention layer, a.k.a. Luong-style attention.\n\nInputs are a list with 2 or 3 elements:\n1. A `query` tensor of shape `(batch_size, Tq, dim)`.\n2. A `value` tensor of shape `(batch_size, Tv, dim)`.\n3. A optional `key` tensor of shape `(batch_size, Tv, dim)`. If none\n    supplied, `value` will be used as a `key`.\n\nThe calculation follows the steps:\n1. Calculate attention scores using `query` and `key` with shape\n    `(batch_size, Tq, Tv)`.\n2. Use scores to calculate a softmax distribution with shape\n    `(batch_size, Tq, Tv)`.\n3. Use the softmax distribution to create a linear combination of `value`\n    with shape `(batch_size, Tq, dim)`.",
    "attributes": [
      {
        "description": "If `True`, will create a scalar variable to scale the\n        attention scores.",
        "name": "use_scale"
      },
      {
        "description": "Boolean. Set to `True` for decoder self-attention. Adds a mask\n    such that position `i` cannot attend to positions `j > i`. This prevents\n    the flow of information from the future towards the past.  Defaults to\n    `False`.",
        "name": "causal"
      },
      {
        "description": "Float between 0 and 1. Fraction of the units to drop for the\n        attention scores. Defaults to `0.0`.",
        "name": "dropout"
      },
      {
        "description": "List of the following tensors:\n        - `query`: Query tensor of shape `(batch_size, Tq, dim)`.\n        - `value`: Value tensor of shape `(batch_size, Tv, dim)`.\n        - `key`: Optional key tensor of shape `(batch_size, Tv, dim)`. If\n            not given, will use `value` for both `key` and `value`, which is\n            the most common case.",
        "name": "inputs"
      },
      {
        "description": "List of the following tensors:\n        - `query_mask`: A boolean mask tensor of shape `(batch_size, Tq)`.\n            If given, the output will be zero at the positions where\n            `mask==False`.\n        - `value_mask`: A boolean mask tensor of shape `(batch_size, Tv)`.\n            If given, will apply the mask such that values at positions\n             where `mask==False` do not contribute to the result.",
        "name": "mask"
      },
      {
        "description": "bool, it `True`, returns the attention scores\n        (after masking and softmax) as an additional output argument.",
        "name": "return_attention_scores"
      },
      {
        "description": "Python boolean indicating whether the layer should behave in\n        training mode (adding dropout) or in inference mode (no dropout).",
        "name": "training"
      },
      {
        "name": "score_mode",
        "description": "Function to use to compute attention scores, one of\n        `{\"dot\", \"concat\"}`. `\"dot\"` refers to the dot product between the\n        query and key vectors. `\"concat\"` refers to the hyperbolic tangent\n        of the concatenation of the `query` and `key` vectors.\n\nCall Args:"
      },
      {
        "name": "use_causal_mask",
        "description": "Boolean. Set to `True` for decoder self-attention. Adds\n        a mask such that position `i` cannot attend to positions `j > i`.\n        This prevents the flow of information from the future towards the\n        past. Defaults to `False`.\n\nOutput:\n    Attention outputs of shape `(batch_size, Tq, dim)`.\n    (Optional) Attention scores after masking and softmax with shape\n        `(batch_size, Tq, Tv)`."
      }
    ]
  },
  {
    "name": "Average",
    "module": "keras.layers",
    "category": "Tensor",
    "description": "Averages a list of inputs element-wise..\n\nIt takes as input a list of tensors, all of the same shape,\nand returns a single tensor (also of the same shape).",
    "inputs": [
      {
        "name": "inputs",
        "list": true
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> input_shape = (2, 3, 4)\n>>> x1 = np.random.rand(*input_shape)\n>>> x2 = np.random.rand(*input_shape)\n>>> y = keras.layers.Average()([x1, x2])"
      },
      {
        "summary": "Usage in a Keras model:",
        "code": ">>> input1 = keras.layers.Input(shape=(16,))\n>>> x1 = keras.layers.Dense(8, activation='relu')(input1)\n>>> input2 = keras.layers.Input(shape=(32,))\n>>> x2 = keras.layers.Dense(8, activation='relu')(input2)\n>>> # equivalent to `y = keras.layers.average([x1, x2])`\n>>> y = keras.layers.Average()([x1, x2])\n>>> out = keras.layers.Dense(4)(y)\n>>> model = keras.models.Model(inputs=[input1, input2], outputs=out)"
      }
    ]
  },
  {
    "name": "AveragePooling1D",
    "module": "keras.layers",
    "category": "Pool",
    "description": "Average pooling for temporal data.\n\nDownsamples the input representation by taking the average value over the\nwindow defined by `pool_size`. The window is shifted by `strides`.  The\nresulting output when using \"valid\" padding option has a shape of:\n`output_shape = (input_shape - pool_size + 1) / strides)`\n\nThe resulting output shape when using the \"same\" padding option is:\n`output_shape = input_shape / strides`",
    "attributes": [
      {
        "description": "int, size of the max pooling window.",
        "name": "pool_size"
      },
      {
        "description": "int or None. Specifies how much the pooling window moves\n        for each pooling step. If None, it will default to `pool_size`.",
        "name": "strides"
      },
      {
        "description": "string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input.",
        "name": "padding"
      },
      {
        "description": "string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, steps, features)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, steps)`. It defaults to the `image_data_format`\n        value found in your Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.",
        "name": "data_format"
      }
    ],
    "inputs": [
      {
        "description": "- If `data_format=\"channels_last\"`:\n    3D tensor with shape `(batch_size, steps, features)`.\n- If `data_format=\"channels_first\"`:\n    3D tensor with shape `(batch_size, features, steps)`.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "- If `data_format=\"channels_last\"`:\n    3D tensor with shape `(batch_size, downsampled_steps, features)`.\n- If `data_format=\"channels_first\"`:\n    3D tensor with shape `(batch_size, features, downsampled_steps)`.",
        "name": "output"
      }
    ],
    "examples": [
      {
        "summary": "`strides=1` and `padding=\"valid\"`:",
        "code": ">>> x = np.array([1., 2., 3., 4., 5.])\n>>> x = np.reshape(x, [1, 5, 1])\n>>> avg_pool_1d = keras.layers.AveragePooling1D(pool_size=2,\n...    strides=1, padding=\"valid\")\n>>> avg_pool_1d(x)"
      },
      {
        "summary": "`strides=2` and `padding=\"valid\"`:",
        "code": ">>> x = np.array([1., 2., 3., 4., 5.])\n>>> x = np.reshape(x, [1, 5, 1])\n>>> avg_pool_1d = keras.layers.AveragePooling1D(pool_size=2,\n...    strides=2, padding=\"valid\")\n>>> avg_pool_1d(x)"
      },
      {
        "summary": "`strides=1` and `padding=\"same\"`:",
        "code": ">>> x = np.array([1., 2., 3., 4., 5.])\n>>> x = np.reshape(x, [1, 5, 1])\n>>> avg_pool_1d = keras.layers.AveragePooling1D(pool_size=2,\n...    strides=1, padding=\"same\")\n>>> avg_pool_1d(x)"
      }
    ]
  },
  {
    "name": "AveragePooling2D",
    "module": "keras.layers",
    "category": "Pool",
    "description": "Average pooling operation for 2D spatial data.\n\nDownsamples the input along its spatial dimensions (height and width)\nby taking the average value over an input window\n(of size defined by `pool_size`) for each channel of the input.\nThe window is shifted by `strides` along each dimension.\n\nThe resulting output when using the `\"valid\"` padding option has a spatial\nshape (number of rows or columns) of:\n`output_shape = math.floor((input_shape - pool_size) / strides) + 1`\n(when `input_shape >= pool_size`)\n\nThe resulting output shape when using the `\"same\"` padding option is:\n`output_shape = math.floor((input_shape - 1) / strides) + 1`",
    "attributes": [
      {
        "default": "channels_last",
        "description": "string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, height, width, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, height, width)`. It defaults to the\n        `image_data_format` value found in your Keras config file at\n        `~/.keras/keras.json`. If you never set it, then it will be\n        `\"channels_last\"`.",
        "name": "data_format"
      },
      {
        "description": "int or tuple of 2 integers, factors by which to downscale\n        (dim1, dim2). If only one integer is specified, the same\n        window length will be used for all dimensions.",
        "name": "pool_size"
      },
      {
        "description": "int or tuple of 2 integers, or None. Strides values. If None,\n        it will default to `pool_size`. If only one int is specified, the\n        same stride size will be used for all dimensions.",
        "name": "strides"
      },
      {
        "description": "string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input.",
        "name": "padding"
      }
    ],
    "inputs": [
      {
        "description": "- If `data_format=\"channels_last\"`:\n    4D tensor with shape `(batch_size, height, width, channels)`.\n- If `data_format=\"channels_first\"`:\n    4D tensor with shape `(batch_size, channels, height, width)`.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "- If `data_format=\"channels_last\"`:\n    4D tensor with shape\n    `(batch_size, pooled_height, pooled_width, channels)`.\n- If `data_format=\"channels_first\"`:\n    4D tensor with shape\n    `(batch_size, channels, pooled_height, pooled_width)`.",
        "name": "output"
      }
    ],
    "examples": [
      {
        "summary": "`strides=(1, 1)` and `padding=\"valid\"`:",
        "code": ">>> x = np.array([[1., 2., 3.],\n...               [4., 5., 6.],\n...               [7., 8., 9.]])\n>>> x = np.reshape(x, [1, 3, 3, 1])\n>>> avg_pool_2d = keras.layers.AveragePooling2D(pool_size=(2, 2),\n...    strides=(1, 1), padding=\"valid\")\n>>> avg_pool_2d(x)"
      },
      {
        "summary": "`strides=(2, 2)` and `padding=\"valid\"`:",
        "code": ">>> x = np.array([[1., 2., 3., 4.],\n...              [5., 6., 7., 8.],\n...              [9., 10., 11., 12.]])\n>>> x = np.reshape(x, [1, 3, 4, 1])\n>>> avg_pool_2d = keras.layers.AveragePooling2D(pool_size=(2, 2),\n...    strides=(2, 2), padding=\"valid\")\n>>> avg_pool_2d(x)"
      },
      {
        "summary": "`stride=(1, 1)` and `padding=\"same\"`:",
        "code": ">>> x = np.array([[1., 2., 3.],\n...                  [4., 5., 6.],\n...                  [7., 8., 9.]])\n>>> x = np.reshape(x, [1, 3, 3, 1])\n>>> avg_pool_2d = keras.layers.AveragePooling2D(pool_size=(2, 2),\n...    strides=(1, 1), padding=\"same\")\n>>> avg_pool_2d(x)"
      }
    ]
  },
  {
    "name": "AveragePooling3D",
    "module": "keras.layers",
    "description": "Average pooling operation for 3D data (spatial or spatio-temporal).\n\nDownsamples the input along its spatial dimensions (depth, height, and\nwidth) by taking the average value over an input window (of size defined by\n`pool_size`) for each channel of the input. The window is shifted by\n`strides` along each dimension.",
    "attributes": [
      {
        "description": "int or tuple of 3 integers, factors by which to downscale\n        (dim1, dim2, dim3). If only one integer is specified, the same\n        window length will be used for all dimensions.",
        "name": "pool_size"
      },
      {
        "description": "int or tuple of 3 integers, or None. Strides values. If None,\n        it will default to `pool_size`. If only one int is specified, the\n        same stride size will be used for all dimensions.",
        "name": "strides"
      },
      {
        "description": "string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input.",
        "name": "padding"
      },
      {
        "default": "channels_last",
        "description": "string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape\n        `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)` while\n        `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n        It defaults to the `image_data_format` value found in your Keras\n        config file at `~/.keras/keras.json`. If you never set it, then it\n        will be `\"channels_last\"`.",
        "name": "data_format"
      }
    ],
    "inputs": [
      {
        "description": "- If `data_format=\"channels_last\"`:\n    5D tensor with shape:\n    `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n- If `data_format=\"channels_first\"`:\n    5D tensor with shape:\n    `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "- If `data_format=\"channels_last\"`:\n    5D tensor with shape:\n    `(batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)`\n- If `data_format=\"channels_first\"`:\n    5D tensor with shape:\n    `(batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": "depth = 30\nheight = 30\nwidth = 30\nchannels = 3\n\ninputs = keras.layers.Input(shape=(depth, height, width, channels))\nlayer = keras.layers.AveragePooling3D(pool_size=3)\noutputs = layer(inputs)  # Shape: (batch_size, 10, 10, 10, 3)"
      }
    ]
  },
  {
    "name": "BatchNorm",
    "category": "Normalization",
    "attributes": [
      {
        "default": -1,
        "name": "axis"
      },
      {
        "default": 0.001,
        "name": "epsilon"
      },
      {
        "default": 0.99,
        "name": "momentum"
      },
      {
        "default": true,
        "name": "scale"
      },
      {
        "default": true,
        "name": "center"
      },
      {
        "default": {
          "class_name": "Ones",
          "config": {}
        },
        "name": "gamma_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "Zeros",
          "config": {}
        },
        "name": "moving_mean_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "Ones",
          "config": {}
        },
        "name": "moving_variance_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "Zeros",
          "config": {}
        },
        "name": "beta_initializer",
        "visible": false
      },
      {
        "name": "beta_regularizer",
        "visible": false
      },
      {
        "name": "gamma_regularizer",
        "visible": false
      },
      {
        "name": "beta_constraint"
      },
      {
        "name": "gamma_constraint"
      }
    ],
    "inputs": [
      {
        "name": "input"
      },
      {
        "name": "gamma"
      },
      {
        "name": "beta"
      },
      {
        "name": "running_mean"
      },
      {
        "name": "running_std"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ]
  },
  {
    "name": "BatchNormalization",
    "module": "keras.layers",
    "category": "Normalization",
    "description": "Layer that normalizes its inputs.\n\nBatch normalization applies a transformation that maintains the mean output\nclose to 0 and the output standard deviation close to 1.\n\nImportantly, batch normalization works differently during training and\nduring inference.\n\n**During training** (i.e. when using `fit()` or when calling the layer/model\nwith the argument `training=True`), the layer normalizes its output using\nthe mean and standard deviation of the current batch of inputs. That is to\nsay, for each channel being normalized, the layer returns\n`gamma * (batch - mean(batch)) / sqrt(var(batch) + epsilon) + beta`, where:\n\n- `epsilon` is small constant (configurable as part of the constructor\narguments)\n- `gamma` is a learned scaling factor (initialized as 1), which\ncan be disabled by passing `scale=False` to the constructor.\n- `beta` is a learned offset factor (initialized as 0), which\ncan be disabled by passing `center=False` to the constructor.\n\n**During inference** (i.e. when using `evaluate()` or `predict()` or when\ncalling the layer/model with the argument `training=False` (which is the\ndefault), the layer normalizes its output using a moving average of the\nmean and standard deviation of the batches it has seen during training. That\nis to say, it returns\n`gamma * (batch - self.moving_mean) / sqrt(self.moving_var+epsilon) + beta`.\n\n`self.moving_mean` and `self.moving_var` are non-trainable variables that\nare updated each time the layer in called in training mode, as such:\n\n- `moving_mean = moving_mean * momentum + mean(batch) * (1 - momentum)`\n- `moving_var = moving_var * momentum + var(batch) * (1 - momentum)`\n\nAs such, the layer will only normalize its inputs during inference\n*after having been trained on data that has similar statistics as the\ninference data*.",
    "attributes": [
      {
        "default": -1,
        "description": "Integer, the axis that should be normalized\n        (typically the features axis). For instance, after a `Conv2D` layer\n        with `data_format=\"channels_first\"`, use `axis=1`.",
        "name": "axis"
      },
      {
        "default": 0.001,
        "description": "Small float added to variance to avoid dividing by zero.",
        "name": "epsilon"
      },
      {
        "default": 0.99,
        "description": "Momentum for the moving average.",
        "name": "momentum"
      },
      {
        "default": true,
        "description": "If `True`, multiply by `gamma`. If `False`, `gamma` is not used.\n        When the next layer is linear this can be disabled\n        since the scaling will be done by the next layer.",
        "name": "scale",
        "type": "boolean"
      },
      {
        "default": true,
        "description": "If `True`, add offset of `beta` to normalized tensor.\n        If `False`, `beta` is ignored.",
        "name": "center",
        "type": "boolean"
      },
      {
        "default": {
          "class_name": "Ones",
          "config": {}
        },
        "description": "Initializer for the gamma weight.",
        "name": "gamma_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "Zeros",
          "config": {}
        },
        "description": "Initializer for the moving mean.",
        "name": "moving_mean_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "Ones",
          "config": {}
        },
        "description": "Initializer for the moving variance.",
        "name": "moving_variance_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "Zeros",
          "config": {}
        },
        "description": "Initializer for the beta weight.",
        "name": "beta_initializer",
        "visible": false
      },
      {
        "description": "Optional regularizer for the beta weight.",
        "name": "beta_regularizer",
        "visible": false
      },
      {
        "description": "Optional regularizer for the gamma weight.",
        "name": "gamma_regularizer",
        "visible": false
      },
      {
        "description": "Optional constraint for the beta weight.",
        "name": "beta_constraint"
      },
      {
        "description": "Optional constraint for the gamma weight.",
        "name": "gamma_constraint"
      },
      {
        "description": "Whether to use [Batch Renormalization](\n    https://arxiv.org/abs/1702.03275). This adds extra variables during\n      training. The inference is the same for either value of this parameter.",
        "name": "renorm"
      },
      {
        "description": "A dictionary that may map keys 'rmax', 'rmin', 'dmax' to\n    scalar `Tensors` used to clip the renorm correction. The correction `(r,\n    d)` is used as `corrected_value = normalized_value * r + d`, with `r`\n    clipped to [rmin, rmax], and `d` to [-dmax, dmax]. Missing rmax, rmin,\n    dmax are set to inf, 0, inf, respectively.",
        "name": "renorm_clipping"
      },
      {
        "description": "Momentum used to update the moving means and standard\n    deviations with renorm. Unlike `momentum`, this affects training and\n    should be neither too small (which would add noise) nor too large (which\n    would give stale estimates). Note that `momentum` is still applied to get\n    the means and variances for inference.",
        "name": "renorm_momentum"
      },
      {
        "description": "if `True`, use a faster, fused implementation, or raise a ValueError\n    if the fused implementation cannot be used. If `None`, use the faster\n    implementation if possible. If False, do not used the fused\n    implementation.",
        "name": "fused"
      },
      {
        "description": "Boolean, if `True` the variables will be marked as trainable.",
        "name": "trainable"
      },
      {
        "description": "An `int`. By default, `virtual_batch_size` is `None`,\n    which means batch normalization is performed across the whole batch. When\n    `virtual_batch_size` is not `None`, instead perform \"Ghost Batch\n    Normalization\", which creates virtual sub-batches which are each\n    normalized separately (with shared gamma, beta, and moving statistics).\n    Must divide the actual batch size during execution.",
        "name": "virtual_batch_size"
      },
      {
        "description": "A function taking the `Tensor` containing the (dynamic) shape of\n    the input tensor and returning a pair (scale, bias) to apply to the\n    normalized values (before gamma and beta), only during training. For\n    example, if axis==-1,\n      `adjustment = lambda shape: (\n        tf.random.uniform(shape[-1:], 0.93, 1.07),\n        tf.random.uniform(shape[-1:], -0.1, 0.1))` will scale the normalized\n          value by up to 7% up or down, then shift the result by up to 0.1\n          (with independent scaling and bias for each feature but shared\n          across all examples), and finally apply gamma and/or beta. If\n          `None`, no adjustment is applied. Cannot be specified if\n          virtual_batch_size is specified.",
        "name": "adjustment"
      },
      {
        "name": "synchronized",
        "description": "Only applicable with the TensorFlow backend.\n        If `True`, synchronizes the global batch statistics (mean and\n        variance) for the layer across all devices at each training step\n        in a distributed training strategy.\n        If `False`, each replica uses its own local batch statistics."
      },
      {
        "name": "**kwargs",
        "description": "Base layer keyword arguments (e.g. `name` and `dtype`)."
      }
    ],
    "inputs": [
      {
        "description": "Arbitrary. Use the keyword argument `input_shape` (tuple of\nintegers, does not include the samples axis) when using this layer as the\nfirst layer in a model.",
        "name": "input"
      },
      {
        "name": "gamma"
      },
      {
        "name": "beta"
      },
      {
        "name": "moving_mean"
      },
      {
        "name": "moving_variance"
      }
    ],
    "outputs": [
      {
        "description": "Same shape as input.\n\nReference:\n  - [Ioffe and Szegedy, 2015](https://arxiv.org/abs/1502.03167).\n\n**About setting `layer.trainable = False` on a `BatchNormalization` layer:**\n\nThe meaning of setting `layer.trainable = False` is to freeze the layer,\ni.e. its internal state will not change during training:\nits trainable weights will not be updated\nduring `fit()` or `train_on_batch()`, and its state updates will not be run.\n\nUsually, this does not necessarily mean that the layer is run in inference\nmode (which is normally controlled by the `training` argument that can\nbe passed when calling a layer). \"Frozen state\" and \"inference mode\"\nare two separate concepts.\n\nHowever, in the case of the `BatchNormalization` layer, **setting\n`trainable = False` on the layer means that the layer will be\nsubsequently run in inference mode** (meaning that it will use\nthe moving mean and the moving variance to normalize the current batch,\nrather than using the mean and variance of the current batch).\n\nThis behavior has been introduced in TensorFlow 2.0, in order\nto enable `layer.trainable = False` to produce the most commonly\nexpected behavior in the convnet fine-tuning use case.\n\nNote that:\n  - Setting `trainable` on an model containing other layers will\n    recursively set the `trainable` value of all inner layers.\n  - If the value of the `trainable`\n    attribute is changed after calling `compile()` on a model,\n    the new value doesn't take effect for this model\n    until `compile()` is called again.",
        "name": "output"
      }
    ],
    "references": [
      {
        "description": "[Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)"
      }
    ]
  },
  {
    "name": "Bidirectional",
    "module": "keras.layers",
    "category": "Wrapper",
    "description": "Bidirectional wrapper for RNNs.",
    "attributes": [
      {
        "default": "concat",
        "description": "Mode by which outputs of the forward and backward RNNs\n        will be combined. One of `{\"sum\", \"mul\", \"concat\", \"ave\", None}`.\n        If `None`, the outputs will not be combined,\n        they will be returned as a list. Defaults to `\"concat\"`.",
        "name": "merge_mode"
      },
      {
        "description": "`keras.layers.RNN` instance, such as\n        `keras.layers.LSTM` or `keras.layers.GRU`.\n        It could also be a `keras.layers.Layer` instance\n        that meets the following criteria:\n        1. Be a sequence-processing layer (accepts 3D+ inputs).\n        2. Have a `go_backwards`, `return_sequences` and `return_state`\n        attribute (with the same semantics as for the `RNN` class).\n        3. Have an `input_spec` attribute.\n        4. Implement serialization via `get_config()` and `from_config()`.\n        Note that the recommended way to create new RNN layers is to write a\n        custom RNN cell and use it with `keras.layers.RNN`, instead of\n        subclassing `keras.layers.Layer` directly.\n        When `return_sequences` is `True`, the output of the masked\n        timestep will be zero regardless of the layer's original\n        `zero_output_for_mask` value.",
        "name": "layer"
      },
      {
        "description": "Initial weights to load in the Bidirectional model\n",
        "name": "weights"
      },
      {
        "description": "Optional `keras.layers.RNN`,\n        or `keras.layers.Layer` instance to be used to handle\n        backwards input processing.\n        If `backward_layer` is not provided, the layer instance passed\n        as the `layer` argument will be used to generate the backward layer\n        automatically.\n        Note that the provided `backward_layer` layer should have properties\n        matching those of the `layer` argument, in particular\n        it should have the same values for `stateful`, `return_states`,\n        `return_sequences`, etc. In addition, `backward_layer`\n        and `layer` should have different `go_backwards` argument values.\n        A `ValueError` will be raised if these requirements are not met.",
        "name": "backward_layer"
      }
    ],
    "inputs": [
      {
        "name": "input"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": "model = Sequential([\n    Input(shape=(5, 10)),\n    Bidirectional(LSTM(10, return_sequences=True),\n    Bidirectional(LSTM(10)),\n    Dense(5, activation=\"softmax\"),\n])\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\n# With custom backward layer\nforward_layer = LSTM(10, return_sequences=True)\nbackward_layer = LSTM(10, activation='relu', return_sequences=True,\n                      go_backwards=True)\nmodel = Sequential([\n    Input(shape=(5, 10)),\n    Bidirectional(forward_layer, backward_layer=backward_layer),\n    Dense(5, activation=\"softmax\"),\n])\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
      }
    ]
  },
  {
    "name": "Concatenate",
    "module": "keras.layers",
    "category": "Tensor",
    "description": "Concatenates a list of inputs.\n\nIt takes as input a list of tensors, all of the same shape except\nfor the concatenation axis, and returns a single tensor that is the\nconcatenation of all inputs.",
    "attributes": [
      {
        "description": "Axis along which to concatenate.",
        "name": "axis"
      },
      {
        "description": "Standard layer keyword arguments.",
        "name": "**kwargs"
      }
    ],
    "inputs": [
      {
        "name": "inputs",
        "list": true
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> x = np.arange(20).reshape(2, 2, 5)\n>>> y = np.arange(20, 30).reshape(2, 1, 5)\n>>> keras.layers.Concatenate(axis=1)([x, y])"
      },
      {
        "summary": "Usage in a Keras model:",
        "code": ">>> x1 = keras.layers.Dense(8)(np.arange(10).reshape(5, 2))\n>>> x2 = keras.layers.Dense(8)(np.arange(10, 20).reshape(5, 2))\n>>> y = keras.layers.Concatenate()([x1, x2])"
      }
    ]
  },
  {
    "name": "Conv1D",
    "module": "keras.layers",
    "category": "Layer",
    "description": "1D convolution layer (e.g. temporal convolution).\n\nThis layer creates a convolution kernel that is convolved with the layer\ninput over a single spatial (or temporal) dimension to produce a tensor of\noutputs. If `use_bias` is True, a bias vector is created and added to the\noutputs. Finally, if `activation` is not `None`, it is applied to the\noutputs as well.",
    "attributes": [
      {
        "default": "linear",
        "description": "Activation function. If `None`, no activation is applied.",
        "name": "activation"
      },
      {
        "default": "valid",
        "description": "string, `\"valid\"`, `\"same\"` or `\"causal\"`(case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input. `\"causal\"` results in causal\n        (dilated) convolutions, e.g. `output[t]` does not depend on\n        `input[t+1:]`. Useful when modeling temporal data where the model\n        should not violate the temporal order.\n        See [WaveNet: A Generative Model for Raw Audio, section2.1](\n        https://arxiv.org/abs/1609.03499).",
        "name": "padding"
      },
      {
        "default": true,
        "description": "bool, if `True`, bias will be added to the output.",
        "name": "use_bias",
        "visible": false
      },
      {
        "default": "channels_last",
        "description": "string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, steps, features)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, steps)`. It defaults to the `image_data_format`\n        value found in your Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.",
        "name": "data_format"
      },
      {
        "default": [
          1
        ],
        "description": "int or tuple/list of 1 integer, specifying the stride length\n        of the convolution. `strides > 1` is incompatible with\n        `dilation_rate > 1`.",
        "name": "strides"
      },
      {
        "default": [
          1
        ],
        "description": "int or tuple/list of 1 integers, specifying the dilation\n        rate to use for dilated convolution.",
        "name": "dilation_rate"
      },
      {
        "default": {
          "class_name": "Zeros",
          "config": {}
        },
        "description": "Initializer for the bias vector. If `None`, the\n        default initializer (`\"zeros\"`) will be used.",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "VarianceScaling",
          "config": {
            "distribution": "uniform",
            "mode": "fan_avg",
            "scale": 1,
            "seed": null
          }
        },
        "description": "Initializer for the convolution kernel. If `None`,\n        the default initializer (`\"glorot_uniform\"`) will be used.",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "description": "int, the dimension of the output space (the number of filters\n        in the convolution).",
        "name": "filters"
      },
      {
        "description": "int or tuple/list of 1 integer, specifying the size of the\n        convolution window.",
        "name": "kernel_size"
      },
      {
        "description": "Optional regularizer for the convolution kernel.",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Optional regularizer for the bias vector.",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Optional regularizer function for the output.",
        "name": "activity_regularizer",
        "visible": false
      },
      {
        "description": "Optional projection function to be applied to the\n        kernel after being updated by an `Optimizer` (e.g. used to implement\n        norm constraints or value constraints for layer weights). The\n        function must take as input the unprojected variable and must return\n        the projected variable (which must have the same shape). Constraints\n        are not safe to use when doing asynchronous distributed training.",
        "name": "kernel_constraint"
      },
      {
        "description": "Optional projection function to be applied to the\n        bias after being updated by an `Optimizer`.",
        "name": "bias_constraint"
      },
      {
        "description": "A positive int specifying the number of groups in which the\n        input is split along the channel axis. Each group is convolved\n        separately with `filters // groups` filters. The output is the\n        concatenation of all the `groups` results along the channel axis.\n        Input channels and `filters` must both be divisible by `groups`.",
        "name": "groups"
      }
    ],
    "inputs": [
      {
        "description": "- If `data_format=\"channels_last\"`:\n    A 3D tensor with shape: `(batch_shape, steps, channels)`\n- If `data_format=\"channels_first\"`:\n    A 3D tensor with shape: `(batch_shape, channels, steps)`",
        "name": "input"
      },
      {
        "name": "kernel"
      },
      {
        "name": "bias"
      }
    ],
    "outputs": [
      {
        "description": "- If `data_format=\"channels_last\"`:\n    A 3D tensor with shape: `(batch_shape, new_steps, filters)`\n- If `data_format=\"channels_first\"`:\n    A 3D tensor with shape: `(batch_shape, filters, new_steps)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> # The inputs are 128-length vectors with 10 timesteps, and the\n>>> # batch size is 4.\n>>> x = np.random.rand(4, 10, 128)\n>>> y = keras.layers.Conv1D(32, 3, activation='relu')(x)\n>>> print(y.shape)\n(4, 8, 32)"
      }
    ]
  },
  {
    "name": "Conv2D",
    "module": "keras.layers",
    "category": "Layer",
    "description": "2D convolution layer.\n\nThis layer creates a convolution kernel that is convolved with the layer\ninput over a single spatial (or temporal) dimension to produce a tensor of\noutputs. If `use_bias` is True, a bias vector is created and added to the\noutputs. Finally, if `activation` is not `None`, it is applied to the\noutputs as well.",
    "attributes": [
      {
        "default": "linear",
        "description": "Activation function. If `None`, no activation is applied.",
        "name": "activation"
      },
      {
        "default": "valid",
        "description": "string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input.",
        "name": "padding"
      },
      {
        "default": true,
        "description": "bool, if `True`, bias will be added to the output.",
        "name": "use_bias",
        "type": "boolean",
        "visible": false
      },
      {
        "default": "channels_last",
        "description": "string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape\n        `(batch_size, channels, height, width)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch_size, channels, height, width)`. It defaults to the\n        `image_data_format` value found in your Keras config file at\n        `~/.keras/keras.json`. If you never set it, then it will be\n        `\"channels_last\"`.",
        "name": "data_format"
      },
      {
        "default": [
          1,
          1
        ],
        "description": "int or tuple/list of 2 integer, specifying the stride length\n        of the convolution. `strides > 1` is incompatible with\n        `dilation_rate > 1`.",
        "name": "strides"
      },
      {
        "default": [
          1,
          1
        ],
        "description": "int or tuple/list of 2 integers, specifying the dilation\n        rate to use for dilated convolution.",
        "name": "dilation_rate"
      },
      {
        "default": {
          "class_name": "Zeros",
          "config": {}
        },
        "description": "Initializer for the bias vector. If `None`, the\n        default initializer (`\"zeros\"`) will be used.",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "VarianceScaling",
          "config": {
            "distribution": "uniform",
            "mode": "fan_avg",
            "scale": 1,
            "seed": null
          }
        },
        "description": "Initializer for the convolution kernel. If `None`,\n        the default initializer (`\"glorot_uniform\"`) will be used.",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "description": "int, the dimension of the output space (the number of filters\n        in the convolution).",
        "name": "filters"
      },
      {
        "description": "int or tuple/list of 2 integer, specifying the size of the\n        convolution window.",
        "name": "kernel_size"
      },
      {
        "description": "Optional regularizer for the convolution kernel.",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Optional regularizer for the bias vector.",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Optional regularizer function for the output.",
        "name": "activity_regularizer",
        "visible": false
      },
      {
        "description": "Optional projection function to be applied to the\n        kernel after being updated by an `Optimizer` (e.g. used to implement\n        norm constraints or value constraints for layer weights). The\n        function must take as input the unprojected variable and must return\n        the projected variable (which must have the same shape). Constraints\n        are not safe to use when doing asynchronous distributed training.",
        "name": "kernel_constraint",
        "visible": false
      },
      {
        "description": "Optional projection function to be applied to the\n        bias after being updated by an `Optimizer`.",
        "name": "bias_constraint",
        "visible": false
      },
      {
        "description": "A positive int specifying the number of groups in which the\n        input is split along the channel axis. Each group is convolved\n        separately with `filters // groups` filters. The output is the\n        concatenation of all the `groups` results along the channel axis.\n        Input channels and `filters` must both be divisible by `groups`.",
        "name": "groups"
      }
    ],
    "inputs": [
      {
        "description": "- If `data_format=\"channels_last\"`:\n    A 4D tensor with shape: `(batch_size, height, width, channels)`\n- If `data_format=\"channels_first\"`:\n    A 4D tensor with shape: `(batch_size, channels, height, width)`",
        "name": "input"
      },
      {
        "name": "kernel"
      },
      {
        "name": "bias"
      }
    ],
    "outputs": [
      {
        "description": "- If `data_format=\"channels_last\"`:\n    A 4D tensor with shape: `(batch_size, new_height, new_width, filters)`\n- If `data_format=\"channels_first\"`:\n    A 4D tensor with shape: `(batch_size, filters, new_height, new_width)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> x = np.random.rand(4, 10, 10, 128)\n>>> y = keras.layers.Conv2D(32, 3, activation='relu')(x)\n>>> print(y.shape)\n(4, 8, 8, 32)"
      }
    ]
  },
  {
    "name": "Conv2DTranspose",
    "module": "keras.layers",
    "category": "Layer",
    "description": "2D transposed convolution layer.\n\nThe need for transposed convolutions generally arise from the desire to use\na transformation going in the opposite direction of a normal convolution,\ni.e., from something that has the shape of the output of some convolution\nto something that has the shape of its input while maintaining a\nconnectivity pattern that is compatible with said convolution.",
    "attributes": [
      {
        "description": "int, the dimension of the output space (the number of filters\n        in the transposed convolution).",
        "name": "filters"
      },
      {
        "description": "int or tuple/list of 1 integer, specifying the size of the\n        transposed convolution window.",
        "name": "kernel_size"
      },
      {
        "description": "int or tuple/list of 1 integer, specifying the stride length\n        of the transposed convolution. `strides > 1` is incompatible with\n        `dilation_rate > 1`.",
        "name": "strides"
      },
      {
        "description": "string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input.",
        "name": "padding"
      },
      {
        "default": "channels_last",
        "description": "string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape\n        `(batch_size, channels, height, width)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch_size, channels, height, width)`. It defaults to the\n        `image_data_format` value found in your Keras config file at\n        `~/.keras/keras.json`. If you never set it, then it will be\n        `\"channels_last\"`.",
        "name": "data_format"
      },
      {
        "description": "int or tuple/list of 1 integers, specifying the dilation\n        rate to use for dilated transposed convolution.",
        "name": "dilation_rate"
      },
      {
        "description": "Activation function. If `None`, no activation is applied.",
        "name": "activation"
      },
      {
        "default": true,
        "description": "bool, if `True`, bias will be added to the output.",
        "name": "use_bias",
        "visible": false
      },
      {
        "default": {
          "class_name": "VarianceScaling",
          "config": {
            "distribution": "uniform",
            "mode": "fan_avg",
            "scale": 1,
            "seed": null
          }
        },
        "description": "Initializer for the convolution kernel. If `None`,\n        the default initializer (`\"glorot_uniform\"`) will be used.",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "Zeros",
          "config": {}
        },
        "description": "Initializer for the bias vector. If `None`, the\n        default initializer (`\"zeros\"`) will be used.",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "description": "Optional regularizer for the convolution kernel.",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Optional regularizer for the bias vector.",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Optional regularizer function for the output.",
        "name": "activity_regularizer",
        "visible": false
      },
      {
        "description": "Optional projection function to be applied to the\n        kernel after being updated by an `Optimizer` (e.g. used to implement\n        norm constraints or value constraints for layer weights). The\n        function must take as input the unprojected variable and must return\n        the projected variable (which must have the same shape). Constraints\n        are not safe to use when doing asynchronous distributed training.",
        "name": "kernel_constraint"
      },
      {
        "description": "Optional projection function to be applied to the\n        bias after being updated by an `Optimizer`.",
        "name": "bias_constraint"
      },
      {
        "description": "An integer or tuple/list of 2 integers,\n    specifying the amount of padding along the height and width\n    of the output tensor.\n    Can be a single integer to specify the same value for all\n    spatial dimensions.\n    The amount of output padding along a given dimension must be\n    lower than the stride along that same dimension.\n    If set to `None` (default), the output shape is inferred.",
        "name": "output_padding"
      }
    ],
    "inputs": [
      {
        "description": "- If `data_format=\"channels_last\"`:\n    A 4D tensor with shape: `(batch_size, height, width, channels)`\n- If `data_format=\"channels_first\"`:\n    A 4D tensor with shape: `(batch_size, channels, height, width)`",
        "name": "input"
      },
      {
        "name": "kernel"
      },
      {
        "name": "bias"
      }
    ],
    "outputs": [
      {
        "description": "- If `data_format=\"channels_last\"`:\n    A 4D tensor with shape: `(batch_size, new_height, new_width, filters)`\n- If `data_format=\"channels_first\"`:\n    A 4D tensor with shape: `(batch_size, filters, new_height, new_width)`",
        "name": "output"
      }
    ],
    "references": [
      {
        "description": "[A guide to convolution arithmetic for deep learning]( https://arxiv.org/abs/1603.07285v1)"
      },
      {
        "description": "[Deconvolutional Networks]( https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf) "
      }
    ],
    "examples": [
      {
        "code": ">>> x = np.random.rand(4, 10, 8, 128)\n>>> y = keras.layers.Conv2DTranspose(32, 2, 2, activation='relu')(x)\n>>> print(y.shape)\n(4, 20, 16, 32)"
      }
    ]
  },
  {
    "name": "Conv3D",
    "module": "keras.layers",
    "category": "Layer",
    "description": "3D convolution layer.\n\nThis layer creates a convolution kernel that is convolved with the layer\ninput over a single spatial (or temporal) dimension to produce a tensor of\noutputs. If `use_bias` is True, a bias vector is created and added to the\noutputs. Finally, if `activation` is not `None`, it is applied to the\noutputs as well.",
    "attributes": [
      {
        "description": "int, the dimension of the output space (the number of filters\n        in the convolution).",
        "name": "filters"
      },
      {
        "description": "int or tuple/list of 3 integer, specifying the size of the\n        convolution window.",
        "name": "kernel_size"
      },
      {
        "description": "int or tuple/list of 3 integer, specifying the stride length\n        of the convolution. `strides > 1` is incompatible with\n        `dilation_rate > 1`.",
        "name": "strides"
      },
      {
        "description": "string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input.",
        "name": "padding"
      },
      {
        "description": "string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape\n        `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`.\n        It defaults to the `image_data_format` value found in your Keras\n        config file at `~/.keras/keras.json`. If you never set it, then it\n        will be `\"channels_last\"`.",
        "name": "data_format"
      },
      {
        "description": "int or tuple/list of 3 integers, specifying the dilation\n        rate to use for dilated convolution.",
        "name": "dilation_rate"
      },
      {
        "description": "Activation function. If `None`, no activation is applied.",
        "name": "activation"
      },
      {
        "default": true,
        "description": "bool, if `True`, bias will be added to the output.",
        "name": "use_bias",
        "visible": false
      },
      {
        "description": "Initializer for the convolution kernel. If `None`,\n        the default initializer (`\"glorot_uniform\"`) will be used.",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "description": "Initializer for the bias vector. If `None`, the\n        default initializer (`\"zeros\"`) will be used.",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "description": "Optional regularizer for the convolution kernel.",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Optional regularizer for the bias vector.",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Optional regularizer function for the output.",
        "name": "activity_regularizer",
        "visible": false
      },
      {
        "description": "Optional projection function to be applied to the\n        kernel after being updated by an `Optimizer` (e.g. used to implement\n        norm constraints or value constraints for layer weights). The\n        function must take as input the unprojected variable and must return\n        the projected variable (which must have the same shape). Constraints\n        are not safe to use when doing asynchronous distributed training.",
        "name": "kernel_constraint"
      },
      {
        "description": "Optional projection function to be applied to the\n        bias after being updated by an `Optimizer`.",
        "name": "bias_constraint"
      },
      {
        "description": "A positive int specifying the number of groups in which the\n        input is split along the channel axis. Each group is convolved\n        separately with `filters // groups` filters. The output is the\n        concatenation of all the `groups` results along the channel axis.\n        Input channels and `filters` must both be divisible by `groups`.",
        "name": "groups"
      }
    ],
    "inputs": [
      {
        "description": "- If `data_format=\"channels_last\"`:\n    5D tensor with shape:\n    `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n- If `data_format=\"channels_first\"`:\n    5D tensor with shape:\n    `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "- If `data_format=\"channels_last\"`:\n    5D tensor with shape:\n    `(batch_size, new_spatial_dim1, new_spatial_dim2, new_spatial_dim3,\n    filters)`\n- If `data_format=\"channels_first\"`:\n    5D tensor with shape:\n    `(batch_size, filters, new_spatial_dim1, new_spatial_dim2,\n    new_spatial_dim3)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> x = np.random.rand(4, 10, 10, 10, 128)\n>>> y = keras.layers.Conv3D(32, 3, activation='relu')(x)\n>>> print(y.shape)\n(4, 8, 8, 8, 32)"
      }
    ]
  },
  {
    "name": "ConvLSTM2D",
    "module": "keras.layers",
    "description": "2D Convolutional LSTM.\n\nSimilar to an LSTM layer, but the input transformations\nand recurrent transformations are both convolutional.",
    "attributes": [
      {
        "description": "int, the dimension of the output space (the number of filters\n        in the convolution).",
        "name": "filters"
      },
      {
        "description": "int or tuple/list of 2 integers, specifying the size of the\n        convolution window.",
        "name": "kernel_size"
      },
      {
        "description": "int or tuple/list of 2 integers, specifying the stride length\n        of the convolution. `strides > 1` is incompatible with\n        `dilation_rate > 1`.",
        "name": "strides"
      },
      {
        "description": "string, `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input.",
        "name": "padding"
      },
      {
        "default": "channels_last",
        "description": "string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, steps, features)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, steps)`. It defaults to the `image_data_format`\n        value found in your Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.",
        "name": "data_format"
      },
      {
        "description": "int or tuple/list of 2 integers, specifying the dilation\n        rate to use for dilated convolution.",
        "name": "dilation_rate"
      },
      {
        "description": "Activation function to use. By default hyperbolic tangent\n        activation function is applied (`tanh(x)`).",
        "name": "activation"
      },
      {
        "description": "Activation function to use for the recurrent step.",
        "name": "recurrent_activation"
      },
      {
        "default": true,
        "description": "Boolean, whether the layer uses a bias vector.",
        "name": "use_bias",
        "visible": false
      },
      {
        "description": "Initializer for the `kernel` weights matrix,\n        used for the linear transformation of the inputs.",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "description": "Initializer for the `recurrent_kernel` weights\n        matrix, used for the linear transformation of the recurrent state.",
        "name": "recurrent_initializer",
        "visible": false
      },
      {
        "description": "Initializer for the bias vector.",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "description": "Boolean. If `True`, add 1 to the bias of the forget\n        gate at initialization.\n        Use in combination with `bias_initializer=\"zeros\"`.\n        This is recommended in [Jozefowicz et al., 2015](\n        http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)",
        "name": "unit_forget_bias"
      },
      {
        "description": "Regularizer function applied to the `kernel` weights\n        matrix.",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the\n        `recurrent_kernel` weights matrix.",
        "name": "recurrent_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the bias vector.",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to.",
        "name": "activity_regularizer",
        "visible": false
      },
      {
        "description": "Constraint function applied to the `kernel` weights\n        matrix.",
        "name": "kernel_constraint",
        "visible": false
      },
      {
        "description": "Constraint function applied to the\n        `recurrent_kernel` weights matrix.",
        "name": "recurrent_constraint",
        "visible": false
      },
      {
        "description": "Constraint function applied to the bias vector.",
        "name": "bias_constraint",
        "visible": false
      },
      {
        "description": "Boolean. Whether to return the last output\n        in the output sequence, or the full sequence. Default: `False`.",
        "name": "return_sequences"
      },
      {
        "description": "Boolean (default: `False`).\n        If `True`, process the input sequence backwards and return the\n        reversed sequence.",
        "name": "go_backwards"
      },
      {
        "description": "Boolean (default False). If `True`, the last state\n        for each sample at index i in a batch will be used as initial\n        state for the sample of index i in the following batch.",
        "name": "stateful"
      },
      {
        "default": 0,
        "description": "Float between 0 and 1. Fraction of the units to drop for the\n        linear transformation of the inputs.",
        "name": "dropout"
      },
      {
        "description": "Float between 0 and 1. Fraction of the units to drop\n        for the linear transformation of the recurrent state.",
        "name": "recurrent_dropout"
      },
      {
        "description": "Boolean. Whether to return the last state in addition\n        to the output. Default: `False`.",
        "name": "return_state"
      },
      {
        "name": "seed",
        "description": "Random seed for dropout."
      },
      {
        "name": "unroll",
        "description": "Boolean (default: `False`).\n        If `True`, the network will be unrolled,\n        else a symbolic loop will be used.\n        Unrolling can speed-up a RNN,\n        although it tends to be more memory-intensive.\n        Unrolling is only suitable for short sequences."
      }
    ],
    "inputs": [
      {
        "description": "- If `data_format='channels_first'`:\n    5D tensor with shape: `(samples, time, channels, rows, cols)`\n- If `data_format='channels_last'`:\n    5D tensor with shape: `(samples, time, rows, cols, channels)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "- If `return_state`: a list of tensors. The first tensor is the output.\n    The remaining tensors are the last states,\n    each 4D tensor with shape: `(samples, filters, new_rows, new_cols)` if\n    `data_format='channels_first'`\n    or shape: `(samples, new_rows, new_cols, filters)` if\n    `data_format='channels_last'`. `rows` and `cols` values might have\n    changed due to padding.\n- If `return_sequences`: 5D tensor with shape: `(samples, timesteps,\n    filters, new_rows, new_cols)` if data_format='channels_first'\n    or shape: `(samples, timesteps, new_rows, new_cols, filters)` if\n    `data_format='channels_last'`.\n- Else, 4D tensor with shape: `(samples, filters, new_rows, new_cols)` if\n    `data_format='channels_first'`\n    or shape: `(samples, new_rows, new_cols, filters)` if\n    `data_format='channels_last'`.",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": "steps = 10\nheight = 32\nwidth = 32\ninput_channels = 3\noutput_channels = 6\n\ninputs = tf.keras.Input(shape=(steps, height, width, input_channels))\nlayer = tf.keras.layers.ConvLSTM2D(filters=output_channels, kernel_size=3)\noutputs = layer(inputs)"
      }
    ],
    "references": [
      {
        "description": " "
      },
      {
        "description": "[Shi et al., 2015](http://arxiv.org/abs/1506.04214v1) (the current implementation does not include the feedback loop on the cells output)."
      }
    ]
  },
  {
    "name": "Convolution2D",
    "module": "keras.layers",
    "category": "Layer",
    "description": "2D convolution layer.\n\nThis layer creates a convolution kernel that is convolved with the layer\ninput over a single spatial (or temporal) dimension to produce a tensor of\noutputs. If `use_bias` is True, a bias vector is created and added to the\noutputs. Finally, if `activation` is not `None`, it is applied to the\noutputs as well.",
    "attributes": [
      {
        "default": "linear",
        "description": "Activation function. If `None`, no activation is applied.",
        "name": "activation"
      },
      {
        "default": "valid",
        "description": "string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input.",
        "name": "padding"
      },
      {
        "default": true,
        "description": "bool, if `True`, bias will be added to the output.",
        "name": "use_bias",
        "visible": false
      },
      {
        "default": "channels_last",
        "description": "string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape\n        `(batch_size, channels, height, width)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch_size, channels, height, width)`. It defaults to the\n        `image_data_format` value found in your Keras config file at\n        `~/.keras/keras.json`. If you never set it, then it will be\n        `\"channels_last\"`.",
        "name": "data_format"
      },
      {
        "default": [
          1,
          1
        ],
        "description": "int or tuple/list of 2 integer, specifying the stride length\n        of the convolution. `strides > 1` is incompatible with\n        `dilation_rate > 1`.",
        "name": "strides"
      },
      {
        "default": [
          1,
          1
        ],
        "description": "int or tuple/list of 2 integers, specifying the dilation\n        rate to use for dilated convolution.",
        "name": "dilation_rate"
      },
      {
        "default": 1,
        "name": "depth_multiplier"
      },
      {
        "default": {
          "class_name": "Zeros",
          "config": {}
        },
        "description": "Initializer for the bias vector. If `None`, the\n        default initializer (`\"zeros\"`) will be used.",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "VarianceScaling",
          "config": {
            "distribution": "uniform",
            "mode": "fan_avg",
            "scale": 1,
            "seed": null
          }
        },
        "description": "Initializer for the convolution kernel. If `None`,\n        the default initializer (`\"glorot_uniform\"`) will be used.",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "description": "int, the dimension of the output space (the number of filters\n        in the convolution).",
        "name": "filters"
      },
      {
        "description": "int or tuple/list of 2 integer, specifying the size of the\n        convolution window.",
        "name": "kernel_size"
      },
      {
        "description": "Optional regularizer for the convolution kernel.",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Optional regularizer for the bias vector.",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Optional regularizer function for the output.",
        "name": "activity_regularizer",
        "visible": false
      },
      {
        "description": "Optional projection function to be applied to the\n        kernel after being updated by an `Optimizer` (e.g. used to implement\n        norm constraints or value constraints for layer weights). The\n        function must take as input the unprojected variable and must return\n        the projected variable (which must have the same shape). Constraints\n        are not safe to use when doing asynchronous distributed training.",
        "name": "kernel_constraint"
      },
      {
        "description": "Optional projection function to be applied to the\n        bias after being updated by an `Optimizer`.",
        "name": "bias_constraint"
      },
      {
        "description": "A positive int specifying the number of groups in which the\n        input is split along the channel axis. Each group is convolved\n        separately with `filters // groups` filters. The output is the\n        concatenation of all the `groups` results along the channel axis.\n        Input channels and `filters` must both be divisible by `groups`.",
        "name": "groups"
      }
    ],
    "inputs": [
      {
        "description": "- If `data_format=\"channels_last\"`:\n    A 4D tensor with shape: `(batch_size, height, width, channels)`\n- If `data_format=\"channels_first\"`:\n    A 4D tensor with shape: `(batch_size, channels, height, width)`",
        "name": "input"
      },
      {
        "name": "kernel"
      },
      {
        "name": "bias"
      }
    ],
    "outputs": [
      {
        "description": "- If `data_format=\"channels_last\"`:\n    A 4D tensor with shape: `(batch_size, new_height, new_width, filters)`\n- If `data_format=\"channels_first\"`:\n    A 4D tensor with shape: `(batch_size, filters, new_height, new_width)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> x = np.random.rand(4, 10, 10, 128)\n>>> y = keras.layers.Conv2D(32, 3, activation='relu')(x)\n>>> print(y.shape)\n(4, 8, 8, 32)"
      }
    ]
  },
  {
    "name": "Cropping1D",
    "module": "keras.layers",
    "category": "Shape",
    "description": "Cropping layer for 1D input (e.g. temporal sequence).\n\nIt crops along the time dimension (axis 1).",
    "attributes": [
      {
        "description": "Int, or tuple of int (length 2), or dictionary.\n        - If int: how many units should be trimmed off at the beginning and\n          end of the cropping dimension (axis 1).\n        - If tuple of 2 ints: how many units should be trimmed off at the\n          beginning and end of the cropping dimension\n          (`(left_crop, right_crop)`).",
        "name": "cropping"
      }
    ],
    "inputs": [
      {
        "description": "3D tensor with shape `(batch_size, axis_to_crop, features)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "3D tensor with shape `(batch_size, cropped_axis, features)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> input_shape = (2, 3, 2)\n>>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n>>> x\n[[[ 0  1]\n  [ 2  3]\n  [ 4  5]]\n [[ 6  7]\n  [ 8  9]\n  [10 11]]]\n>>> y = keras.layers.Cropping1D(cropping=1)(x)\n>>> y\n[[[2 3]]\n [[8 9]]]"
      }
    ]
  },
  {
    "name": "Cropping2D",
    "module": "keras.layers",
    "category": "Shape",
    "description": "Cropping layer for 2D input (e.g. picture).\n\nIt crops along spatial dimensions, i.e. height and width.",
    "attributes": [
      {
        "description": "Int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n        - If int: the same symmetric cropping is applied to height and\n          width.\n        - If tuple of 2 ints: interpreted as two different symmetric\n          cropping values for height and width:\n          `(symmetric_height_crop, symmetric_width_crop)`.\n        - If tuple of 2 tuples of 2 ints: interpreted as\n          `((top_crop, bottom_crop), (left_crop, right_crop))`.",
        "name": "cropping"
      },
      {
        "description": "A string, one of `\"channels_last\"` (default) or\n        `\"channels_first\"`. The ordering of the dimensions in the inputs.\n        `\"channels_last\"` corresponds to inputs with shape\n        `(batch_size, height, width, channels)` while `\"channels_first\"`\n        corresponds to inputs with shape\n        `(batch_size, channels, height, width)`.\n        When unspecified, uses `image_data_format` value found in your Keras\n        config file at `~/.keras/keras.json` (if exists). Defaults to\n        `\"channels_last\"`.",
        "name": "data_format"
      }
    ],
    "inputs": [
      {
        "description": "4D tensor with shape:\n- If `data_format` is `\"channels_last\"`:\n  `(batch_size, height, width, channels)`\n- If `data_format` is `\"channels_first\"`:\n  `(batch_size, channels, height, width)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "4D tensor with shape:\n- If `data_format` is `\"channels_last\"`:\n  `(batch_size, cropped_height, cropped_width, channels)`\n- If `data_format` is `\"channels_first\"`:\n  `(batch_size, channels, cropped_height, cropped_width)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> input_shape = (2, 28, 28, 3)\n>>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n>>> y = keras.layers.Cropping2D(cropping=((2, 2), (4, 4)))(x)\n>>> y.shape\n(2, 24, 20, 3)"
      }
    ]
  },
  {
    "name": "Cropping3D",
    "module": "keras.layers",
    "category": "Shape",
    "description": "Cropping layer for 3D data (e.g. spatial or spatio-temporal).",
    "attributes": [
      {
        "description": "Int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.\n        - If int: the same symmetric cropping is applied to depth, height,\n          and width.\n        - If tuple of 3 ints: interpreted as three different symmetric\n          cropping values for depth, height, and width:\n          `(symmetric_dim1_crop, symmetric_dim2_crop, symmetric_dim3_crop)`.\n        - If tuple of 3 tuples of 2 ints: interpreted as\n          `((left_dim1_crop, right_dim1_crop), (left_dim2_crop,\n          right_dim2_crop), (left_dim3_crop, right_dim3_crop))`.",
        "name": "cropping"
      },
      {
        "description": "A string, one of `\"channels_last\"` (default) or\n        `\"channels_first\"`. The ordering of the dimensions in the inputs.\n        `\"channels_last\"` corresponds to inputs with shape\n        `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n        When unspecified, uses `image_data_format` value found in your Keras\n        config file at `~/.keras/keras.json` (if exists). Defaults to\n        `\"channels_last\"`.",
        "name": "data_format"
      }
    ],
    "inputs": [
      {
        "description": "5D tensor with shape:\n- If `data_format` is `\"channels_last\"`:\n  `(batch_size, first_axis_to_crop, second_axis_to_crop,\n  third_axis_to_crop, channels)`\n- If `data_format` is `\"channels_first\"`:\n  `(batch_size, channels, first_axis_to_crop, second_axis_to_crop,\n  third_axis_to_crop)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "5D tensor with shape:\n- If `data_format` is `\"channels_last\"`:\n  `(batch_size, first_cropped_axis, second_cropped_axis,\n  third_cropped_axis, channels)`\n- If `data_format` is `\"channels_first\"`:\n  `(batch_size, channels, first_cropped_axis, second_cropped_axis,\n  third_cropped_axis)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> input_shape = (2, 28, 28, 10, 3)\n>>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n>>> y = keras.layers.Cropping3D(cropping=(2, 4, 2))(x)\n>>> y.shape\n(2, 24, 20, 6, 3)"
      }
    ]
  },
  {
    "name": "CuDNNGRU",
    "description": "Fast GRU implementation backed by [CuDNN](https://developer.nvidia.com/cudnn).\n\nCan only be run on GPU, with the TensorFlow backend.\n",
    "attributes": [
      {
        "description": "Positive integer, dimensionality of the output space.",
        "name": "units"
      },
      {
        "description": "Initializer for the `kernel` weights matrix,\n    used for the linear transformation of the inputs.\n    (see [initializers](https://keras.io/initializers)).",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "description": "Initializer for the `recurrent_kernel`\n    weights matrix,\n    used for the linear transformation of the recurrent state.\n    (see [initializers](https://keras.io/initializers)).",
        "name": "recurrent_initializer",
        "visible": false
      },
      {
        "description": "Initializer for the bias vector\n    (see [initializers](https://keras.io/initializers)).",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to\n    the `kernel` weights matrix\n    (see [regularizer](https://keras.io/regularizers)).",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to\n    the `recurrent_kernel` weights matrix\n    (see [regularizer](https://keras.io/regularizers)).",
        "name": "recurrent_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the bias vector\n    (see [regularizer](https://keras.io/regularizers)).",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to\n    the output of the layer (its \"activation\").\n    (see [regularizer](https://keras.io/regularizers)).",
        "name": "activity_regularizer",
        "visible": false
      },
      {
        "description": "Constraint function applied to\n    the `kernel` weights matrix\n    (see [constraints](https://keras.io/constraints)).",
        "name": "kernel_constraint"
      },
      {
        "description": "Constraint function applied to\n    the `recurrent_kernel` weights matrix\n    (see [constraints](https://keras.io/constraints)).",
        "name": "recurrent_constraint"
      },
      {
        "description": "Constraint function applied to the bias vector\n    (see [constraints](https://keras.io/constraints)).",
        "name": "bias_constraint"
      },
      {
        "description": "Boolean. Whether to return the last output.\n    in the output sequence, or the full sequence.",
        "name": "return_sequences"
      },
      {
        "description": "Boolean. Whether to return the last state\n    in addition to the output.",
        "name": "return_state"
      },
      {
        "description": "Boolean (default False). If True, the last state\n    for each sample at index i in a batch will be used as initial\n    state for the sample of index i in the following batch.\n",
        "name": "stateful"
      }
    ]
  },
  {
    "name": "CuDNNLSTM",
    "description": "Fast LSTM implementation with [CuDNN](https://developer.nvidia.com/cudnn).\n\nCan only be run on GPU, with the TensorFlow backend.\n",
    "attributes": [
      {
        "description": "Positive integer, dimensionality of the output space.",
        "name": "units"
      },
      {
        "description": "Initializer for the `kernel` weights matrix,\n    used for the linear transformation of the inputs.\n    (see [initializers](https://keras.io/initializers)).",
        "name": "kernel_initializer"
      },
      {
        "description": "Initializer for the `recurrent_kernel`\n    weights matrix,\n    used for the linear transformation of the recurrent state.\n    (see [initializers](https://keras.io/initializers)).",
        "name": "recurrent_initializer"
      },
      {
        "description": "Initializer for the bias vector\n    (see [initializers](https://keras.io/initializers)).",
        "name": "bias_initializer"
      },
      {
        "description": "Boolean.\n    If True, add 1 to the bias of the forget gate at initialization.\n    Setting it to true will also force `bias_initializer=\"zeros\"`.\n    This is recommended in [Jozefowicz et al. (2015)](\n    http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).",
        "name": "unit_forget_bias"
      },
      {
        "description": "Regularizer function applied to\n    the `kernel` weights matrix\n    (see [regularizer](https://keras.io/regularizers)).",
        "name": "kernel_regularizer"
      },
      {
        "description": "Regularizer function applied to\n    the `recurrent_kernel` weights matrix\n    (see [regularizer](https://keras.io/regularizers)).",
        "name": "recurrent_regularizer"
      },
      {
        "description": "Regularizer function applied to the bias vector\n    (see [regularizer](https://keras.io/regularizers)).",
        "name": "bias_regularizer"
      },
      {
        "description": "Regularizer function applied to\n    the output of the layer (its \"activation\").\n    (see [regularizer](https://keras.io/regularizers)).",
        "name": "activity_regularizer"
      },
      {
        "description": "Constraint function applied to\n    the `kernel` weights matrix\n    (see [constraints](https://keras.io/constraints)).",
        "name": "kernel_constraint"
      },
      {
        "description": "Constraint function applied to\n    the `recurrent_kernel` weights matrix\n    (see [constraints](https://keras.io/constraints)).",
        "name": "recurrent_constraint"
      },
      {
        "description": "Constraint function applied to the bias vector\n    (see [constraints](https://keras.io/constraints)).",
        "name": "bias_constraint"
      },
      {
        "description": "Boolean. Whether to return the last output.\n    in the output sequence, or the full sequence.",
        "name": "return_sequences"
      },
      {
        "description": "Boolean. Whether to return the last state\n    in addition to the output.",
        "name": "return_state"
      },
      {
        "description": "Boolean (default False). If True, the last state\n    for each sample at index i in a batch will be used as initial\n    state for the sample of index i in the following batch.\n",
        "name": "stateful"
      }
    ]
  },
  {
    "name": "Dense",
    "module": "keras.layers",
    "category": "Layer",
    "description": "Just your regular densely-connected NN layer.\n\n`Dense` implements the operation:\n`output = activation(dot(input, kernel) + bias)`\nwhere `activation` is the element-wise activation function\npassed as the `activation` argument, `kernel` is a weights matrix\ncreated by the layer, and `bias` is a bias vector created by the layer\n(only applicable if `use_bias` is `True`).\n\nNote: If the input to the layer has a rank greater than 2, `Dense`\ncomputes the dot product between the `inputs` and the `kernel` along the\nlast axis of the `inputs` and axis 0 of the `kernel` (using `tf.tensordot`).\nFor example, if input has dimensions `(batch_size, d0, d1)`, then we create\na `kernel` with shape `(d1, units)`, and the `kernel` operates along axis 2\nof the `input`, on every sub-tensor of shape `(1, 1, d1)` (there are\n`batch_size * d0` such sub-tensors). The output in this case will have\nshape `(batch_size, d0, units)`.",
    "attributes": [
      {
        "description": "Positive integer, dimensionality of the output space.",
        "name": "units"
      },
      {
        "default": "linear",
        "description": "Activation function to use.\n        If you don't specify anything, no activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).",
        "name": "activation"
      },
      {
        "default": true,
        "description": "Boolean, whether the layer uses a bias vector.",
        "name": "use_bias",
        "type": "boolean"
      },
      {
        "default": {
          "class_name": "VarianceScaling",
          "config": {
            "distribution": "uniform",
            "mode": "fan_avg",
            "scale": 1,
            "seed": null
          }
        },
        "description": "Initializer for the `kernel` weights matrix.",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "Zeros",
          "config": {}
        },
        "description": "Initializer for the bias vector.",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to\n        the `kernel` weights matrix.",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the bias vector.",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to\n        the output of the layer (its \"activation\").",
        "name": "activity_regularizer",
        "visible": false
      },
      {
        "description": "Constraint function applied to\n        the `kernel` weights matrix.",
        "name": "kernel_constraint"
      },
      {
        "description": "Constraint function applied to the bias vector.",
        "name": "bias_constraint"
      }
    ],
    "inputs": [
      {
        "description": "N-D tensor with shape: `(batch_size, ..., input_dim)`.\nThe most common situation would be\na 2D input with shape `(batch_size, input_dim)`.",
        "name": "input",
        "type": "T"
      },
      {
        "name": "kernel",
        "type": "T"
      },
      {
        "name": "bias",
        "type": "T"
      }
    ],
    "outputs": [
      {
        "description": "N-D tensor with shape: `(batch_size, ..., units)`.\nFor instance, for a 2D input with shape `(batch_size, input_dim)`,\nthe output would have shape `(batch_size, units)`.",
        "name": "output",
        "type": "T"
      }
    ],
    "examples": [
      {
        "code": ">>> # Create a `Sequential` model and add a Dense layer as the first layer.\n>>> model = tf.keras.models.Sequential()\n>>> model.add(tf.keras.Input(shape=(16,)))\n>>> model.add(tf.keras.layers.Dense(32, activation='relu'))\n>>> # Now the model will take as input arrays of shape (None, 16)\n>>> # and output arrays of shape (None, 32).\n>>> # Note that after the first layer, you don't need to specify\n>>> # the size of the input anymore:\n>>> model.add(tf.keras.layers.Dense(32))\n>>> model.output_shape\n(None, 32)"
      }
    ]
  },
  {
    "name": "DepthwiseConv2D",
    "category": "Layer",
    "attributes": [
      {
        "default": "linear",
        "name": "activation"
      },
      {
        "default": "valid",
        "name": "padding"
      },
      {
        "default": true,
        "name": "use_bias",
        "type": "boolean",
        "visible": false
      },
      {
        "default": "channels_last",
        "name": "data_format"
      },
      {
        "default": [
          1,
          1
        ],
        "name": "strides"
      },
      {
        "default": [
          1,
          1
        ],
        "name": "dilation_rate"
      },
      {
        "default": {
          "class_name": "Zeros",
          "config": {}
        },
        "name": "bias_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "VarianceScaling",
          "config": {
            "distribution": "uniform",
            "mode": "fan_avg",
            "scale": 1,
            "seed": null
          }
        },
        "name": "depthwise_initializer",
        "visible": false
      },
      {
        "default": 1,
        "name": "depth_multiplier"
      }
    ],
    "inputs": [
      {
        "name": "input"
      },
      {
        "name": "kernel"
      },
      {
        "name": "bias"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ]
  },
  {
    "name": "Dot",
    "module": "keras.layers",
    "description": "Computes element-wise dot product of two tensors.\n\nIt takes a list of inputs of size 2, and the axes\ncorresponding to each input along with the dot product\nis to be performed.\n\nLet's say `x` and `y` are the two input tensors with shapes\n`(2, 3, 5)` and `(2, 10, 3)`. The batch dimension should be\nof same size for both the inputs, and `axes` should correspond\nto the dimensions that have the same size in the corresponding\ninputs. e.g. with `axes=(1, 2)`, the dot product of `x`, and `y`\nwill result in a tensor with shape `(2, 5, 10)`",
    "attributes": [
      {
        "description": "Integer or tuple of integers, axis or axes along which to\n        take the dot product. If a tuple, should be two integers\n        corresponding to the desired axis from the first input and the\n        desired axis from the second input, respectively. Note that the\n        size of the two selected axes must match.",
        "name": "axes"
      },
      {
        "description": "Whether to L2-normalize samples along the dot product axis\n        before taking the dot product. If set to `True`, then\n        the output of the dot product is the cosine proximity\n        between the two samples.",
        "name": "normalize"
      },
      {
        "description": "Standard layer keyword arguments.",
        "name": "**kwargs"
      }
    ],
    "inputs": [
      {
        "name": "x"
      },
      {
        "name": "y"
      }
    ],
    "outputs": [
      {
        "name": "z"
      }
    ],
    "examples": [
      {
        "code": ">>> x = np.arange(10).reshape(1, 5, 2)\n>>> y = np.arange(10, 20).reshape(1, 2, 5)\n>>> keras.layers.Dot(axes=(1, 2))([x, y])"
      },
      {
        "summary": "Usage in a Keras model:",
        "code": ">>> x1 = keras.layers.Dense(8)(np.arange(10).reshape(5, 2))\n>>> x2 = keras.layers.Dense(8)(np.arange(10, 20).reshape(5, 2))\n>>> y = keras.layers.Dot(axes=1)([x1, x2])"
      }
    ]
  },
  {
    "name": "Dropout",
    "module": "keras.layers",
    "category": "Dropout",
    "description": "Applies dropout to the input.\n\nThe `Dropout` layer randomly sets input units to 0 with a frequency of\n`rate` at each step during training time, which helps prevent overfitting.\nInputs not set to 0 are scaled up by `1 / (1 - rate)` such that the sum over\nall inputs is unchanged.\n\nNote that the `Dropout` layer only applies when `training` is set to `True`\nin `call()`, such that no values are dropped during inference.\nWhen using `model.fit`, `training` will be appropriately set to `True`\nautomatically. In other contexts, you can set the argument explicitly\nto `True` when calling the layer.\n\n(This is in contrast to setting `trainable=False` for a `Dropout` layer.\n`trainable` does not affect the layer's behavior, as `Dropout` does\nnot have any variables/weights that can be frozen during training.)",
    "attributes": [
      {
        "description": "Float between 0 and 1. Fraction of the input units to drop.",
        "name": "rate"
      },
      {
        "description": "1D integer tensor representing the shape of the\n        binary dropout mask that will be multiplied with the input.\n        For instance, if your inputs have shape\n        `(batch_size, timesteps, features)` and\n        you want the dropout mask to be the same for all timesteps,\n        you can use `noise_shape=(batch_size, 1, features)`.",
        "name": "noise_shape"
      },
      {
        "description": "A Python integer to use as random seed.",
        "name": "seed"
      }
    ],
    "inputs": [
      {
        "name": "input"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ],
    "references": [
      {
        "description": "[Dropout: A Simple Way to Prevent Neural Networks from Overfitting]( http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)"
      }
    ]
  },
  {
    "name": "ELU",
    "module": "keras.layers",
    "category": "Activation",
    "description": "Applies an Exponential Linear Unit function to an output.\n\nFormula:\n\n```\nf(x) = alpha * (exp(x) - 1.) for x < 0\nf(x) = x for x >= 0\n```",
    "attributes": [
      {
        "description": "float, slope of negative section. Defaults to `1.0`.",
        "name": "alpha"
      },
      {
        "name": "**kwargs",
        "description": "Base layer keyword arguments, such as `name` and `dtype`."
      }
    ],
    "inputs": [
      {
        "description": "Arbitrary. Use the keyword argument `input_shape`\n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "Same shape as the input.",
        "name": "output"
      }
    ],
    "references": [
      {
        "description": "[Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)](https://arxiv.org/abs/1511.07289v1)"
      }
    ]
  },
  {
    "name": "Embedding",
    "module": "keras.layers",
    "category": "Transform",
    "description": "Turns positive integers (indexes) into dense vectors of fixed size.\n\ne.g. `[[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]`\n\nThis layer can only be used on positive integer inputs of a fixed range.",
    "attributes": [
      {
        "default": false,
        "description": "Boolean, whether or not the input value 0 is a special\n        \"padding\" value that should be masked out.\n        This is useful when using recurrent layers which\n        may take variable length input. If this is `True`,\n        then all subsequent layers in the model need\n        to support masking or an exception will be raised.\n        If mask_zero is set to True, as a consequence,\n        index 0 cannot be used in the vocabulary (input_dim should\n        equal size of vocabulary + 1).",
        "name": "mask_zero"
      },
      {
        "default": {
          "class_name": "RandomUniform",
          "config": {
            "maxval": 0.05,
            "minval": -0.05,
            "seed": null
          }
        },
        "description": "Initializer for the `embeddings`\n        matrix (see `keras.initializers`).",
        "name": "embeddings_initializer",
        "visible": false
      },
      {
        "description": "Integer. Size of the vocabulary,\n        i.e. maximum integer index + 1.",
        "name": "input_dim"
      },
      {
        "description": "Integer. Dimension of the dense embedding.",
        "name": "output_dim"
      },
      {
        "description": "Regularizer function applied to\n        the `embeddings` matrix (see `keras.regularizers`).",
        "name": "embeddings_regularizer",
        "visible": false
      },
      {
        "description": "Constraint function applied to\n        the `embeddings` matrix (see `keras.constraints`).",
        "name": "embeddings_constraint"
      },
      {
        "description": "Length of input sequences, when it is constant.\n    This argument is required if you are going to connect\n    `Flatten` then `Dense` layers upstream\n    (without it, the shape of the dense outputs cannot be computed).",
        "name": "input_length"
      },
      {
        "description": "Regularizer function applied to\n    the output of the layer (its \"activation\").\n    (see [regularizer](https://keras.io/regularizers)).",
        "name": "activity_regularizer"
      },
      {
        "name": "sparse",
        "description": "If True, calling this layer returns a `tf.SparseTensor`. If False,\n    the layer returns a dense `tf.Tensor`. For an entry with no features in\n    a sparse tensor (entry with value 0), the embedding vector of index 0 is\n    returned by default."
      }
    ],
    "inputs": [
      {
        "description": "2D tensor with shape: `(batch_size, input_length)`.",
        "name": "input"
      },
      {
        "name": "embeddings"
      }
    ],
    "outputs": [
      {
        "description": "3D tensor with shape: `(batch_size, input_length, output_dim)`.",
        "name": "output"
      }
    ],
    "references": [
      {
        "description": "[A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](http://arxiv.org/abs/1512.05287)"
      }
    ],
    "examples": [
      {
        "code": ">>> model = keras.Sequential()\n>>> model.add(keras.layers.Embedding(1000, 64, input_length=10))\n>>> # The model will take as input an integer matrix of size (batch,\n>>> # input_length), and the largest integer (i.e. word index) in the input\n>>> # should be no larger than 999 (vocabulary size).\n>>> # Now model.output_shape is (None, 10, 64), where `None` is the batch\n>>> # dimension.\n>>> input_array = np.random.randint(1000, size=(32, 10))\n>>> model.compile('rmsprop', 'mse')\n>>> output_array = model.predict(input_array)\n>>> print(output_array.shape)\n(32, 10, 64)"
      }
    ]
  },
  {
    "name": "Flatten",
    "module": "keras.layers",
    "category": "Shape",
    "description": "Flattens the input. Does not affect the batch size.\n\nNote: If inputs are shaped `(batch,)` without a feature axis, then\nflattening adds an extra channel dimension and output shape is `(batch, 1)`.",
    "attributes": [
      {
        "default": "channels_last",
        "description": "A string, one of `\"channels_last\"` (default) or\n        `\"channels_first\"`. The ordering of the dimensions in the inputs.\n        `\"channels_last\"` corresponds to inputs with shape\n        `(batch, ..., channels)` while `\"channels_first\"` corresponds to\n        inputs with shape `(batch, channels, ...)`.\n        When unspecified, uses `image_data_format` value found in your Keras\n        config file at `~/.keras/keras.json` (if exists). Defaults to\n        `\"channels_last\"`.",
        "name": "data_format"
      }
    ],
    "inputs": [
      {
        "name": "input"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> x = keras.Input(shape=(10, 64))\n>>> y = keras.layers.Flatten()(x)\n>>> y.shape\n(None, 640)"
      }
    ]
  },
  {
    "name": "GlobalAveragePooling1D",
    "module": "keras.layers",
    "category": "Pool",
    "description": "Global average pooling operation for temporal data.",
    "attributes": [
      {
        "description": "string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, steps, features)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, steps)`. It defaults to the `image_data_format`\n        value found in your Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.",
        "name": "data_format"
      },
      {
        "name": "keepdims",
        "description": "A boolean, whether to keep the temporal dimension or not.\n        If `keepdims` is `False` (default), the rank of the tensor is\n        reduced for spatial dimensions. If `keepdims` is `True`, the\n        temporal dimension are retained with length 1.\n        The behavior is the same as for `tf.reduce_mean` or `np.mean`."
      }
    ],
    "inputs": [
      {
        "description": "- If `data_format='channels_last'`:\n    3D tensor with shape:\n    `(batch_size, steps, features)`\n- If `data_format='channels_first'`:\n    3D tensor with shape:\n    `(batch_size, features, steps)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "- If `keepdims=False`:\n    2D tensor with shape `(batch_size, features)`.\n- If `keepdims=True`:\n    - If `data_format=\"channels_last\"`:\n        3D tensor with shape `(batch_size, 1, features)`\n    - If `data_format=\"channels_first\"`:\n        3D tensor with shape `(batch_size, features, 1)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> x = np.random.rand(2, 3, 4)\n>>> y = keras.layers.GlobalAveragePooling1D()(x)\n>>> y.shape\n(2, 4)"
      }
    ]
  },
  {
    "name": "GlobalAveragePooling2D",
    "module": "keras.layers",
    "category": "Pool",
    "description": "Global average pooling operation for 2D data.",
    "attributes": [
      {
        "default": "channels_last",
        "description": "string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, height, width, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, height, weight)`. It defaults to the\n        `image_data_format` value found in your Keras config file at\n        `~/.keras/keras.json`. If you never set it, then it will be\n        `\"channels_last\"`.",
        "name": "data_format"
      },
      {
        "name": "keepdims",
        "description": "A boolean, whether to keep the temporal dimension or not.\n        If `keepdims` is `False` (default), the rank of the tensor is\n        reduced for spatial dimensions. If `keepdims` is `True`, the\n        spatial dimension are retained with length 1.\n        The behavior is the same as for `tf.reduce_mean` or `np.mean`."
      }
    ],
    "inputs": [
      {
        "description": "- If `data_format='channels_last'`:\n    4D tensor with shape:\n    `(batch_size, height, width, channels)`\n- If `data_format='channels_first'`:\n    4D tensor with shape:\n    `(batch_size, channels, height, width)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "- If `keepdims=False`:\n    2D tensor with shape `(batch_size, channels)`.\n- If `keepdims=True`:\n    - If `data_format=\"channels_last\"`:\n        4D tensor with shape `(batch_size, 1, 1, channels)`\n    - If `data_format=\"channels_first\"`:\n        4D tensor with shape `(batch_size, channels, 1, 1)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> x = np.random.rand(2, 4, 5, 3)\n>>> y = keras.layers.GlobalAveragePooling2D()(x)\n>>> y.shape\n(2, 3)"
      }
    ]
  },
  {
    "name": "GlobalMaxPooling1D",
    "module": "keras.layers",
    "category": "Pool",
    "description": "Global max pooling operation for temporal data.",
    "attributes": [
      {
        "description": "string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, steps, features)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, steps)`. It defaults to the `image_data_format`\n        value found in your Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.",
        "name": "data_format"
      },
      {
        "name": "keepdims",
        "description": "A boolean, whether to keep the temporal dimension or not.\n        If `keepdims` is `False` (default), the rank of the tensor is\n        reduced for spatial dimensions. If `keepdims` is `True`, the\n        temporal dimension are retained with length 1.\n        The behavior is the same as for `tf.reduce_mean` or `np.mean`."
      }
    ],
    "inputs": [
      {
        "description": "- If `data_format='channels_last'`:\n    3D tensor with shape:\n    `(batch_size, steps, features)`\n- If `data_format='channels_first'`:\n    3D tensor with shape:\n    `(batch_size, features, steps)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "- If `keepdims=False`:\n    2D tensor with shape `(batch_size, features)`.\n- If `keepdims=True`:\n    - If `data_format=\"channels_last\"`:\n        3D tensor with shape `(batch_size, 1, features)`\n    - If `data_format=\"channels_first\"`:\n        3D tensor with shape `(batch_size, features, 1)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> x = np.random.rand(2, 3, 4)\n>>> y = keras.layers.GlobalMaxPooling1D()(x)\n>>> y.shape\n(2, 4)"
      }
    ]
  },
  {
    "name": "GlobalMaxPooling2D",
    "module": "keras.layers",
    "category": "Pool",
    "description": "Global max pooling operation for 2D data.",
    "attributes": [
      {
        "default": "channels_last",
        "description": "string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, height, width, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, height, weight)`. It defaults to the\n        `image_data_format` value found in your Keras config file at\n        `~/.keras/keras.json`. If you never set it, then it will be\n        `\"channels_last\"`.",
        "name": "data_format"
      },
      {
        "name": "keepdims",
        "description": "A boolean, whether to keep the temporal dimension or not.\n        If `keepdims` is `False` (default), the rank of the tensor is\n        reduced for spatial dimensions. If `keepdims` is `True`, the\n        spatial dimension are retained with length 1.\n        The behavior is the same as for `tf.reduce_mean` or `np.mean`."
      }
    ],
    "inputs": [
      {
        "description": "- If `data_format='channels_last'`:\n    4D tensor with shape:\n    `(batch_size, height, width, channels)`\n- If `data_format='channels_first'`:\n    4D tensor with shape:\n    `(batch_size, channels, height, width)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "- If `keepdims=False`:\n    2D tensor with shape `(batch_size, channels)`.\n- If `keepdims=True`:\n    - If `data_format=\"channels_last\"`:\n        4D tensor with shape `(batch_size, 1, 1, channels)`\n    - If `data_format=\"channels_first\"`:\n        4D tensor with shape `(batch_size, channels, 1, 1)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> x = np.random.rand(2, 4, 5, 3)\n>>> y = keras.layers.GlobalMaxPooling2D()(x)\n>>> y.shape\n(2, 3)"
      }
    ]
  },
  {
    "name": "GRU",
    "module": "keras.layers",
    "category": "Layer",
    "description": "Gated Recurrent Unit - Cho et al. 2014.\n\nBased on available runtime hardware and constraints, this layer\nwill choose different implementations (cuDNN-based or backend-native)\nto maximize the performance. If a GPU is available and all\nthe arguments to the layer meet the requirement of the cuDNN kernel\n(see below for details), the layer will use a fast cuDNN implementation\nwhen using the TensorFlow backend.\n\nThe requirements to use the cuDNN implementation are:\n\n1. `activation` == `tanh`\n2. `recurrent_activation` == `sigmoid`\n3. `dropout` == 0 and `recurrent_dropout` == 0\n4. `unroll` is `False`\n5. `use_bias` is `True`\n6. `reset_after` is `True`\n7. Inputs, if use masking, are strictly right-padded.\n8. Eager execution is enabled in the outermost context.\n\nThere are two variants of the GRU implementation. The default one is based\non [v3](https://arxiv.org/abs/1406.1078v3) and has reset gate applied to\nhidden state before matrix multiplication. The other one is based on\n[original](https://arxiv.org/abs/1406.1078v1) and has the order reversed.\n\nThe second variant is compatible with CuDNNGRU (GPU-only) and allows\ninference on CPU. Thus it has separate biases for `kernel` and\n`recurrent_kernel`. To use this variant, set `reset_after=True` and\n`recurrent_activation='sigmoid'`.\n\nFor example:\n\n```\n>>> inputs = np.random.random((32, 10, 8))\n>>> gru = keras.layers.GRU(4)\n>>> output = gru(inputs)\n>>> output.shape\n(32, 4)\n>>> gru = keras.layers.GRU(4, return_sequences=True, return_state=True)\n>>> whole_sequence_output, final_state = gru(inputs)\n>>> whole_sequence_output.shape\n(32, 10, 4)\n>>> final_state.shape\n(32, 4)\n```",
    "attributes": [
      {
        "default": "tanh",
        "description": "Activation function to use.\n        Default: hyperbolic tangent (`tanh`).\n        If you pass `None`, no activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).",
        "name": "activation"
      },
      {
        "default": "hard_sigmoid",
        "description": "Activation function to use\n        for the recurrent step.\n        Default: sigmoid (`sigmoid`).\n        If you pass `None`, no activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).",
        "name": "recurrent_activation"
      },
      {
        "default": true,
        "description": "Boolean, (default `True`), whether the layer\n        should use a bias vector.",
        "name": "use_bias",
        "visible": false
      },
      {
        "default": {
          "class_name": "VarianceScaling",
          "config": {
            "distribution": "uniform",
            "mode": "fan_avg",
            "scale": 1,
            "seed": null
          }
        },
        "description": "Initializer for the `kernel` weights matrix,\n        used for the linear transformation of the inputs. Default:\n        `\"glorot_uniform\"`.",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "Orthogonal",
          "config": {
            "gain": 1,
            "seed": null
          }
        },
        "description": "Initializer for the `recurrent_kernel`\n        weights matrix, used for the linear transformation of the recurrent\n        state. Default: `\"orthogonal\"`.",
        "name": "recurrent_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "Zeros",
          "config": {}
        },
        "description": "Initializer for the bias vector. Default: `\"zeros\"`.",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "default": 0,
        "description": "Float between 0 and 1. Fraction of the units to drop for the\n        linear transformation of the inputs. Default: 0.",
        "name": "dropout"
      },
      {
        "default": 1,
        "description": "Implementation mode, either 1 or 2.\n    Mode 1 will structure its operations as a larger number of\n    smaller dot products and additions, whereas mode 2 will\n    batch them into fewer, larger operations. These modes will\n    have different performance profiles on different hardware and\n    for different applications. Default: 2.",
        "name": "implementation"
      },
      {
        "default": false,
        "description": "Boolean. Whether to return the last output\n        in the output sequence, or the full sequence. Default: `False`.",
        "name": "return_sequences"
      },
      {
        "default": false,
        "description": "Boolean. Whether to return the last state in addition\n        to the output. Default: `False`.",
        "name": "return_state"
      },
      {
        "default": false,
        "description": "Boolean (default `False`).\n        If `True`, process the input sequence backwards and return the\n        reversed sequence.",
        "name": "go_backwards"
      },
      {
        "default": false,
        "description": "Boolean (default: `False`). If `True`, the last state\n        for each sample at index i in a batch will be used as initial\n        state for the sample of index i in the following batch.",
        "name": "stateful"
      },
      {
        "default": false,
        "description": "Boolean (default: `False`).\n        If `True`, the network will be unrolled,\n        else a symbolic loop will be used.\n        Unrolling can speed-up a RNN,\n        although it tends to be more memory-intensive.\n        Unrolling is only suitable for short sequences.",
        "name": "unroll"
      },
      {
        "description": "Positive integer, dimensionality of the output space.",
        "name": "units"
      },
      {
        "description": "Regularizer function applied to the `kernel` weights\n        matrix. Default: `None`.",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the\n        `recurrent_kernel` weights matrix. Default: `None`.",
        "name": "recurrent_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the bias vector.\n        Default: `None`.",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the output of the\n        layer (its \"activation\"). Default: `None`.",
        "name": "activity_regularizer",
        "visible": false
      },
      {
        "description": "Constraint function applied to the `kernel` weights\n        matrix. Default: `None`.",
        "name": "kernel_constraint"
      },
      {
        "description": "Constraint function applied to the\n        `recurrent_kernel` weights matrix. Default: `None`.",
        "name": "recurrent_constraint"
      },
      {
        "description": "Constraint function applied to the bias vector.\n        Default: `None`.",
        "name": "bias_constraint"
      },
      {
        "description": "Float between 0 and 1. Fraction of the units to drop\n        for the linear transformation of the recurrent state. Default: 0.",
        "name": "recurrent_dropout"
      },
      {
        "description": "`None`.",
        "name": "Default"
      },
      {
        "description": "GRU convention (whether to apply reset gate after or\n        before matrix multiplication). `False` is `\"before\"`,\n        `True` is `\"after\"` (default and cuDNN compatible).",
        "name": "reset_after"
      },
      {
        "description": "The shape format of the `inputs` and `outputs` tensors.\n    If True, the inputs and outputs will be in shape\n    `[timesteps, batch, feature]`, whereas in the False case, it will be\n    `[batch, timesteps, feature]`. Using `time_major = True` is a bit more\n    efficient because it avoids transposes at the beginning and end of the\n    RNN calculation. However, most TensorFlow data is batch-major, so by\n    default this function accepts input and emits output in batch-major\n    form.",
        "name": "time_major"
      },
      {
        "name": "seed",
        "description": "Random seed for dropout."
      }
    ],
    "inputs": [
      {
        "name": "input"
      },
      {
        "name": "kernel"
      },
      {
        "name": "recurrent_kernel"
      },
      {
        "name": "bias"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ],
    "references": [
      {
        "description": "[Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](https://arxiv.org/abs/1406.1078)"
      },
      {
        "description": "[On the Properties of Neural Machine Translation: Encoder-Decoder Approaches](https://arxiv.org/abs/1409.1259)"
      },
      {
        "description": "[Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling](https://arxiv.org/abs/1412.3555v1)"
      },
      {
        "description": "[A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](https://arxiv.org/abs/1512.05287)"
      }
    ]
  },
  {
    "name": "GRUCell",
    "module": "keras.layers",
    "description": "Cell class for the GRU layer.\n\nThis class processes one step within the whole time sequence input, whereas\n`keras.layer.GRU` processes the whole sequence.",
    "attributes": [
      {
        "description": "Positive integer, dimensionality of the output space.",
        "name": "units"
      },
      {
        "description": "Activation function to use. Default: hyperbolic tangent\n        (`tanh`). If you pass None, no activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).",
        "name": "activation"
      },
      {
        "description": "Activation function to use for the recurrent step.\n        Default: sigmoid (`sigmoid`). If you pass `None`, no activation is\n        applied (ie. \"linear\" activation: `a(x) = x`).",
        "name": "recurrent_activation"
      },
      {
        "default": true,
        "description": "Boolean, (default `True`), whether the layer\n        should use a bias vector.",
        "name": "use_bias",
        "visible": false
      },
      {
        "description": "Initializer for the `kernel` weights matrix,\n        used for the linear transformation of the inputs. Default:\n        `\"glorot_uniform\"`.",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "description": "Initializer for the `recurrent_kernel`\n        weights matrix, used for the linear transformation\n        of the recurrent state. Default: `\"orthogonal\"`.",
        "name": "recurrent_initializer",
        "visible": false
      },
      {
        "description": "Initializer for the bias vector. Default: `\"zeros\"`.",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the `kernel` weights\n        matrix. Default: `None`.",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the\n        `recurrent_kernel` weights matrix. Default: `None`.",
        "name": "recurrent_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the bias vector.\n        Default: `None`.",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Constraint function applied to the `kernel` weights\n        matrix. Default: `None`.",
        "name": "kernel_constraint"
      },
      {
        "description": "Constraint function applied to the\n        `recurrent_kernel` weights matrix. Default: `None`.",
        "name": "recurrent_constraint"
      },
      {
        "description": "Constraint function applied to the bias vector.\n        Default: `None`.",
        "name": "bias_constraint"
      },
      {
        "default": 0,
        "description": "Float between 0 and 1. Fraction of the units to drop for the\n        linear transformation of the inputs. Default: 0.",
        "name": "dropout"
      },
      {
        "default": 0,
        "description": "Float between 0 and 1. Fraction of the units to drop\n        for the linear transformation of the recurrent state. Default: 0.",
        "name": "recurrent_dropout"
      },
      {
        "description": "Implementation mode, either 1 or 2.\n    Mode 1 will structure its operations as a larger number of\n    smaller dot products and additions, whereas mode 2 (default) will\n    batch them into fewer, larger operations. These modes will\n    have different performance profiles on different hardware and\n    for different applications. Default: 2.",
        "name": "implementation"
      },
      {
        "description": "`None`.",
        "name": "Default"
      },
      {
        "description": "GRU convention (whether to apply reset gate after or\n        before matrix multiplication). False = \"before\",\n        True = \"after\" (default and cuDNN compatible).",
        "name": "reset_after"
      },
      {
        "name": "seed",
        "description": "Random seed for dropout."
      }
    ],
    "examples": [
      {
        "code": ">>> inputs = np.random.random((32, 10, 8))\n>>> rnn = keras.layers.RNN(keras.layers.GRUCell(4))\n>>> output = rnn(inputs)\n>>> output.shape\n(32, 4)\n>>> rnn = keras.layers.RNN(\n...    keras.layers.GRUCell(4),\n...    return_sequences=True,\n...    return_state=True)\n>>> whole_sequence_output, final_state = rnn(inputs)\n>>> whole_sequence_output.shape\n(32, 10, 4)\n>>> final_state.shape\n(32, 4)"
      }
    ]
  },
  {
    "name": "HardSigmoid",
    "category": "Activation"
  },
  {
    "name": "InputLayer",
    "module": "keras.layers",
    "category": "Data",
    "description": "Layer to be used as an entry point into a Network (a graph of layers).\n\nIt can either wrap an existing tensor (pass an `input_tensor` argument)\nor create a placeholder tensor (pass arguments `input_shape`, and\noptionally, `dtype`).\n\nIt is generally recommend to use the Keras Functional model via `Input`,\n(which creates an `InputLayer`) without directly using `InputLayer`.\n\nWhen using `InputLayer` with the Keras Sequential model, it can be skipped\nby moving the `input_shape` parameter to the first layer after the\n`InputLayer`.\n\nThis class can create placeholders for `tf.Tensors`, `tf.SparseTensors`, and\n`tf.RaggedTensors` by choosing `sparse=True` or `ragged=True`. Note that\n`sparse` and `ragged` can't be configured to `True` at the same time.",
    "attributes": [
      {
        "description": "Shape tuple (not including the batch axis), or\n        `TensorShape` instance (not including the batch axis).",
        "name": "input_shape"
      },
      {
        "description": "Optional input batch size (integer or `None`).",
        "name": "batch_size"
      },
      {
        "description": "Optional datatype of the input. When not provided, the Keras\n        default `float` type will be used.",
        "name": "dtype"
      },
      {
        "description": "Optional tensor to use as layer input. If set, the layer\n        will use the `tf.TypeSpec` of this tensor rather\n        than creating a new placeholder tensor.",
        "name": "input_tensor"
      },
      {
        "description": "Boolean, whether the placeholder created is meant to be sparse.\n        Defaults to `False`.",
        "name": "sparse"
      },
      {
        "description": "Boolean, whether the placeholder created is meant to be ragged.\n        In this case, values of `None` in the `shape` argument represent\n        ragged dimensions. For more information about `tf.RaggedTensor`, see\n        [this guide](https://www.tensorflow.org/guide/ragged_tensor).\n        Defaults to `False`.",
        "name": "ragged"
      },
      {
        "description": "Optional name of the layer (string).",
        "name": "name"
      },
      {
        "description": "A `tf.TypeSpec` object to create Input from. This\n        `tf.TypeSpec` represents the entire batch. When provided, all other\n        args except name must be `None`.",
        "name": "type_spec"
      }
    ],
    "examples": [
      {
        "code": "# With explicit InputLayer.\nmodel = tf.keras.Sequential([\n  tf.keras.layers.InputLayer(input_shape=(4,)),\n  tf.keras.layers.Dense(8)])\nmodel.compile(tf.keras.optimizers.RMSprop(0.001), loss='mse')\nmodel.fit(np.zeros((10, 4)),\n          np.ones((10, 8)))\n\n# Without InputLayer and let the first layer to have the input_shape.\n# Keras will add a input for the model behind the scene.\nmodel = tf.keras.Sequential([\n  tf.keras.layers.Dense(8, input_shape=(4,))])\nmodel.compile(tf.keras.optimizers.RMSprop(0.001), loss='mse')\nmodel.fit(np.zeros((10, 4)),\n          np.ones((10, 8)))"
      }
    ]
  },
  {
    "name": "InputSpec",
    "module": "keras.layers",
    "category": "Data",
    "description": "Specifies the rank, dtype and shape of every input to a layer.\n\nLayers can expose (if appropriate) an `input_spec` attribute:\nan instance of `InputSpec`, or a nested structure of `InputSpec` instances\n(one per input tensor). These objects enable the layer to run input\ncompatibility checks for input structure, input rank, input shape, and\ninput dtype for the first argument of `Layer.__call__`.\n\nA `None` entry in a shape is compatible with any dimension.",
    "attributes": [
      {
        "description": "Expected DataType of the input.",
        "name": "dtype"
      },
      {
        "description": "Shape tuple, expected shape of the input\n        (may include None for unchecked axes). Includes the batch size.",
        "name": "shape"
      },
      {
        "description": "Integer, expected rank of the input.",
        "name": "ndim"
      },
      {
        "description": "Integer, maximum rank of the input.",
        "name": "max_ndim"
      },
      {
        "description": "Integer, minimum rank of the input.",
        "name": "min_ndim"
      },
      {
        "description": "Dictionary mapping integer axes to\n        a specific dimension value.",
        "name": "axes"
      },
      {
        "description": "If True, then allow inputs of rank N+1 as long\n        as the last axis of the input is 1, as well as inputs of rank N-1\n        as long as the last axis of the spec is 1.",
        "name": "allow_last_axis_squeeze"
      },
      {
        "description": "Expected key corresponding to this input when passing data as\n        a dictionary.",
        "name": "name"
      }
    ],
    "examples": [
      {
        "code": "class MyLayer(Layer):\n    def __init__(self):\n        super(MyLayer, self).__init__()\n        # The layer will accept inputs with\n        # shape (*, 28, 28) & (*, 28, 28, 1)\n        # and raise an appropriate error message otherwise.\n        self.input_spec = InputSpec(\n            shape=(None, 28, 28, 1),\n            allow_last_axis_squeeze=True)"
      }
    ]
  },
  {
    "name": "Lambda",
    "module": "keras.layers",
    "description": "Wraps arbitrary expressions as a `Layer` object.\n\nThe `Lambda` layer exists so that arbitrary expressions can be used\nas a `Layer` when constructing Sequential\nand Functional API models. `Lambda` layers are best suited for simple\noperations or quick experimentation. For more advanced use cases,\nprefer writing new subclasses of `Layer`.\n\nWARNING: `Lambda` layers have (de)serialization limitations!\n\nThe main reason to subclass `Layer` instead of using a\n`Lambda` layer is saving and inspecting a model. `Lambda` layers\nare saved by serializing the Python bytecode, which is fundamentally\nnon-portable and potentially unsafe.\nThey should only be loaded in the same environment where\nthey were saved. Subclassed layers can be saved in a more portable way\nby overriding their `get_config()` method. Models that rely on\nsubclassed Layers are also often easier to visualize and reason about.",
    "attributes": [
      {
        "description": "The function to be evaluated. Takes input tensor as first\n        argument.",
        "name": "function"
      },
      {
        "description": "Expected output shape from function. This argument\n        can usually be inferred if not explicitly provided.\n        Can be a tuple or function. If a tuple, it only specifies\n        the first dimension onward; sample dimension is assumed\n        either the same as the input:\n        `output_shape = (input_shape[0], ) + output_shape` or,\n        the input is `None` and the sample dimension is also `None`:\n        `output_shape = (None, ) + output_shape`.\n        If a function, it specifies the\n        entire shape as a function of the input shape:\n        `output_shape = f(input_shape)`.",
        "name": "output_shape"
      },
      {
        "description": "Optional dictionary of keyword arguments to be passed to the\n        function.",
        "name": "arguments"
      },
      {
        "description": "Either None (indicating no masking) or a callable with the same\n        signature as the `compute_mask` layer method, or a tensor\n        that will be returned as output mask regardless\n        of what the input is.",
        "name": "mask"
      }
    ],
    "inputs": [
      {
        "description": "Arbitrary. Use the keyword argument input_shape (tuple of\nintegers, does not include the samples axis) when using this layer as the\nfirst layer in a model.",
        "name": "inputs",
        "list": true
      }
    ],
    "outputs": [
      {
        "description": "Specified by `output_shape` argument",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": "# add a x -> x^2 layer\nmodel.add(Lambda(lambda x: x ** 2))"
      }
    ]
  },
  {
    "name": "LeakyReLU",
    "module": "keras.layers",
    "category": "Activation",
    "description": "Leaky version of a Rectified Linear Unit activation layer.\n\nThis layer allows a small gradient when the unit is not active.\n\nFormula:\n\n``` python\nf(x) = alpha * x if x < 0\nf(x) = x if x >= 0\n```",
    "attributes": [
      {
        "description": "Float >= `0.`. Negative slope coefficient. Defaults to `0.3`.",
        "name": "alpha"
      },
      {
        "name": "negative_slope",
        "description": "Float >= 0.0. Negative slope coefficient.\n      Defaults to `0.3`."
      },
      {
        "name": "**kwargs",
        "description": "Base layer keyword arguments, such as\n        `name` and `dtype`."
      }
    ],
    "inputs": [
      {
        "description": "Arbitrary. Use the keyword argument `input_shape`\n(tuple of integers, does not include the batch axis)\nwhen using this layer as the first layer in a model.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "Same shape as the input.",
        "name": "output"
      }
    ],
    "references": [
      {
        "description": "[Rectifier Nonlinearities Improve Neural Network Acoustic Models]( https://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf)"
      }
    ],
    "examples": [
      {
        "code": "leaky_relu_layer = LeakyReLU(negative_slope=0.5)\ninput = np.array([-10, -5, 0.0, 5, 10])\nresult = leaky_relu_layer(input)\n# result = [-5. , -2.5,  0. ,  5. , 10.]"
      }
    ]
  },
  {
    "name": "LocallyConnected1D",
    "module": "keras.layers",
    "category": "Layer",
    "description": "Locally-connected layer for 1D inputs.\n\nThe `LocallyConnected1D` layer works similarly to\nthe `Conv1D` layer, except that weights are unshared,\nthat is, a different set of filters is applied at each different patch\nof the input.\n\nNote: layer attributes cannot be modified after the layer has been called\nonce (except the `trainable` attribute).",
    "attributes": [
      {
        "description": "Integer, the dimensionality of the output space (i.e. the\n      number of output filters in the convolution).",
        "name": "filters"
      },
      {
        "description": "An integer or tuple/list of a single integer, specifying\n      the length of the 1D convolution window.",
        "name": "kernel_size"
      },
      {
        "description": "An integer or tuple/list of a single integer, specifying the\n      stride length of the convolution.",
        "name": "strides"
      },
      {
        "description": "Currently only supports `\"valid\"` (case-insensitive). `\"same\"`\n      may be supported in the future. `\"valid\"` means no padding.",
        "name": "padding"
      },
      {
        "description": "Activation function to use. If you don't specify anything,\n      no activation is applied (ie. \"linear\" activation: `a(x) = x`).",
        "name": "activation"
      },
      {
        "description": "Boolean, whether the layer uses a bias vector.",
        "name": "use_bias"
      },
      {
        "description": "Initializer for the `kernel` weights matrix.",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "description": "Initializer for the bias vector.",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the `kernel` weights\n      matrix.",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the bias vector.",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the output of the\n      layer (its \"activation\")..",
        "name": "activity_regularizer",
        "visible": false
      },
      {
        "description": "Constraint function applied to the kernel matrix.",
        "name": "kernel_constraint"
      },
      {
        "description": "Constraint function applied to the bias vector.",
        "name": "bias_constraint"
      },
      {
        "default": "channels_last",
        "description": "A string, one of `channels_last` (default) or\n      `channels_first`. The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape `(batch, length,\n      channels)` while `channels_first` corresponds to inputs with shape\n      `(batch, channels, length)`. When unspecified, uses\n      `image_data_format` value found in your Keras config file at\n      `~/.keras/keras.json` (if exists) else 'channels_last'.\n      Defaults to 'channels_last'.",
        "name": "data_format"
      },
      {
        "description": "implementation mode, either `1`, `2`, or `3`. `1` loops\n      over input spatial locations to perform the forward pass. It is\n      memory-efficient but performs a lot of (small) ops.  `2` stores layer\n      weights in a dense but sparsely-populated 2D matrix and implements the\n      forward pass as a single matrix-multiply. It uses a lot of RAM but\n      performs few (large) ops.  `3` stores layer weights in a sparse tensor\n      and implements the forward pass as a single sparse matrix-multiply.\n        How to choose:\n        `1`: large, dense models,\n        `2`: small models,\n        `3`: large, sparse models,  where \"large\" stands for large\n          input/output activations (i.e. many `filters`, `input_filters`,\n          large `input_size`, `output_size`), and \"sparse\" stands for few\n          connections between inputs and outputs, i.e. small ratio\n          `filters * input_filters * kernel_size / (input_size * strides)`,\n          where inputs to and outputs of the layer are assumed to have\n          shapes `(input_size, input_filters)`, `(output_size, filters)`\n          respectively.  It is recommended to benchmark each in the setting\n          of interest to pick the most efficient one (in terms of speed and\n          memory usage). Correct choice of implementation can lead to\n          dramatic speed improvements (e.g. 50X), potentially at the expense\n          of RAM.  Also, only `padding=\"valid\"` is supported by\n          `implementation=1`.",
        "name": "implementation"
      }
    ],
    "inputs": [
      {
        "description": "3D tensor with shape: `(batch_size, steps, input_dim)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "3D tensor with shape: `(batch_size, new_steps, filters)` `steps` value\n  might have changed due to padding or strides.",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": "    # apply a unshared weight convolution 1d of length 3 to a sequence with\n    # 10 timesteps, with 64 output filters\n    model = Sequential()\n    model.add(LocallyConnected1D(64, 3, input_shape=(10, 32)))\n    # now model.output_shape == (None, 8, 64)\n    # add a new conv1d on top\n    model.add(LocallyConnected1D(32, 3))\n    # now model.output_shape == (None, 6, 32)"
      }
    ]
  },
  {
    "name": "LocallyConnected2D",
    "module": "keras.layers",
    "category": "Layer",
    "description": "Locally-connected layer for 2D inputs.\n\nThe `LocallyConnected2D` layer works similarly\nto the `Conv2D` layer, except that weights are unshared,\nthat is, a different set of filters is applied at each\ndifferent patch of the input.\n\nNote: layer attributes cannot be modified after the layer has been called\nonce (except the `trainable` attribute).",
    "attributes": [
      {
        "description": "Integer, the dimensionality of the output space (i.e. the\n      number of output filters in the convolution).",
        "name": "filters"
      },
      {
        "description": "An integer or tuple/list of 2 integers, specifying the\n      width and height of the 2D convolution window. Can be a single integer\n      to specify the same value for all spatial dimensions.",
        "name": "kernel_size"
      },
      {
        "description": "An integer or tuple/list of 2 integers, specifying the strides\n      of the convolution along the width and height. Can be a single integer\n      to specify the same value for all spatial dimensions.",
        "name": "strides"
      },
      {
        "description": "Currently only support `\"valid\"` (case-insensitive). `\"same\"`\n      will be supported in future. `\"valid\"` means no padding.",
        "name": "padding"
      },
      {
        "default": "channels_last",
        "description": "A string, one of `channels_last` (default) or\n      `channels_first`. The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape `(batch, height,\n        width, channels)` while `channels_first` corresponds to inputs with\n        shape\n      `(batch, channels, height, width)`. When unspecified, uses\n      `image_data_format` value found in your Keras config file at\n      `~/.keras/keras.json` (if exists) else 'channels_last'.\n      Defaults to 'channels_last'.",
        "name": "data_format"
      },
      {
        "description": "Activation function to use. If you don't specify anything,\n      no activation is applied (ie. \"linear\" activation: `a(x) = x`).",
        "name": "activation"
      },
      {
        "description": "Boolean, whether the layer uses a bias vector.",
        "name": "use_bias",
        "visible": false
      },
      {
        "description": "Initializer for the `kernel` weights matrix.",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "description": "Initializer for the bias vector.",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the `kernel` weights\n      matrix.",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the bias vector.",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the output of the\n      layer (its \"activation\").",
        "name": "activity_regularizer"
      },
      {
        "description": "Constraint function applied to the kernel matrix.",
        "name": "kernel_constraint"
      },
      {
        "description": "Constraint function applied to the bias vector.",
        "name": "bias_constraint"
      },
      {
        "description": "implementation mode, either `1`, `2`, or `3`. `1` loops\n      over input spatial locations to perform the forward pass. It is\n      memory-efficient but performs a lot of (small) ops.  `2` stores layer\n      weights in a dense but sparsely-populated 2D matrix and implements the\n      forward pass as a single matrix-multiply. It uses a lot of RAM but\n      performs few (large) ops.  `3` stores layer weights in a sparse tensor\n      and implements the forward pass as a single sparse matrix-multiply.\n        How to choose:\n        `1`: large, dense models,\n        `2`: small models,\n        `3`: large, sparse models,  where \"large\" stands for large\n          input/output activations (i.e. many `filters`, `input_filters`,\n          large `np.prod(input_size)`, `np.prod(output_size)`), and \"sparse\"\n          stands for few connections between inputs and outputs, i.e. small\n          ratio `filters * input_filters * np.prod(kernel_size) /\n          (np.prod(input_size) * np.prod(strides))`, where inputs to and\n          outputs of the layer are assumed to have shapes `input_size +\n          (input_filters,)`, `output_size + (filters,)` respectively. It is\n          recommended to benchmark each in the setting of interest to pick\n          the most efficient one (in terms of speed and memory usage).\n          Correct choice of implementation can lead to dramatic speed\n          improvements (e.g. 50X), potentially at the expense of RAM. Also,\n          only `padding=\"valid\"` is supported by `implementation=1`.",
        "name": "implementation"
      }
    ],
    "inputs": [
      {
        "description": "4D tensor with shape: `(samples, channels, rows, cols)` if\n  data_format='channels_first'\nor 4D tensor with shape: `(samples, rows, cols, channels)` if\n  data_format='channels_last'.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "4D tensor with shape: `(samples, filters, new_rows, new_cols)` if\n  data_format='channels_first'\nor 4D tensor with shape: `(samples, new_rows, new_cols, filters)` if\n  data_format='channels_last'. `rows` and `cols` values might have\n  changed due to padding.",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": "    # apply a 3x3 unshared weights convolution with 64 output filters on a\n    32x32 image\n    # with `data_format=\"channels_last\"`:\n    model = Sequential()\n    model.add(LocallyConnected2D(64, (3, 3), input_shape=(32, 32, 3)))\n    # now model.output_shape == (None, 30, 30, 64)\n    # notice that this layer will consume (30*30)*(3*3*3*64) + (30*30)*64\n    parameters\n\n    # add a 3x3 unshared weights convolution on top, with 32 output filters:\n    model.add(LocallyConnected2D(32, (3, 3)))\n    # now model.output_shape == (None, 28, 28, 32)"
      }
    ]
  },
  {
    "name": "LSTM",
    "module": "keras.layers",
    "category": "Layer",
    "description": "Long Short-Term Memory layer - Hochreiter 1997.\n\nBased on available runtime hardware and constraints, this layer\nwill choose different implementations (cuDNN-based or backend-native)\nto maximize the performance. If a GPU is available and all\nthe arguments to the layer meet the requirement of the cuDNN kernel\n(see below for details), the layer will use a fast cuDNN implementation\nwhen using the TensorFlow backend.\nThe requirements to use the cuDNN implementation are:\n\n1. `activation` == `tanh`\n2. `recurrent_activation` == `sigmoid`\n3. `dropout` == 0 and `recurrent_dropout` == 0\n4. `unroll` is `False`\n5. `use_bias` is `True`\n6. Inputs, if use masking, are strictly right-padded.\n7. Eager execution is enabled in the outermost context.\n\nFor example:\n\n```\n>>> inputs = np.random.random((32, 10, 8))\n>>> lstm = keras.layers.LSTM(4)\n>>> output = lstm(inputs)\n>>> output.shape\n(32, 4)\n>>> lstm = keras.layers.LSTM(\n...     4, return_sequences=True, return_state=True)\n>>> whole_seq_output, final_memory_state, final_carry_state = lstm(inputs)\n>>> whole_seq_output.shape\n(32, 10, 4)\n>>> final_memory_state.shape\n(32, 4)\n>>> final_carry_state.shape\n(32, 4)\n```",
    "attributes": [
      {
        "description": "Positive integer, dimensionality of the output space.",
        "name": "units"
      },
      {
        "default": "tanh",
        "description": "Activation function to use.\n        Default: hyperbolic tangent (`tanh`).\n        If you pass `None`, no activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).",
        "name": "activation"
      },
      {
        "default": "hard_sigmoid",
        "description": "Activation function to use\n        for the recurrent step.\n        Default: sigmoid (`sigmoid`).\n        If you pass `None`, no activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).",
        "name": "recurrent_activation"
      },
      {
        "description": "Boolean, (default `True`), whether the layer\n        should use a bias vector.",
        "name": "use_bias",
        "visible": false
      },
      {
        "description": "Initializer for the `kernel` weights matrix,\n        used for the linear transformation of the inputs. Default:\n        `\"glorot_uniform\"`.",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "description": "Initializer for the `recurrent_kernel`\n        weights matrix, used for the linear transformation of the recurrent\n        state. Default: `\"orthogonal\"`.",
        "name": "recurrent_initializer",
        "visible": false
      },
      {
        "description": "Initializer for the bias vector. Default: `\"zeros\"`.",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "default": true,
        "description": "Boolean (default `True`). If `True`,\n        add 1 to the bias of the forget gate at initialization.\n        Setting it to `True` will also force `bias_initializer=\"zeros\"`.\n        This is recommended in [Jozefowicz et al.](\n        https://github.com/mlresearch/v37/blob/gh-pages/jozefowicz15.pdf)",
        "name": "unit_forget_bias"
      },
      {
        "description": "Regularizer function applied to the `kernel` weights\n        matrix. Default: `None`.",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the\n        `recurrent_kernel` weights matrix. Default: `None`.",
        "name": "recurrent_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the bias vector.\n        Default: `None`.",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the output of the\n        layer (its \"activation\"). Default: `None`.",
        "name": "activity_regularizer",
        "visible": false
      },
      {
        "description": "Constraint function applied to the `kernel` weights\n        matrix. Default: `None`.",
        "name": "kernel_constraint",
        "visible": false
      },
      {
        "description": "Constraint function applied to the\n        `recurrent_kernel` weights matrix. Default: `None`.",
        "name": "recurrent_constraint",
        "visible": false
      },
      {
        "description": "Constraint function applied to the bias vector.\n        Default: `None`.",
        "name": "bias_constraint",
        "visible": false
      },
      {
        "default": 0,
        "description": "Float between 0 and 1. Fraction of the units to drop for the\n        linear transformation of the inputs. Default: 0.",
        "name": "dropout"
      },
      {
        "default": 0,
        "description": "Float between 0 and 1. Fraction of the units to drop\n        for the linear transformation of the recurrent state. Default: 0.",
        "name": "recurrent_dropout"
      },
      {
        "default": 1,
        "description": "Implementation mode, either 1 or 2. Mode 1 will structure\n    its operations as a larger number of smaller dot products and additions,\n    whereas mode 2 will batch them into fewer, larger operations. These modes\n    will have different performance profiles on different hardware and for\n    different applications. Default: 2.",
        "name": "implementation"
      },
      {
        "default": false,
        "description": "Boolean. Whether to return the last output\n        in the output sequence, or the full sequence. Default: `False`.",
        "name": "return_sequences"
      },
      {
        "default": false,
        "description": "Boolean. Whether to return the last state in addition\n        to the output. Default: `False`.",
        "name": "return_state"
      },
      {
        "default": false,
        "description": "Boolean (default: `False`).\n        If `True`, process the input sequence backwards and return the\n        reversed sequence.",
        "name": "go_backwards"
      },
      {
        "default": false,
        "description": "Boolean (default: `False`). If `True`, the last state\n        for each sample at index i in a batch will be used as initial\n        state for the sample of index i in the following batch.",
        "name": "stateful"
      },
      {
        "default": false,
        "description": "Boolean (default False).\n        If `True`, the network will be unrolled,\n        else a symbolic loop will be used.\n        Unrolling can speed-up a RNN,\n        although it tends to be more memory-intensive.\n        Unrolling is only suitable for short sequences.",
        "name": "unroll"
      },
      {
        "description": "`None`.",
        "name": "Default"
      },
      {
        "description": "The shape format of the `inputs` and `outputs` tensors.\n    If True, the inputs and outputs will be in shape\n    `[timesteps, batch, feature]`, whereas in the False case, it will be\n    `[batch, timesteps, feature]`. Using `time_major = True` is a bit more\n    efficient because it avoids transposes at the beginning and end of the\n    RNN calculation. However, most TensorFlow data is batch-major, so by\n    default this function accepts input and emits output in batch-major\n    form.",
        "name": "time_major"
      },
      {
        "name": "seed",
        "description": "Random seed for dropout."
      }
    ],
    "inputs": [
      {
        "name": "input"
      },
      {
        "name": "kernel"
      },
      {
        "name": "recurrent_kernel"
      },
      {
        "name": "bias"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ],
    "references": [
      {
        "description": "[Long short-term memory](http://www.bioinf.jku.at/publications/older/2604.pdf)"
      },
      {
        "description": "[Learning to forget: Continual prediction with LSTM](http://www.mitpressjournals.org/doi/pdf/10.1162/089976600300015015)"
      },
      {
        "description": "[Supervised sequence labeling with recurrent neural networks](http://www.cs.toronto.edu/~graves/preprint.pdf)"
      },
      {
        "description": "[A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](https://arxiv.org/abs/1512.05287)"
      }
    ]
  },
  {
    "name": "LSTMCell",
    "module": "keras.layers",
    "description": "Cell class for the LSTM layer.\n\nThis class processes one step within the whole time sequence input, whereas\n`keras.layer.LSTM` processes the whole sequence.",
    "attributes": [
      {
        "description": "Positive integer, dimensionality of the output space.",
        "name": "units"
      },
      {
        "description": "Activation function to use. Default: hyperbolic tangent\n        (`tanh`). If you pass None, no activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).",
        "name": "activation"
      },
      {
        "description": "Activation function to use for the recurrent step.\n        Default: sigmoid (`sigmoid`). If you pass `None`, no activation is\n        applied (ie. \"linear\" activation: `a(x) = x`).",
        "name": "recurrent_activation"
      },
      {
        "default": true,
        "description": "Boolean, (default `True`), whether the layer\n        should use a bias vector.",
        "name": "use_bias"
      },
      {
        "description": "Initializer for the `kernel` weights matrix,\n        used for the linear transformation of the inputs. Default:\n        `\"glorot_uniform\"`.",
        "name": "kernel_initializer"
      },
      {
        "description": "Initializer for the `recurrent_kernel`\n        weights matrix, used for the linear transformation\n        of the recurrent state. Default: `\"orthogonal\"`.",
        "name": "recurrent_initializer"
      },
      {
        "description": "Initializer for the bias vector. Default: `\"zeros\"`.",
        "name": "bias_initializer"
      },
      {
        "description": "Boolean (default `True`). If `True`,\n        add 1 to the bias of the forget gate at initialization.\n        Setting it to `True` will also force `bias_initializer=\"zeros\"`.\n        This is recommended in [Jozefowicz et al.](\n        https://github.com/mlresearch/v37/blob/gh-pages/jozefowicz15.pdf)",
        "name": "unit_forget_bias"
      },
      {
        "description": "Regularizer function applied to the `kernel` weights\n        matrix. Default: `None`.",
        "name": "kernel_regularizer"
      },
      {
        "description": "Regularizer function applied to the\n        `recurrent_kernel` weights matrix. Default: `None`.",
        "name": "recurrent_regularizer"
      },
      {
        "description": "Regularizer function applied to the bias vector.\n        Default: `None`.",
        "name": "bias_regularizer"
      },
      {
        "description": "Constraint function applied to the `kernel` weights\n        matrix. Default: `None`.",
        "name": "kernel_constraint"
      },
      {
        "description": "Constraint function applied to the\n        `recurrent_kernel` weights matrix. Default: `None`.",
        "name": "recurrent_constraint"
      },
      {
        "description": "Constraint function applied to the bias vector.\n        Default: `None`.",
        "name": "bias_constraint"
      },
      {
        "default": 0,
        "description": "Float between 0 and 1. Fraction of the units to drop for the\n        linear transformation of the inputs. Default: 0.",
        "name": "dropout"
      },
      {
        "default": 0,
        "description": "Float between 0 and 1. Fraction of the units to drop\n        for the linear transformation of the recurrent state. Default: 0.",
        "name": "recurrent_dropout"
      },
      {
        "description": "Implementation mode, either 1 or 2.\n    Mode 1 will structure its operations as a larger number of smaller dot\n    products and additions, whereas mode 2 (default) will batch them into\n    fewer, larger operations. These modes will have different performance\n    profiles on different hardware and for different applications. Default: 2.",
        "name": "implementation"
      },
      {
        "description": "`None`.",
        "name": "Default"
      },
      {
        "name": "seed",
        "description": "Random seed for dropout."
      }
    ],
    "examples": [
      {
        "code": ">>> inputs = np.random.random((32, 10, 8))\n>>> rnn = keras.layers.RNN(keras.layers.LSTMCell(4))\n>>> output = rnn(inputs)\n>>> output.shape\n(32, 4)\n>>> rnn = keras.layers.RNN(\n...    keras.layers.LSTMCell(4),\n...    return_sequences=True,\n...    return_state=True)\n>>> whole_sequence_output, final_state = rnn(inputs)\n>>> whole_sequence_output.shape\n(32, 10, 4)\n>>> final_state.shape\n(32, 4)"
      }
    ]
  },
  {
    "name": "Masking",
    "module": "keras.layers",
    "description": "Masks a sequence by using a mask value to skip timesteps.\n\nFor each timestep in the input tensor (dimension #1 in the tensor),\nif all values in the input tensor at that timestep\nare equal to `mask_value`, then the timestep will be masked (skipped)\nin all downstream layers (as long as they support masking).\n\nIf any downstream layer does not support masking yet receives such\nan input mask, an exception will be raised.",
    "attributes": [
      {
        "description": "Either None or mask value to skip\n",
        "name": "mask_value"
      }
    ],
    "examples": [
      {
        "summary": "Consider a NumPy data array `x` of shape `(samples, timesteps, features)`,\nto be fed to an LSTM layer. You want to mask timestep #3 and #5 because you\nlack data for these timesteps. You can:\n- Set `x[:, 3, :] = 0.` and `x[:, 5, :] = 0.`\n- Insert a `Masking` layer with `mask_value=0.` before the LSTM layer:",
        "code": "samples, timesteps, features = 32, 10, 8\ninputs = np.random.random([samples, timesteps, features]).astype(np.float32)\ninputs[:, 3, :] = 0.\ninputs[:, 5, :] = 0.\n\nmodel = keras.models.Sequential()\nmodel.add(keras.layers.Masking(mask_value=0.)\nmodel.add(keras.layers.LSTM(32))\noutput = model(inputs)\n# The time step 3 and 5 will be skipped from LSTM calculation."
      }
    ]
  },
  {
    "name": "Maximum",
    "module": "keras.layers",
    "category": "Tensor",
    "description": "Computes element-wise maximum on a list of inputs.\n\nIt takes as input a list of tensors, all of the same shape,\nand returns a single tensor (also of the same shape).",
    "inputs": [
      {
        "name": "inputs",
        "list": true
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> input_shape = (2, 3, 4)\n>>> x1 = np.random.rand(*input_shape)\n>>> x2 = np.random.rand(*input_shape)\n>>> y = keras.layers.Maximum()([x1, x2])"
      },
      {
        "summary": "Usage in a Keras model:",
        "code": ">>> input1 = keras.layers.Input(shape=(16,))\n>>> x1 = keras.layers.Dense(8, activation='relu')(input1)\n>>> input2 = keras.layers.Input(shape=(32,))\n>>> x2 = keras.layers.Dense(8, activation='relu')(input2)\n>>> # equivalent to `y = keras.layers.maximum([x1, x2])`\n>>> y = keras.layers.Maximum()([x1, x2])\n>>> out = keras.layers.Dense(4)(y)\n>>> model = keras.models.Model(inputs=[input1, input2], outputs=out)"
      }
    ]
  },
  {
    "name": "MaxPooling1D",
    "module": "keras.layers",
    "category": "Pool",
    "description": "Max pooling operation for 1D temporal data.\n\nDownsamples the input representation by taking the maximum value over a\nspatial window of size `pool_size`. The window is shifted by `strides`.\n\nThe resulting output when using the `\"valid\"` padding option has a shape of:\n`output_shape = (input_shape - pool_size + 1) / strides)`.\n\nThe resulting output shape when using the `\"same\"` padding option is:\n`output_shape = input_shape / strides`",
    "attributes": [
      {
        "default": "channels_last",
        "description": "string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, steps, features)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, steps)`. It defaults to the `image_data_format`\n        value found in your Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.",
        "name": "data_format"
      },
      {
        "default": "valid",
        "description": "string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input.",
        "name": "padding"
      },
      {
        "default": [
          2,
          2
        ],
        "description": "int, size of the max pooling window.",
        "name": "pool_size"
      },
      {
        "default": [
          2,
          2
        ],
        "description": "int or None. Specifies how much the pooling window moves\n        for each pooling step. If None, it will default to `pool_size`.",
        "name": "strides"
      }
    ],
    "inputs": [
      {
        "description": "- If `data_format=\"channels_last\"`:\n    3D tensor with shape `(batch_size, steps, features)`.\n- If `data_format=\"channels_first\"`:\n    3D tensor with shape `(batch_size, features, steps)`.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "- If `data_format=\"channels_last\"`:\n    3D tensor with shape `(batch_size, downsampled_steps, features)`.\n- If `data_format=\"channels_first\"`:\n    3D tensor with shape `(batch_size, features, downsampled_steps)`.",
        "name": "output"
      }
    ],
    "examples": [
      {
        "summary": "`strides=1` and `padding=\"valid\"`:",
        "code": ">>> x = np.array([1., 2., 3., 4., 5.])\n>>> x = np.reshape(x, [1, 5, 1])\n>>> max_pool_1d = keras.layers.MaxPooling1D(pool_size=2,\n...    strides=1, padding=\"valid\")\n>>> max_pool_1d(x)"
      },
      {
        "summary": "`strides=2` and `padding=\"valid\"`:",
        "code": ">>> x = np.array([1., 2., 3., 4., 5.])\n>>> x = np.reshape(x, [1, 5, 1])\n>>> max_pool_1d = keras.layers.MaxPooling1D(pool_size=2,\n...    strides=2, padding=\"valid\")\n>>> max_pool_1d(x)"
      },
      {
        "summary": "`strides=1` and `padding=\"same\"`:",
        "code": ">>> x = np.array([1., 2., 3., 4., 5.])\n>>> x = np.reshape(x, [1, 5, 1])\n>>> max_pool_1d = keras.layers.MaxPooling1D(pool_size=2,\n...    strides=1, padding=\"same\")\n>>> max_pool_1d(x)"
      }
    ]
  },
  {
    "name": "MaxPooling2D",
    "module": "keras.layers",
    "category": "Pool",
    "description": "Max pooling operation for 2D spatial data.\n\nDownsamples the input along its spatial dimensions (height and width)\nby taking the maximum value over an input window\n(of size defined by `pool_size`) for each channel of the input.\nThe window is shifted by `strides` along each dimension.\n\nThe resulting output when using the `\"valid\"` padding option has a spatial\nshape (number of rows or columns) of:\n`output_shape = math.floor((input_shape - pool_size) / strides) + 1`\n(when `input_shape >= pool_size`)\n\nThe resulting output shape when using the `\"same\"` padding option is:\n`output_shape = math.floor((input_shape - 1) / strides) + 1`",
    "attributes": [
      {
        "default": "channels_last",
        "description": "string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, height, width, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, height, width)`. It defaults to the\n        `image_data_format` value found in your Keras config file at\n        `~/.keras/keras.json`. If you never set it, then it will be\n        `\"channels_last\"`.",
        "name": "data_format"
      },
      {
        "default": "valid",
        "description": "string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input.",
        "name": "padding"
      },
      {
        "default": [
          2,
          2
        ],
        "description": "int or tuple of 2 integers, factors by which to downscale\n        (dim1, dim2). If only one integer is specified, the same\n        window length will be used for all dimensions.",
        "name": "pool_size"
      },
      {
        "default": [
          2,
          2
        ],
        "description": "int or tuple of 2 integers, or None. Strides values. If None,\n        it will default to `pool_size`. If only one int is specified, the\n        same stride size will be used for all dimensions.",
        "name": "strides"
      }
    ],
    "inputs": [
      {
        "description": "- If `data_format=\"channels_last\"`:\n    4D tensor with shape `(batch_size, height, width, channels)`.\n- If `data_format=\"channels_first\"`:\n    4D tensor with shape `(batch_size, channels, height, width)`.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "- If `data_format=\"channels_last\"`:\n    4D tensor with shape\n    `(batch_size, pooled_height, pooled_width, channels)`.\n- If `data_format=\"channels_first\"`:\n    4D tensor with shape\n    `(batch_size, channels, pooled_height, pooled_width)`.",
        "name": "output"
      }
    ],
    "examples": [
      {
        "summary": "`strides=(1, 1)` and `padding=\"valid\"`:",
        "code": ">>> x = np.array([[1., 2., 3.],\n...               [4., 5., 6.],\n...               [7., 8., 9.]])\n>>> x = np.reshape(x, [1, 3, 3, 1])\n>>> max_pool_2d = keras.layers.MaxPooling2D(pool_size=(2, 2),\n...    strides=(1, 1), padding=\"valid\")\n>>> max_pool_2d(x)"
      },
      {
        "summary": "`strides=(2, 2)` and `padding=\"valid\"`:",
        "code": ">>> x = np.array([[1., 2., 3., 4.],\n...               [5., 6., 7., 8.],\n...               [9., 10., 11., 12.]])\n>>> x = np.reshape(x, [1, 3, 4, 1])\n>>> max_pool_2d = keras.layers.MaxPooling2D(pool_size=(2, 2),\n...    strides=(2, 2), padding=\"valid\")\n>>> max_pool_2d(x)"
      },
      {
        "summary": "`stride=(1, 1)` and `padding=\"same\"`:",
        "code": ">>> x = np.array([[1., 2., 3.],\n...               [4., 5., 6.],\n...               [7., 8., 9.]])\n>>> x = np.reshape(x, [1, 3, 3, 1])\n>>> max_pool_2d = keras.layers.MaxPooling2D(pool_size=(2, 2),\n...    strides=(1, 1), padding=\"same\")\n>>> max_pool_2d(x)"
      }
    ]
  },
  {
    "name": "MaxPooling3D",
    "module": "keras.layers",
    "category": "Pool",
    "description": "Max pooling operation for 3D data (spatial or spatio-temporal).\n\nDownsamples the input along its spatial dimensions (depth, height, and\nwidth) by taking the maximum value over an input window (of size defined by\n`pool_size`) for each channel of the input. The window is shifted by\n`strides` along each dimension.",
    "attributes": [
      {
        "description": "int or tuple of 3 integers, factors by which to downscale\n        (dim1, dim2, dim3). If only one integer is specified, the same\n        window length will be used for all dimensions.",
        "name": "pool_size"
      },
      {
        "description": "int or tuple of 3 integers, or None. Strides values. If None,\n        it will default to `pool_size`. If only one int is specified, the\n        same stride size will be used for all dimensions.",
        "name": "strides"
      },
      {
        "description": "string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input.",
        "name": "padding"
      },
      {
        "default": "channels_last",
        "description": "string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape\n        `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)` while\n        `\"channels_first\"` corresponds to inputs with shape\n        `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n        It defaults to the `image_data_format` value found in your Keras\n        config file at `~/.keras/keras.json`. If you never set it, then it\n        will be `\"channels_last\"`.",
        "name": "data_format"
      }
    ],
    "inputs": [
      {
        "description": "- If `data_format=\"channels_last\"`:\n    5D tensor with shape:\n    `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n- If `data_format=\"channels_first\"`:\n    5D tensor with shape:\n    `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "- If `data_format=\"channels_last\"`:\n    5D tensor with shape:\n    `(batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)`\n- If `data_format=\"channels_first\"`:\n    5D tensor with shape:\n    `(batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": "depth = 30\nheight = 30\nwidth = 30\nchannels = 3\n\ninputs = keras.layers.Input(shape=(depth, height, width, channels))\nlayer = keras.layers.MaxPooling3D(pool_size=3)\noutputs = layer(inputs)  # Shape: (batch_size, 10, 10, 10, 3)"
      }
    ]
  },
  {
    "name": "MultiHeadAttention",
    "module": "keras.layers",
    "description": "MultiHeadAttention layer.\n\nThis is an implementation of multi-headed attention as described in the\npaper \"Attention is all you Need\"\n[Vaswani et al., 2017](https://arxiv.org/abs/1706.03762).\nIf `query`, `key,` `value` are the same, then\nthis is self-attention. Each timestep in `query` attends to the\ncorresponding sequence in `key`, and returns a fixed-width vector.\n\nThis layer first projects `query`, `key` and `value`. These are\n(effectively) a list of tensors of length `num_attention_heads`, where the\ncorresponding shapes are `(batch_size, <query dimensions>, key_dim)`,\n`(batch_size, <key/value dimensions>, key_dim)`,\n`(batch_size, <key/value dimensions>, value_dim)`.\n\nThen, the query and key tensors are dot-producted and scaled. These are\nsoftmaxed to obtain attention probabilities. The value tensors are then\ninterpolated by these probabilities, then concatenated back to a single\ntensor.\n\nFinally, the result tensor with the last dimension as `value_dim` can take\na linear projection and return.",
    "attributes": [
      {
        "description": "Number of attention heads.",
        "name": "num_heads"
      },
      {
        "description": "Size of each attention head for query and key.",
        "name": "key_dim"
      },
      {
        "description": "Size of each attention head for value.",
        "name": "value_dim"
      },
      {
        "description": "Dropout probability.",
        "name": "dropout"
      },
      {
        "description": "Boolean, whether the dense layers use bias vectors/matrices.",
        "name": "use_bias"
      },
      {
        "description": "The expected shape of an output tensor, besides the batch\n        and sequence dims. If not specified, projects back to the query\n        feature dim (the query input's last dimension).",
        "name": "output_shape"
      },
      {
        "description": "axes over which the attention is applied. `None` means\n        attention over all axes, but batch, heads, and features.",
        "name": "attention_axes"
      },
      {
        "description": "Initializer for dense layer kernels.",
        "name": "kernel_initializer"
      },
      {
        "description": "Initializer for dense layer biases.",
        "name": "bias_initializer"
      },
      {
        "description": "Regularizer for dense layer kernels.",
        "name": "kernel_regularizer"
      },
      {
        "description": "Regularizer for dense layer biases.",
        "name": "bias_regularizer"
      },
      {
        "description": "Regularizer for dense layer activity.",
        "name": "activity_regularizer"
      },
      {
        "description": "Constraint for dense layer kernels.",
        "name": "kernel_constraint"
      },
      {
        "description": "Constraint for dense layer kernels.",
        "name": "bias_constraint"
      }
    ],
    "examples": [
      {
        "summary": "Performs 1D cross-attention over two sequence inputs with an attention mask.\nReturns the additional attention weights over heads.",
        "code": ">>> layer = MultiHeadAttention(num_heads=2, key_dim=2)\n>>> target = tf.keras.Input(shape=[8, 16])\n>>> source = tf.keras.Input(shape=[4, 16])\n>>> output_tensor, weights = layer(target, source,\n...                                return_attention_scores=True)\n>>> print(output_tensor.shape)\n(None, 8, 16)\n>>> print(weights.shape)\n(None, 2, 8, 4)"
      },
      {
        "summary": "Performs 2D self-attention over a 5D input tensor on axes 2 and 3.",
        "code": ">>> layer = MultiHeadAttention(\n...     num_heads=2, key_dim=2, attention_axes=(2, 3))\n>>> input_tensor = tf.keras.Input(shape=[5, 3, 4, 16])\n>>> output_tensor = layer(input_tensor, input_tensor)\n>>> print(output_tensor.shape)\n(None, 5, 3, 4, 16)"
      }
    ]
  },
  {
    "name": "Multiply",
    "module": "keras.layers",
    "description": "Performs elementwise multiplication.\n\nIt takes as input a list of tensors, all of the same shape,\nand returns a single tensor (also of the same shape).",
    "inputs": [
      {
        "name": "inputs",
        "list": true
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> input_shape = (2, 3, 4)\n>>> x1 = np.random.rand(*input_shape)\n>>> x2 = np.random.rand(*input_shape)\n>>> y = keras.layers.Multiply()([x1, x2])"
      },
      {
        "summary": "Usage in a Keras model:",
        "code": ">>> input1 = keras.layers.Input(shape=(16,))\n>>> x1 = keras.layers.Dense(8, activation='relu')(input1)\n>>> input2 = keras.layers.Input(shape=(32,))\n>>> x2 = keras.layers.Dense(8, activation='relu')(input2)\n>>> # equivalent to `y = keras.layers.multiply([x1, x2])`\n>>> y = keras.layers.Multiply()([x1, x2])\n>>> out = keras.layers.Dense(4)(y)\n>>> model = keras.models.Model(inputs=[input1, input2], outputs=out)"
      }
    ]
  },
  {
    "name": "Permute",
    "module": "keras.layers",
    "category": "Shape",
    "description": "Permutes the dimensions of the input according to a given pattern.\n\nUseful e.g. connecting RNNs and convnets.",
    "attributes": [
      {
        "description": "Tuple of integers. Permutation pattern does not include the\n        batch dimension. Indexing starts at 1.\n        For instance, `(2, 1)` permutes the first and second dimensions\n        of the input.",
        "name": "dims"
      }
    ],
    "inputs": [
      {
        "description": "Arbitrary.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "Same as the input shape, but with the dimensions re-ordered according\nto the specified pattern.",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> x = keras.Input(shape=(10, 64))\n>>> y = keras.layers.Permute((2, 1))(x)\n>>> y.shape\n(None, 64, 10)"
      }
    ]
  },
  {
    "name": "PReLU",
    "module": "keras.layers",
    "category": "Activation",
    "description": "Parametric Rectified Linear Unit activation layer.\n\nFormula:\n``` python\nf(x) = alpha * x for x < 0\nf(x) = x for x >= 0\n```\nwhere `alpha` is a learned array with the same shape as x.",
    "attributes": [
      {
        "description": "Initializer function for the weights.",
        "name": "alpha_initializer"
      },
      {
        "description": "Regularizer for the weights.",
        "name": "alpha_regularizer",
        "visible": false
      },
      {
        "description": "Constraint for the weights.",
        "name": "alpha_constraint"
      },
      {
        "description": "The axes along which to share learnable parameters for the\n        activation function. For example, if the incoming feature maps are\n        from a 2D convolution with output shape\n        `(batch, height, width, channels)`, and you wish to share parameters\n        across space so that each filter only has one set of parameters,\n        set `shared_axes=[1, 2]`.",
        "name": "shared_axes"
      },
      {
        "name": "**kwargs",
        "description": "Base layer keyword arguments, such as `name` and `dtype`."
      }
    ],
    "inputs": [
      {
        "description": "Arbitrary. Use the keyword argument `input_shape`\n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.",
        "name": "input"
      },
      {
        "name": "params"
      }
    ],
    "outputs": [
      {
        "description": "Same shape as the input.",
        "name": "output"
      }
    ],
    "references": [
      {
        "description": "[Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification](https://arxiv.org/abs/1502.01852)"
      }
    ]
  },
  {
    "name": "ReLU",
    "module": "keras.layers",
    "category": "Activation",
    "description": "Rectified Linear Unit activation function layer.\n\nFormula:\n``` python\nf(x) = max(x,0)\nf(x) = max_value if x >= max_value\nf(x) = x if threshold <= x < max_value\nf(x) = negative_slope * (x - threshold) otherwise\n```",
    "attributes": [
      {
        "description": "Float >= 0. Maximum activation value. None means unlimited.\n        Defaults to `None`.",
        "name": "max_value"
      },
      {
        "description": "Float >= 0. Negative slope coefficient.\n        Defaults to `0.0`.",
        "name": "negative_slope"
      },
      {
        "description": "Float >= 0. Threshold value for thresholded activation.\n        Defaults to `0.0`.",
        "name": "threshold"
      },
      {
        "name": "**kwargs",
        "description": "Base layer keyword arguments, such as `name` and `dtype`."
      }
    ],
    "inputs": [
      {
        "description": "Arbitrary. Use the keyword argument `input_shape`\n(tuple of integers, does not include the batch axis)\nwhen using this layer as the first layer in a model.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "Same shape as the input.",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": "relu_layer = keras.layers.activations.ReLU(\n    max_value=10,\n    negative_slope=0.5,\n    threshold=0,\n)\ninput = np.array([-10, -5, 0.0, 5, 10])\nresult = relu_layer(input)\n# result = [-5. , -2.5,  0. ,  5. , 10.]"
      }
    ]
  },
  {
    "name": "RepeatVector",
    "module": "keras.layers",
    "category": "Shape",
    "description": "Repeats the input n times.",
    "attributes": [
      {
        "description": "Integer, repetition factor.",
        "name": "n"
      }
    ],
    "inputs": [
      {
        "description": "2D tensor with shape `(batch_size, features)`.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "3D tensor with shape `(batch_size, n, features)`.",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> x = keras.Input(shape=(32,))\n>>> y = keras.layers.RepeatVector(3)(x)\n>>> y.shape\n(None, 3, 32)"
      }
    ]
  },
  {
    "name": "Reshape",
    "module": "keras.layers",
    "category": "Shape",
    "description": "Layer that reshapes inputs into the given shape.",
    "attributes": [
      {
        "description": "Target shape. Tuple of integers, does not include the\n        samples dimension (batch size).",
        "name": "target_shape"
      }
    ],
    "inputs": [
      {
        "description": "Arbitrary, although all dimensions in the input shape must be\nknown/fixed. Use the keyword argument `input_shape` (tuple of integers,\ndoes not include the samples/batch size axis) when using this layer as\nthe first layer in a model.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "`(batch_size, *target_shape)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> x = keras.Input(shape=(12,))\n>>> y = keras.layers.Reshape((3, 4))(x)\n>>> y.shape\n(None, 3, 4)"
      },
      {
        "code": ">>> # also supports shape inference using `-1` as dimension\n>>> y = keras.layers.Reshape((-1, 2, 2))(x)\n>>> y.shape\n(None, 3, 2, 2)"
      }
    ]
  },
  {
    "name": "RNN",
    "module": "keras.layers",
    "category": "Layer",
    "description": "Base class for recurrent layers.",
    "attributes": [
      {
        "default": false,
        "description": "Boolean (default `False`). Whether to return the last\n        output in the output sequence, or the full sequence.",
        "name": "return_sequences"
      },
      {
        "default": false,
        "description": "Boolean (default `False`).\n        Whether to return the last state in addition to the output.",
        "name": "return_state"
      },
      {
        "default": false,
        "description": "Boolean (default `False`).\n        If `True`, process the input sequence backwards and return the\n        reversed sequence.",
        "name": "go_backwards"
      },
      {
        "default": false,
        "description": "Boolean (default `False`). If True, the last state\n        for each sample at index `i` in a batch will be used as initial\n        state for the sample of index `i` in the following batch.",
        "name": "stateful"
      },
      {
        "default": false,
        "description": "Boolean (default `False`).\n        If True, the network will be unrolled, else a symbolic loop will be\n        used. Unrolling can speed-up a RNN, although it tends to be more\n        memory-intensive. Unrolling is only suitable for short sequences.",
        "name": "unroll"
      },
      {
        "description": "A RNN cell instance or a list of RNN cell instances.\n        A RNN cell is a class that has:\n        - A `call(input_at_t, states_at_t)` method, returning\n        `(output_at_t, states_at_t_plus_1)`. The call method of the\n        cell can also take the optional argument `constants`, see\n        section \"Note on passing external constants\" below.\n        - A `state_size` attribute. This can be a single integer\n        (single state) in which case it is the size of the recurrent\n        state. This can also be a list/tuple of integers\n        (one size per state).\n        - A `output_size` attribute, a single integer.\n        - A `get_initial_state(batch_size=None)`\n        method that creates a tensor meant to be fed to `call()` as the\n        initial state, if the user didn't specify any initial state\n        via other means. The returned initial state should have\n        shape `(batch_size, cell.state_size)`.\n        The cell might choose to create a tensor full of zeros,\n        or other values based on the cell's implementation.\n        `inputs` is the input tensor to the RNN layer, with shape\n        `(batch_size, timesteps, features)`.\n        If this method is not implemented\n        by the cell, the RNN layer will create a zero filled tensor\n        with shape `(batch_size, cell.state_size)`.\n        In the case that `cell` is a list of RNN cell instances, the cells\n        will be stacked on top of each other in the RNN, resulting in an\n        efficient stacked RNN.",
        "name": "cell"
      },
      {
        "description": "dimensionality of the input (integer).\n    This argument (or alternatively,\n    the keyword argument `input_shape`)\n    is required when using this layer as the first layer in a model.",
        "name": "input_dim"
      },
      {
        "description": "Length of input sequences, to be specified\n    when it is constant.\n    This argument is required if you are going to connect\n    `Flatten` then `Dense` layers upstream\n    (without it, the shape of the dense outputs cannot be computed).\n    Note that if the recurrent layer is not the first layer\n    in your model, you would need to specify the input length\n    at the level of the first layer\n    (e.g. via the `input_shape` argument)\n",
        "name": "input_length"
      },
      {
        "description": "The shape format of the `inputs` and `outputs` tensors.\n    If True, the inputs and outputs will be in shape\n    `(timesteps, batch, ...)`, whereas in the False case, it will be\n    `(batch, timesteps, ...)`. Using `time_major = True` is a bit more\n    efficient because it avoids transposes at the beginning and end of the\n    RNN calculation. However, most TensorFlow data is batch-major, so by\n    default this function accepts input and emits output in batch-major\n    form.",
        "name": "time_major"
      },
      {
        "description": "Boolean (default `False`).\n        Whether the output should use zeros for the masked timesteps.\n        Note that this field is only used when `return_sequences`\n        is `True` and `mask` is provided.\n        It can useful if you want to reuse the raw output sequence of\n        the RNN without interference from the masked timesteps, e.g.,\n        merging bidirectional RNNs.",
        "name": "zero_output_for_mask"
      }
    ],
    "inputs": [
      {
        "description": "3-D tensor with shape `(batch_size, timesteps, features)`.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "- If `return_state`: a list of tensors. The first tensor is\nthe output. The remaining tensors are the last states,\neach with shape `(batch_size, state_size)`, where `state_size` could\nbe a high dimension tensor shape.\n- If `return_sequences`: 3D tensor with shape\n`(batch_size, timesteps, output_size)`.\n\nMasking:\n\nThis layer supports masking for input data with a variable number\nof timesteps. To introduce masks to your data,\nuse a `keras.layers.Embedding` layer with the `mask_zero` parameter\nset to `True`.\n\nNote on using statefulness in RNNs:\n\nYou can set RNN layers to be 'stateful', which means that the states\ncomputed for the samples in one batch will be reused as initial states\nfor the samples in the next batch. This assumes a one-to-one mapping\nbetween samples in different successive batches.\n\nTo enable statefulness:\n\n- Specify `stateful=True` in the layer constructor.\n- Specify a fixed batch size for your model, by passing\nIf sequential model:\n    `batch_input_shape=(...)` to the first layer in your model.\nElse for functional model with 1 or more Input layers:\n    `batch_shape=(...)` to all the first layers in your model.\nThis is the expected shape of your inputs\n*including the batch size*.\nIt should be a tuple of integers, e.g. `(32, 10, 100)`.\n- Specify `shuffle=False` when calling `fit()`.\n\nTo reset the states of your model, call `.reset_states()` on either\na specific layer, or on your entire model.\n\nNote on specifying the initial state of RNNs:\n\nYou can specify the initial state of RNN layers symbolically by\ncalling them with the keyword argument `initial_state`. The value of\n`initial_state` should be a tensor or list of tensors representing\nthe initial state of the RNN layer.\n\nYou can specify the initial state of RNN layers numerically by\ncalling `reset_states` with the keyword argument `states`. The value of\n`states` should be a numpy array or list of numpy arrays representing\nthe initial state of the RNN layer.",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": "from keras.layers import RNN\nfrom keras import ops\n\n# First, let's define a RNN Cell, as a layer subclass.\nclass MinimalRNNCell(keras.layers.Layer):\n\n    def __init__(self, units, **kwargs):\n        super().__init__(**kwargs)\n        self.units = units\n        self.state_size = units\n\n    def build(self, input_shape):\n        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n                                      initializer='uniform',\n                                      name='kernel')\n        self.recurrent_kernel = self.add_weight(\n            shape=(self.units, self.units),\n            initializer='uniform',\n            name='recurrent_kernel')\n        self.built = True\n\n    def call(self, inputs, states):\n        prev_output = states[0]\n        h = ops.matmul(inputs, self.kernel)\n        output = h + ops.matmul(prev_output, self.recurrent_kernel)\n        return output, [output]\n\n# Let's use this cell in a RNN layer:\n\ncell = MinimalRNNCell(32)\nx = keras.Input((None, 5))\nlayer = RNN(cell)\ny = layer(x)\n\n# Here's how to use the cell to build a stacked RNN:\n\ncells = [MinimalRNNCell(32), MinimalRNNCell(64)]\nx = keras.Input((None, 5))\nlayer = RNN(cells)\ny = layer(x)"
      }
    ]
  },
  {
    "name": "SeparableConv1D",
    "module": "keras.layers",
    "category": "Layer",
    "description": "1D separable convolution layer.\n\nThis layer performs a depthwise convolution that acts separately on\nchannels, followed by a pointwise convolution that mixes channels.\nIf `use_bias` is True and a bias initializer is provided,\nit adds a bias vector to the output. It then optionally applies an\nactivation function to produce the final output.",
    "attributes": [
      {
        "description": "int, the dimensionality of the output space (i.e. the number\n        of filters in the pointwise convolution).",
        "name": "filters"
      },
      {
        "description": "int or tuple/list of 1 integers, specifying the size of the\n        depthwise convolution window.",
        "name": "kernel_size"
      },
      {
        "description": "int or tuple/list of 1 integers, specifying the stride length\n        of the depthwise convolution. If only one int is specified, the same\n        stride size will be used for all dimensions. `strides > 1` is\n        incompatible with `dilation_rate > 1`.",
        "name": "strides"
      },
      {
        "description": "string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input.",
        "name": "padding"
      },
      {
        "description": "string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, steps, features)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, steps)`. It defaults to the `image_data_format`\n        value found in your Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.",
        "name": "data_format"
      },
      {
        "description": "int or tuple/list of 1 integers, specifying the dilation\n        rate to use for dilated convolution. If only one int is specified,\n        the same dilation rate will be used for all dimensions.\n     depth_multiplier: The number of depthwise convolution output channels\n        for each input channel. The total number of depthwise convolution\n        output channels will be equal to `input_channel * depth_multiplier`.",
        "name": "dilation_rate"
      },
      {
        "description": "The number of depthwise convolution output channels for\n    each input channel. The total number of depthwise convolution output\n    channels will be equal to `num_filters_in * depth_multiplier`.",
        "name": "depth_multiplier"
      },
      {
        "description": "Activation function. If `None`, no activation is applied.",
        "name": "activation"
      },
      {
        "description": "bool, if `True`, bias will be added to the output.",
        "name": "use_bias"
      },
      {
        "description": "An initializer for the depthwise convolution\n        kernel. If None, then the default initializer (`\"glorot_uniform\"`)\n        will be used.",
        "name": "depthwise_initializer"
      },
      {
        "description": "An initializer for the pointwise convolution\n        kernel. If None, then the default initializer (`\"glorot_uniform\"`)\n        will be used.",
        "name": "pointwise_initializer"
      },
      {
        "description": "An initializer for the bias vector. If None, the\n        default initializer ('\"zeros\"') will be used.",
        "name": "bias_initializer"
      },
      {
        "description": "Optional regularizer for the depthwise\n        convolution kernel.",
        "name": "depthwise_regularizer"
      },
      {
        "description": "Optional regularizer for the pointwise\n        convolution kernel.",
        "name": "pointwise_regularizer"
      },
      {
        "description": "Optional regularizer for the bias vector.",
        "name": "bias_regularizer"
      },
      {
        "description": "Optional regularizer function for the output.",
        "name": "activity_regularizer"
      },
      {
        "description": "Optional projection function to be applied to the\n        depthwise kernel after being updated by an `Optimizer` (e.g. used\n        for norm constraints or value constraints for layer weights). The\n        function must take as input the unprojected variable and must return\n        the projected variable (which must have the same shape).",
        "name": "depthwise_constraint"
      },
      {
        "description": "Optional projection function to be applied to the\n        pointwise kernel after being updated by an `Optimizer`.",
        "name": "pointwise_constraint"
      },
      {
        "description": "Optional projection function to be applied to the\n        bias after being updated by an `Optimizer`.",
        "name": "bias_constraint"
      },
      {
        "description": "Boolean, if `True` the weights of this layer will be marked as\n    trainable (and listed in `layer.trainable_weights`).",
        "name": "trainable"
      }
    ],
    "inputs": [
      {
        "description": "- If `data_format=\"channels_last\"`:\n    A 3D tensor with shape: `(batch_shape, steps, channels)`\n- If `data_format=\"channels_first\"`:\n    A 3D tensor with shape: `(batch_shape, channels, steps)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "- If `data_format=\"channels_last\"`:\n    A 3D tensor with shape: `(batch_shape, new_steps, filters)`\n- If `data_format=\"channels_first\"`:\n    A 3D tensor with shape: `(batch_shape, filters, new_steps)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> x = np.random.rand(4, 10, 12)\n>>> y = keras.layers.SeparableConv1D(3, 4, 3, 2, activation='relu')(x)\n>>> print(y.shape)\n(4, 4, 4)"
      }
    ]
  },
  {
    "name": "SeparableConv2D",
    "module": "keras.layers",
    "category": "Layer",
    "description": "2D separable convolution layer.\n\nThis layer performs a depthwise convolution that acts separately on\nchannels, followed by a pointwise convolution that mixes channels.\nIf `use_bias` is True and a bias initializer is provided,\nit adds a bias vector to the output. It then optionally applies an\nactivation function to produce the final output.",
    "attributes": [
      {
        "default": "linear",
        "description": "Activation function. If `None`, no activation is applied.",
        "name": "activation"
      },
      {
        "default": "valid",
        "description": "string, either `\"valid\"` or `\"same\"` (case-insensitive).\n        `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n        the left/right or up/down of the input such that output has the same\n        height/width dimension as the input.",
        "name": "padding"
      },
      {
        "default": true,
        "description": "bool, if `True`, bias will be added to the output.",
        "name": "use_bias",
        "visible": false
      },
      {
        "default": "channels_last",
        "description": "string, either `\"channels_last\"` or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs. `\"channels_last\"`\n        corresponds to inputs with shape `(batch, steps, features)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch, features, steps)`. It defaults to the `image_data_format`\n        value found in your Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.",
        "name": "data_format"
      },
      {
        "default": [
          1,
          1
        ],
        "description": "int or tuple/list of 2 integers, specifying the stride length\n        of the depthwise convolution. If only one int is specified, the same\n        stride size will be used for all dimensions. `strides > 1` is\n        incompatible with `dilation_rate > 1`.",
        "name": "strides"
      },
      {
        "default": [
          1,
          1
        ],
        "description": "int or tuple/list of 2 integers, specifying the dilation\n        rate to use for dilated convolution. If only one int is specified,\n        the same dilation rate will be used for all dimensions.",
        "name": "dilation_rate"
      },
      {
        "default": 1,
        "description": "The number of depthwise convolution output channels\n        for each input channel. The total number of depthwise convolution\n        output channels will be equal to `input_channel * depth_multiplier`.",
        "name": "depth_multiplier"
      },
      {
        "default": {
          "class_name": "VarianceScaling",
          "config": {
            "distribution": "uniform",
            "mode": "fan_avg",
            "scale": 1,
            "seed": null
          }
        },
        "description": "An initializer for the pointwise convolution\n        kernel. If None, then the default initializer (`\"glorot_uniform\"`)\n        will be used.",
        "name": "pointwise_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "VarianceScaling",
          "config": {
            "distribution": "uniform",
            "mode": "fan_avg",
            "scale": 1,
            "seed": null
          }
        },
        "description": "An initializer for the depthwise convolution\n        kernel. If None, then the default initializer (`\"glorot_uniform\"`)\n        will be used.",
        "name": "depthwise_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "Zeros",
          "config": {}
        },
        "description": "An initializer for the bias vector. If None, the\n        default initializer ('\"zeros\"') will be used.",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "VarianceScaling",
          "config": {
            "distribution": "uniform",
            "mode": "fan_avg",
            "scale": 1,
            "seed": null
          }
        },
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "description": "int, the dimensionality of the output space (i.e. the number\n        of filters in the pointwise convolution).",
        "name": "filters"
      },
      {
        "description": "int or tuple/list of 2 integers, specifying the size of the\n        depthwise convolution window.",
        "name": "kernel_size"
      },
      {
        "description": "Optional regularizer for the depthwise\n        convolution kernel.",
        "name": "depthwise_regularizer",
        "visible": false
      },
      {
        "description": "Optional regularizer for the pointwise\n        convolution kernel.",
        "name": "pointwise_regularizer",
        "visible": false
      },
      {
        "description": "Optional regularizer for the bias vector.",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Optional regularizer function for the output.",
        "name": "activity_regularizer",
        "visible": false
      },
      {
        "description": "Optional projection function to be applied to the\n        depthwise kernel after being updated by an `Optimizer` (e.g. used\n        for norm constraints or value constraints for layer weights). The\n        function must take as input the unprojected variable and must return\n        the projected variable (which must have the same shape).",
        "name": "depthwise_constraint",
        "visible": false
      },
      {
        "description": "Optional projection function to be applied to the\n        pointwise kernel after being updated by an `Optimizer`.",
        "name": "pointwise_constraint"
      },
      {
        "description": "Optional projection function to be applied to the\n        bias after being updated by an `Optimizer`.",
        "name": "bias_constraint"
      }
    ],
    "inputs": [
      {
        "description": "- If `data_format=\"channels_last\"`:\n    A 4D tensor with shape: `(batch_size, height, width, channels)`\n- If `data_format=\"channels_first\"`:\n    A 4D tensor with shape: `(batch_size, channels, height, width)`",
        "name": "input"
      },
      {
        "name": "kernel"
      },
      {
        "name": "bias"
      }
    ],
    "outputs": [
      {
        "description": "- If `data_format=\"channels_last\"`:\n    A 4D tensor with shape: `(batch_size, new_height, new_width, filters)`\n- If `data_format=\"channels_first\"`:\n    A 4D tensor with shape: `(batch_size, filters, new_height, new_width)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> x = np.random.rand(4, 10, 10, 12)\n>>> y = keras.layers.SeparableConv2D(3, 4, 3, 2, activation='relu')(x)\n>>> print(y.shape)\n(4, 4, 4, 4)"
      }
    ]
  },
  {
    "name": "Sigmoid",
    "category": "Activation"
  },
  {
    "name": "SimpleRNN",
    "module": "keras.layers",
    "category": "Layer",
    "description": "Fully-connected RNN where the output is to be fed back as the new input.",
    "attributes": [
      {
        "default": false,
        "description": "Boolean. Whether to return the last output\n        in the output sequence, or the full sequence. Default: `False`.",
        "name": "return_sequences"
      },
      {
        "default": false,
        "description": "Boolean. Whether to return the last state\n        in addition to the output. Default: `False`.",
        "name": "return_state"
      },
      {
        "default": false,
        "description": "Boolean (default: `False`).\n        If `True`, process the input sequence backwards and return the\n        reversed sequence.",
        "name": "go_backwards"
      },
      {
        "default": false,
        "description": "Boolean (default: `False`). If `True`, the last state\n        for each sample at index i in a batch will be used as initial\n        state for the sample of index i in the following batch.",
        "name": "stateful"
      },
      {
        "default": false,
        "description": "Boolean (default: `False`).\n        If `True`, the network will be unrolled,\n        else a symbolic loop will be used.\n        Unrolling can speed-up a RNN,\n        although it tends to be more memory-intensive.\n        Unrolling is only suitable for short sequences.",
        "name": "unroll"
      },
      {
        "default": "tanh",
        "description": "Activation function to use.\n        Default: hyperbolic tangent (`tanh`).\n        If you pass None, no activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).",
        "name": "activation"
      },
      {
        "default": true,
        "description": "Boolean, (default `True`), whether the layer uses\n        a bias vector.",
        "name": "use_bias",
        "visible": false
      },
      {
        "default": {
          "class_name": "VarianceScaling",
          "config": {
            "distribution": "uniform",
            "mode": "fan_avg",
            "scale": 1,
            "seed": null
          }
        },
        "description": "Initializer for the `kernel` weights matrix,\n        used for the linear transformation of the inputs. Default:\n        `\"glorot_uniform\"`.",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "Orthogonal",
          "config": {
            "gain": 1,
            "seed": null
          }
        },
        "description": "Initializer for the `recurrent_kernel`\n        weights matrix, used for the linear transformation of the recurrent\n        state.  Default: `\"orthogonal\"`.",
        "name": "recurrent_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "Zeros",
          "config": {}
        },
        "description": "Initializer for the bias vector. Default: `\"zeros\"`.",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "default": 0,
        "description": "Float between 0 and 1.\n        Fraction of the units to drop for the linear transformation\n        of the inputs. Default: 0.",
        "name": "dropout"
      },
      {
        "default": 0,
        "description": "Float between 0 and 1.\n        Fraction of the units to drop for the linear transformation of the\n        recurrent state. Default: 0.",
        "name": "recurrent_dropout"
      },
      {
        "description": "Positive integer, dimensionality of the output space.",
        "name": "units"
      },
      {
        "description": "Regularizer function applied to the `kernel` weights\n        matrix. Default: `None`.",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the\n        `recurrent_kernel` weights matrix. Default: `None`.",
        "name": "recurrent_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the bias vector.\n        Default: `None`.",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the output of the\n        layer (its \"activation\"). Default: `None`.",
        "name": "activity_regularizer",
        "visible": false
      },
      {
        "description": "Constraint function applied to the `kernel` weights\n        matrix. Default: `None`.",
        "name": "kernel_constraint"
      },
      {
        "description": "Constraint function applied to the\n        `recurrent_kernel` weights matrix.  Default: `None`.",
        "name": "recurrent_constraint"
      },
      {
        "description": "Constraint function applied to the bias vector.\n        Default: `None`.",
        "name": "bias_constraint"
      },
      {
        "description": "`None`.",
        "name": "Default"
      }
    ],
    "inputs": [
      {
        "name": "input"
      },
      {
        "name": "kernel"
      },
      {
        "name": "recurrent_kernel"
      },
      {
        "name": "bias"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": "inputs = np.random.random((32, 10, 8))\nsimple_rnn = keras.layers.SimpleRNN(4)\noutput = simple_rnn(inputs)  # The output has shape `(32, 4)`.\nsimple_rnn = keras.layers.SimpleRNN(\n    4, return_sequences=True, return_state=True\n)\n# whole_sequence_output has shape `(32, 10, 4)`.\n# final_state has shape `(32, 4)`.\nwhole_sequence_output, final_state = simple_rnn(inputs)"
      }
    ]
  },
  {
    "name": "SimpleRNNCell",
    "module": "keras.layers",
    "description": "Cell class for SimpleRNN.\n\nThis class processes one step within the whole time sequence input, whereas\n`keras.layer.SimpleRNN` processes the whole sequence.",
    "attributes": [
      {
        "description": "Positive integer, dimensionality of the output space.",
        "name": "units"
      },
      {
        "description": "Activation function to use.\n        Default: hyperbolic tangent (`tanh`).\n        If you pass `None`, no activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).",
        "name": "activation"
      },
      {
        "description": "Boolean, (default `True`), whether the layer\n        should use a bias vector.",
        "name": "use_bias",
        "visible": false
      },
      {
        "description": "Initializer for the `kernel` weights matrix,\n        used for the linear transformation of the inputs. Default:\n        `\"glorot_uniform\"`.",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "description": "Initializer for the `recurrent_kernel`\n        weights matrix, used for the linear transformation\n        of the recurrent state. Default: `\"orthogonal\"`.",
        "name": "recurrent_initializer",
        "visible": false
      },
      {
        "description": "Initializer for the bias vector. Default: `\"zeros\"`.",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the `kernel` weights\n        matrix. Default: `None`.",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the\n        `recurrent_kernel` weights matrix. Default: `None`.",
        "name": "recurrent_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the bias vector.\n        Default: `None`.",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Constraint function applied to the `kernel` weights\n        matrix. Default: `None`.",
        "name": "kernel_constraint"
      },
      {
        "description": "Constraint function applied to the\n        `recurrent_kernel` weights matrix. Default: `None`.",
        "name": "recurrent_constraint"
      },
      {
        "description": "Constraint function applied to the bias vector.\n        Default: `None`.",
        "name": "bias_constraint"
      },
      {
        "default": 0,
        "description": "Float between 0 and 1. Fraction of the units to drop for the\n        linear transformation of the inputs. Default: 0.",
        "name": "dropout"
      },
      {
        "default": 0,
        "description": "Float between 0 and 1. Fraction of the units to drop\n        for the linear transformation of the recurrent state. Default: 0.",
        "name": "recurrent_dropout"
      },
      {
        "description": "`None`.",
        "name": "Default"
      },
      {
        "name": "seed",
        "description": "Random seed for dropout."
      }
    ],
    "examples": [
      {
        "code": "inputs = np.random.random([32, 10, 8]).astype(np.float32)\nrnn = keras.layers.RNN(keras.layers.SimpleRNNCell(4))\noutput = rnn(inputs)  # The output has shape `(32, 4)`.\nrnn = keras.layers.RNN(\n    keras.layers.SimpleRNNCell(4),\n    return_sequences=True,\n    return_state=True\n)\n# whole_sequence_output has shape `(32, 10, 4)`.\n# final_state has shape `(32, 4)`.\nwhole_sequence_output, final_state = rnn(inputs)"
      }
    ]
  },
  {
    "name": "Softmax",
    "module": "keras.layers",
    "category": "Activation",
    "description": "Softmax activation layer.\n\nFormula:\n``` python\nexp_x = exp(x - max(x))\nf(x) = exp_x / sum(exp_x)\n```",
    "inputs": [
      {
        "name": "input",
        "description": "Arbitrary. Use the keyword argument `input_shape`\n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model."
      }
    ],
    "outputs": [
      {
        "name": "output",
        "description": "Same shape as the input."
      }
    ],
    "attributes": [
      {
        "name": "axis",
        "description": "Integer, or list of Integers, axis along which the softmax\n        normalization is applied."
      },
      {
        "name": "**kwargs",
        "description": "Base layer keyword arguments, such as `name` and `dtype`."
      }
    ],
    "examples": [
      {
        "code": ">>>softmax_layer = keras.layers.activations.Softmax()\n>>>input = np.array([1.0, 2.0, 1.0])\n>>>result = softmax_layer(input)\n[0.21194157, 0.5761169, 0.21194157]"
      }
    ]
  },
  {
    "name": "SoftPlus",
    "category": "Activation"
  },
  {
    "name": "SoftSign",
    "category": "Activation"
  },
  {
    "name": "SpatialDropout1D",
    "module": "keras.layers",
    "category": "Dropout",
    "description": "Spatial 1D version of Dropout.\n\nThis layer performs the same function as Dropout, however, it drops\nentire 1D feature maps instead of individual elements. If adjacent frames\nwithin feature maps are strongly correlated (as is normally the case in\nearly convolution layers) then regular dropout will not regularize the\nactivations and will otherwise just result in an effective learning rate\ndecrease. In this case, `SpatialDropout1D` will help promote independence\nbetween feature maps and should be used instead.",
    "attributes": [
      {
        "description": "Float between 0 and 1. Fraction of the input units to drop.",
        "name": "rate"
      }
    ],
    "inputs": [
      {
        "description": "3D tensor with shape: `(samples, timesteps, channels)`\n\nOutput shape: Same as input.\n\nReference:\n\n- [Tompson et al., 2014](https://arxiv.org/abs/1411.4280)",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "Same as input.",
        "name": "output"
      }
    ],
    "references": [
      {
        "description": "[Efficient Object Localization Using Convolutional Networks](https://arxiv.org/abs/1411.4280)"
      }
    ]
  },
  {
    "name": "SpatialDropout2D",
    "module": "keras.layers",
    "category": "Dropout",
    "description": "Spatial 2D version of Dropout.\n\nThis version performs the same function as Dropout, however, it drops\nentire 2D feature maps instead of individual elements. If adjacent pixels\nwithin feature maps are strongly correlated (as is normally the case in\nearly convolution layers) then regular dropout will not regularize the\nactivations and will otherwise just result in an effective learning rate\ndecrease. In this case, `SpatialDropout2D` will help promote independence\nbetween feature maps and should be used instead.",
    "attributes": [
      {
        "description": "Float between 0 and 1. Fraction of the input units to drop.",
        "name": "rate"
      },
      {
        "description": "`\"channels_first\"` or `\"channels_last\"`.\n        In `\"channels_first\"` mode, the channels dimension (the depth)\n        is at index 1, in `\"channels_last\"` mode is it at index 3.\n        It defaults to the `image_data_format` value found in your\n        Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.",
        "name": "data_format"
      }
    ],
    "inputs": [
      {
        "description": "4D tensor with shape: `(samples, channels, rows, cols)` if\n        data_format='channels_first'\n    or 4D tensor with shape: `(samples, rows, cols, channels)` if\n        data_format='channels_last'.\n\nOutput shape: Same as input.\n\nReference:\n\n- [Tompson et al., 2014](https://arxiv.org/abs/1411.4280)",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "Same as input.",
        "name": "output"
      }
    ],
    "references": [
      {
        "description": "[Efficient Object Localization Using Convolutional Networks](https://arxiv.org/abs/1411.4280)"
      }
    ]
  },
  {
    "name": "SpatialDropout3D",
    "module": "keras.layers",
    "category": "Dropout",
    "description": "Spatial 3D version of Dropout.\n\nThis version performs the same function as Dropout, however, it drops\nentire 3D feature maps instead of individual elements. If adjacent voxels\nwithin feature maps are strongly correlated (as is normally the case in\nearly convolution layers) then regular dropout will not regularize the\nactivations and will otherwise just result in an effective learning rate\ndecrease. In this case, SpatialDropout3D will help promote independence\nbetween feature maps and should be used instead.",
    "attributes": [
      {
        "description": "Float between 0 and 1. Fraction of the input units to drop.",
        "name": "rate"
      },
      {
        "description": "`\"channels_first\"` or `\"channels_last\"`.\n        In `\"channels_first\"` mode, the channels dimension (the depth)\n        is at index 1, in `\"channels_last\"` mode is it at index 4.\n        It defaults to the `image_data_format` value found in your\n        Keras config file at `~/.keras/keras.json`.\n        If you never set it, then it will be `\"channels_last\"`.",
        "name": "data_format"
      }
    ],
    "inputs": [
      {
        "description": "5D tensor with shape: `(samples, channels, dim1, dim2, dim3)` if\n        data_format='channels_first'\n    or 5D tensor with shape: `(samples, dim1, dim2, dim3, channels)` if\n        data_format='channels_last'.\n\nOutput shape: Same as input.\n\nReference:\n\n- [Tompson et al., 2014](https://arxiv.org/abs/1411.4280)",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "Same as input.",
        "name": "output"
      }
    ],
    "references": [
      {
        "description": "[Efficient Object Localization Using Convolutional Networks](https://arxiv.org/abs/1411.4280)"
      }
    ]
  },
  {
    "name": "StackedRNNCells",
    "module": "keras.layers",
    "description": "Wrapper allowing a stack of RNN cells to behave as a single cell.\n\nUsed to implement efficient stacked RNNs.",
    "attributes": [
      {
        "description": "List of RNN cell instances.",
        "name": "cells"
      }
    ],
    "examples": [
      {
        "code": "batch_size = 3\nsentence_length = 5\nnum_features = 2\nnew_shape = (batch_size, sentence_length, num_features)\nx = np.reshape(np.arange(30), new_shape)\n\nrnn_cells = [keras.layers.LSTMCell(128) for _ in range(2)]\nstacked_lstm = keras.layers.StackedRNNCells(rnn_cells)\nlstm_layer = keras.layers.RNN(stacked_lstm)\n\nresult = lstm_layer(x)"
      }
    ]
  },
  {
    "name": "Subtract",
    "module": "keras.layers",
    "description": "Performs elementwise subtraction.\n\nIt takes as input a list of tensors of size 2 both of the\nsame shape, and returns a single tensor (inputs[0] - inputs[1])\nof same shape.",
    "inputs": [
      {
        "name": "x"
      },
      {
        "name": "y"
      }
    ],
    "outputs": [
      {
        "name": "z"
      }
    ],
    "examples": [
      {
        "code": ">>> input_shape = (2, 3, 4)\n>>> x1 = np.random.rand(*input_shape)\n>>> x2 = np.random.rand(*input_shape)\n>>> y = keras.layers.Subtract()([x1, x2])"
      },
      {
        "summary": "Usage in a Keras model:",
        "code": ">>> input1 = keras.layers.Input(shape=(16,))\n>>> x1 = keras.layers.Dense(8, activation='relu')(input1)\n>>> input2 = keras.layers.Input(shape=(32,))\n>>> x2 = keras.layers.Dense(8, activation='relu')(input2)\n>>> # equivalent to `subtracted = keras.layers.subtract([x1, x2])`\n>>> subtracted = keras.layers.Subtract()([x1, x2])\n>>> out = keras.layers.Dense(4)(subtracted)\n>>> model = keras.models.Model(inputs=[input1, input2], outputs=out)"
      }
    ]
  },
  {
    "name": "TanH",
    "category": "Activation"
  },
  {
    "name": "ThresholdedReLU",
    "module": "keras.layers",
    "category": "Activation",
    "description": "Thresholded Rectified Linear Unit.\n\nIt follows:\n\n```\n    f(x) = x for x > theta\n    f(x) = 0 otherwise`\n```",
    "attributes": [
      {
        "description": "Float >= 0. Threshold location of activation.",
        "name": "theta"
      }
    ],
    "inputs": [
      {
        "description": "Arbitrary. Use the keyword argument `input_shape`\n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "Same shape as the input.",
        "name": "output"
      }
    ],
    "references": [
      {
        "description": "[Zero-Bias Autoencoders and the Benefits of Co-Adapting Features]( https://arxiv.org/abs/1402.3337)"
      }
    ]
  },
  {
    "name": "TimeDistributed",
    "module": "keras.layers",
    "category": "Wrapper",
    "description": "This wrapper allows to apply a layer to every temporal slice of an input.\n\nEvery input should be at least 3D, and the dimension of index one of the\nfirst input will be considered to be the temporal dimension.\n\nConsider a batch of 32 video samples, where each sample is a 128x128 RGB\nimage with `channels_last` data format, across 10 timesteps.\nThe batch input shape is `(32, 10, 128, 128, 3)`.\n\nYou can then use `TimeDistributed` to apply the same `Conv2D` layer to each\nof the 10 timesteps, independently:\n\n```\n>>> inputs = layers.Input(shape=(10, 128, 128, 3), batch_size=32)\n>>> conv_2d_layer = layers.Conv2D(64, (3, 3))\n>>> outputs = layers.TimeDistributed(conv_2d_layer)(inputs)\n>>> outputs.shape\n(32, 10, 126, 126, 64)\n```\n\nBecause `TimeDistributed` applies the same instance of `Conv2D` to each of\nthe timestamps, the same set of weights are used at each timestamp.",
    "attributes": [
      {
        "description": "a `keras.layers.Layer` instance.",
        "name": "layer"
      }
    ],
    "inputs": [
      {
        "name": "input"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ]
  },
  {
    "name": "UpSampling1D",
    "module": "keras.layers",
    "category": "Layer",
    "description": "Upsampling layer for 1D inputs.\n\nRepeats each temporal step `size` times along the time axis.",
    "attributes": [
      {
        "default": "channels_last",
        "name": "data_format"
      },
      {
        "description": "Integer. Upsampling factor.",
        "name": "size"
      }
    ],
    "inputs": [
      {
        "description": "3D tensor with shape: `(batch_size, steps, features)`.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "3D tensor with shape: `(batch_size, upsampled_steps, features)`.",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> input_shape = (2, 2, 3)\n>>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n>>> x\n[[[ 0  1  2]\n  [ 3  4  5]]\n [[ 6  7  8]\n  [ 9 10 11]]]\n>>> y = keras.layers.UpSampling1D(size=2)(x)\n>>> y\n[[[ 0.  1.  2.]\n  [ 0.  1.  2.]\n  [ 3.  4.  5.]\n  [ 3.  4.  5.]]"
      }
    ]
  },
  {
    "name": "UpSampling2D",
    "module": "keras.layers",
    "category": "Layer",
    "description": "Upsampling layer for 2D inputs.\n\nThe implementation uses interpolative resizing, given the resize method\n(specified by the `interpolation` argument). Use `interpolation=nearest`\nto repeat the rows and columns of the data.",
    "attributes": [
      {
        "default": "channels_last",
        "description": "A string,\n        one of `\"channels_last\"` (default) or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs.\n        `\"channels_last\"` corresponds to inputs with shape\n        `(batch_size, height, width, channels)` while `\"channels_first\"`\n        corresponds to inputs with shape\n        `(batch_size, channels, height, width)`.\n        When unspecified, uses\n        `image_data_format` value found in your Keras config file at\n        `~/.keras/keras.json` (if exists) else `\"channels_last\"`.\n        Defaults to `\"channels_last\"`.",
        "name": "data_format"
      },
      {
        "description": "Int, or tuple of 2 integers.\n        The upsampling factors for rows and columns.",
        "name": "size"
      },
      {
        "description": "A string, one of `\"bicubic\"`, `\"bilinear\"`, `\"lanczos3\"`,\n        `\"lanczos5\"`, `\"nearest\"`.",
        "name": "interpolation"
      }
    ],
    "inputs": [
      {
        "description": "4D tensor with shape:\n- If `data_format` is `\"channels_last\"`:\n    `(batch_size, rows, cols, channels)`\n- If `data_format` is `\"channels_first\"`:\n    `(batch_size, channels, rows, cols)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "4D tensor with shape:\n- If `data_format` is `\"channels_last\"`:\n    `(batch_size, upsampled_rows, upsampled_cols, channels)`\n- If `data_format` is `\"channels_first\"`:\n    `(batch_size, channels, upsampled_rows, upsampled_cols)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> input_shape = (2, 2, 1, 3)\n>>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n>>> print(x)\n[[[[ 0  1  2]]\n  [[ 3  4  5]]]\n [[[ 6  7  8]]\n  [[ 9 10 11]]]]\n>>> y = keras.layers.UpSampling2D(size=(1, 2))(x)\n>>> print(y)\n[[[[ 0  1  2]\n   [ 0  1  2]]\n  [[ 3  4  5]\n   [ 3  4  5]]]\n [[[ 6  7  8]\n   [ 6  7  8]]\n  [[ 9 10 11]\n   [ 9 10 11]]]]"
      }
    ]
  },
  {
    "name": "UpSampling3D",
    "module": "keras.layers",
    "category": "Layer",
    "description": "Upsampling layer for 3D inputs.\n\nRepeats the 1st, 2nd and 3rd dimensions\nof the data by `size[0]`, `size[1]` and `size[2]` respectively.",
    "attributes": [
      {
        "default": "channels_last",
        "description": "A string,\n        one of `\"channels_last\"` (default) or `\"channels_first\"`.\n        The ordering of the dimensions in the inputs.\n        `\"channels_last\"` corresponds to inputs with shape\n        `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n        When unspecified, uses\n        `image_data_format` value found in your Keras config file at\n         `~/.keras/keras.json` (if exists) else `\"channels_last\"`.\n        Defaults to `\"channels_last\"`.",
        "name": "data_format"
      },
      {
        "description": "Int, or tuple of 3 integers.\n        The upsampling factors for dim1, dim2 and dim3.",
        "name": "size"
      }
    ],
    "inputs": [
      {
        "description": "5D tensor with shape:\n- If `data_format` is `\"channels_last\"`:\n    `(batch_size, dim1, dim2, dim3, channels)`\n- If `data_format` is `\"channels_first\"`:\n    `(batch_size, channels, dim1, dim2, dim3)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "5D tensor with shape:\n- If `data_format` is `\"channels_last\"`:\n    `(batch_size, upsampled_dim1, upsampled_dim2, upsampled_dim3,\n    channels)`\n- If `data_format` is `\"channels_first\"`:\n    `(batch_size, channels, upsampled_dim1, upsampled_dim2,\n    upsampled_dim3)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> input_shape = (2, 1, 2, 1, 3)\n>>> x = np.ones(input_shape)\n>>> y = keras.layers.UpSampling3D(size=(2, 2, 2))(x)\n>>> y.shape\n(2, 2, 4, 2, 3)"
      }
    ]
  },
  {
    "name": "ZeroPadding1D",
    "module": "keras.layers",
    "category": "Tensor",
    "description": "Zero-padding layer for 1D input (e.g. temporal sequence).",
    "attributes": [
      {
        "description": "Int, or tuple of int (length 2), or dictionary.\n        - If int: how many zeros to add at the beginning and end of\n          the padding dimension (axis 1).\n        - If tuple of 2 ints: how many zeros to add at the beginning and the\n          end of the padding dimension (`(left_pad, right_pad)`).",
        "name": "padding"
      }
    ],
    "inputs": [
      {
        "description": "3D tensor with shape `(batch_size, axis_to_pad, features)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "3D tensor with shape `(batch_size, padded_axis, features)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> input_shape = (2, 2, 3)\n>>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n>>> x\n[[[ 0  1  2]\n  [ 3  4  5]]\n [[ 6  7  8]\n  [ 9 10 11]]]\n>>> y = keras.layers.ZeroPadding1D(padding=2)(x)\n>>> y\n[[[ 0  0  0]\n  [ 0  0  0]\n  [ 0  1  2]\n  [ 3  4  5]\n  [ 0  0  0]\n  [ 0  0  0]]\n [[ 0  0  0]\n  [ 0  0  0]\n  [ 6  7  8]\n  [ 9 10 11]\n  [ 0  0  0]\n  [ 0  0  0]]]"
      }
    ]
  },
  {
    "name": "ZeroPadding2D",
    "module": "keras.layers",
    "category": "Tensor",
    "description": "Zero-padding layer for 2D input (e.g. picture).\n\nThis layer can add rows and columns of zeros at the top, bottom, left and\nright side of an image tensor.",
    "attributes": [
      {
        "description": "Int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n        - If int: the same symmetric padding is applied to height and width.\n        - If tuple of 2 ints: interpreted as two different symmetric padding\n          values for height and width:\n          `(symmetric_height_pad, symmetric_width_pad)`.\n        - If tuple of 2 tuples of 2 ints: interpreted as\n         `((top_pad, bottom_pad), (left_pad, right_pad))`.",
        "name": "padding"
      },
      {
        "description": "A string, one of `\"channels_last\"` (default) or\n        `\"channels_first\"`. The ordering of the dimensions in the inputs.\n        `\"channels_last\"` corresponds to inputs with shape\n        `(batch_size, height, width, channels)` while `\"channels_first\"`\n        corresponds to inputs with shape\n        `(batch_size, channels, height, width)`.\n        When unspecified, uses `image_data_format` value found in your Keras\n        config file at `~/.keras/keras.json` (if exists). Defaults to\n        `\"channels_last\"`.",
        "name": "data_format"
      }
    ],
    "inputs": [
      {
        "description": "4D tensor with shape:\n- If `data_format` is `\"channels_last\"`:\n  `(batch_size, height, width, channels)`\n- If `data_format` is `\"channels_first\"`:\n  `(batch_size, channels, height, width)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "4D tensor with shape:\n- If `data_format` is `\"channels_last\"`:\n  `(batch_size, padded_height, padded_width, channels)`\n- If `data_format` is `\"channels_first\"`:\n  `(batch_size, channels, padded_height, padded_width)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> input_shape = (1, 1, 2, 2)\n>>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n>>> x\n[[[[0 1]\n   [2 3]]]]\n>>> y = keras.layers.ZeroPadding2D(padding=1)(x)\n>>> y\n[[[[0 0]\n   [0 0]\n   [0 0]\n   [0 0]]\n  [[0 0]\n   [0 1]\n   [2 3]\n   [0 0]]\n  [[0 0]\n   [0 0]\n   [0 0]\n   [0 0]]]]"
      }
    ]
  },
  {
    "name": "ZeroPadding3D",
    "module": "keras.layers",
    "category": "Tensor",
    "description": "Zero-padding layer for 3D data (spatial or spatio-temporal).",
    "attributes": [
      {
        "description": "Int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.\n        - If int: the same symmetric padding is applied to depth, height,\n          and width.\n        - If tuple of 3 ints: interpreted as three different symmetric\n          padding values for depth, height, and width:\n          `(symmetric_dim1_pad, symmetric_dim2_pad, symmetric_dim3_pad)`.\n        - If tuple of 3 tuples of 2 ints: interpreted as\n          `((left_dim1_pad, right_dim1_pad), (left_dim2_pad,\n          right_dim2_pad), (left_dim3_pad, right_dim3_pad))`.",
        "name": "padding"
      },
      {
        "description": "A string, one of `\"channels_last\"` (default) or\n        `\"channels_first\"`. The ordering of the dimensions in the inputs.\n        `\"channels_last\"` corresponds to inputs with shape\n        `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n        while `\"channels_first\"` corresponds to inputs with shape\n        `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n        When unspecified, uses `image_data_format` value found in your Keras\n        config file at `~/.keras/keras.json` (if exists). Defaults to\n        `\"channels_last\"`.",
        "name": "data_format"
      }
    ],
    "inputs": [
      {
        "description": "5D tensor with shape:\n- If `data_format` is `\"channels_last\"`:\n  `(batch_size, first_axis_to_pad, second_axis_to_pad,\n  third_axis_to_pad, depth)`\n- If `data_format` is `\"channels_first\"`:\n  `(batch_size, depth, first_axis_to_pad, second_axis_to_pad,\n  third_axis_to_pad)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "5D tensor with shape:\n- If `data_format` is `\"channels_last\"`:\n  `(batch_size, first_padded_axis, second_padded_axis,\n  third_axis_to_pad, depth)`\n- If `data_format` is `\"channels_first\"`:\n  `(batch_size, depth, first_padded_axis, second_padded_axis,\n  third_axis_to_pad)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> input_shape = (1, 1, 2, 2, 3)\n>>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n>>> y = keras.layers.ZeroPadding3D(padding=2)(x)\n>>> y.shape\n(1, 5, 6, 6, 3)"
      }
    ]
  },
  {
    "name": "Attention",
    "module": "keras.layers",
    "inputs": [
      {
        "name": "query",
        "type": "Tensor[]"
      },
      {
        "name": "value",
        "type": "Tensor[]"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ],
    "description": "Dot-product attention layer, a.k.a. Luong-style attention.\n\nInputs are a list with 2 or 3 elements:\n1. A `query` tensor of shape `(batch_size, Tq, dim)`.\n2. A `value` tensor of shape `(batch_size, Tv, dim)`.\n3. A optional `key` tensor of shape `(batch_size, Tv, dim)`. If none\n    supplied, `value` will be used as a `key`.\n\nThe calculation follows the steps:\n1. Calculate attention scores using `query` and `key` with shape\n    `(batch_size, Tq, Tv)`.\n2. Use scores to calculate a softmax distribution with shape\n    `(batch_size, Tq, Tv)`.\n3. Use the softmax distribution to create a linear combination of `value`\n    with shape `(batch_size, Tq, dim)`.",
    "attributes": [
      {
        "name": "use_scale",
        "description": "If `True`, will create a scalar variable to scale the\n        attention scores."
      },
      {
        "name": "causal",
        "description": "Boolean. Set to `True` for decoder self-attention. Adds a mask\n    such that position `i` cannot attend to positions `j > i`. This prevents\n    the flow of information from the future towards the past.  Defaults to\n    `False`."
      },
      {
        "name": "dropout",
        "description": "Float between 0 and 1. Fraction of the units to drop for the\n        attention scores. Defaults to `0.0`."
      },
      {
        "name": "inputs",
        "description": "List of the following tensors:\n        - `query`: Query tensor of shape `(batch_size, Tq, dim)`.\n        - `value`: Value tensor of shape `(batch_size, Tv, dim)`.\n        - `key`: Optional key tensor of shape `(batch_size, Tv, dim)`. If\n            not given, will use `value` for both `key` and `value`, which is\n            the most common case."
      },
      {
        "name": "mask",
        "description": "List of the following tensors:\n        - `query_mask`: A boolean mask tensor of shape `(batch_size, Tq)`.\n            If given, the output will be zero at the positions where\n            `mask==False`.\n        - `value_mask`: A boolean mask tensor of shape `(batch_size, Tv)`.\n            If given, will apply the mask such that values at positions\n             where `mask==False` do not contribute to the result."
      },
      {
        "name": "return_attention_scores",
        "description": "bool, it `True`, returns the attention scores\n        (after masking and softmax) as an additional output argument."
      },
      {
        "name": "training",
        "description": "Python boolean indicating whether the layer should behave in\n        training mode (adding dropout) or in inference mode (no dropout)."
      },
      {
        "name": "score_mode",
        "description": "Function to use to compute attention scores, one of\n        `{\"dot\", \"concat\"}`. `\"dot\"` refers to the dot product between the\n        query and key vectors. `\"concat\"` refers to the hyperbolic tangent\n        of the concatenation of the `query` and `key` vectors.\n\nCall Args:"
      },
      {
        "name": "use_causal_mask",
        "description": "Boolean. Set to `True` for decoder self-attention. Adds\n        a mask such that position `i` cannot attend to positions `j > i`.\n        This prevents the flow of information from the future towards the\n        past. Defaults to `False`.\n\nOutput:\n    Attention outputs of shape `(batch_size, Tq, dim)`.\n    (Optional) Attention scores after masking and softmax with shape\n        `(batch_size, Tq, Tv)`."
      }
    ]
  },
  {
    "name": "nn.relu",
    "category": "Activation",
    "inputs": [
      {
        "name": "input"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ]
  },
  {
    "name": "math.add",
    "inputs": [
      {
        "name": "x",
        "type": "Tensor"
      },
      {
        "name": "y",
        "type": "Tensor"
      }
    ],
    "outputs": [
      {
        "name": "z"
      }
    ]
  },
  {
    "name": "__operators__.add",
    "inputs": [
      {
        "name": "x",
        "type": "Tensor"
      },
      {
        "name": "y",
        "type": "Tensor"
      }
    ],
    "outputs": [
      {
        "name": "z"
      }
    ]
  },
  {
    "name": "linalg.matmul",
    "attributes": [
      {
        "name": "transpose_a",
        "type": "boolean"
      },
      {
        "name": "transpose_b",
        "type": "boolean"
      }
    ],
    "inputs": [
      {
        "name": "a",
        "type": "Tensor"
      },
      {
        "name": "b",
        "type": "Tensor"
      }
    ],
    "outputs": [
      {
        "name": "c",
        "type": "Tensor"
      }
    ]
  },
  {
    "name": "nn.abs",
    "inputs": [
      {
        "name": "input"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ]
  },
  {
    "name": "math.sigmoid",
    "category": "Activation",
    "inputs": [
      {
        "name": "input"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ]
  },
  {
    "name": "reshape",
    "category": "Shape",
    "inputs": [
      {
        "name": "input"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ]
  },
  {
    "name": "concat",
    "category": "Tensor",
    "inputs": [
      {
        "name": "inputs",
        "list": true
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ]
  },
  {
    "name": "compat.v1.transpose",
    "category": "Shape",
    "inputs": [
      {
        "name": "input"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ]
  }
]
