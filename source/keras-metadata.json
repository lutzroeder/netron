[
  {
    "name": "Activation",
    "module": "tensorflow.keras.layers",
    "description": "Applies an activation function to an output.",
    "attributes": [
      {
        "description": "Activation function, such as `tf.nn.relu`, or string name of\n    built-in activation function, such as \"relu\".",
        "name": "activation"
      }
    ],
    "inputs": [
      {
        "description": "Arbitrary. Use the keyword argument `input_shape`\n(tuple of integers, does not include the batch axis)\nwhen using this layer as the first layer in a model.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "Same shape as input.",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> layer = tf.keras.layers.Activation('relu')\n>>> output = layer([-3.0, -1.0, 0.0, 2.0])\n>>> list(output.numpy())\n[0.0, 0.0, 0.0, 2.0]\n>>> layer = tf.keras.layers.Activation(tf.nn.relu)\n>>> output = layer([-3.0, -1.0, 0.0, 2.0])\n>>> list(output.numpy())\n[0.0, 0.0, 0.0, 2.0]"
      }
    ]
  },
  {
    "name": "ActivityRegularization",
    "module": "tensorflow.keras.layers",
    "description": "Layer that applies an update to the cost function based input activity.",
    "attributes": [
      {
        "description": "L1 regularization factor (positive float).",
        "name": "l1"
      },
      {
        "description": "L2 regularization factor (positive float).",
        "name": "l2"
      }
    ],
    "inputs": [
      {
        "description": "Arbitrary. Use the keyword argument `input_shape`\n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "Same shape as input.",
        "name": "output"
      }
    ]
  },
  {
    "name": "Add",
    "module": "tensorflow.keras.layers",
    "description": "Layer that adds a list of inputs.\n\nIt takes as input a list of tensors,\nall of the same shape, and returns\na single tensor (also of the same shape).",
    "inputs": [
      {
        "name": "inputs",
        "list": true
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> input_shape = (2, 3, 4)\n>>> x1 = tf.random.normal(input_shape)\n>>> x2 = tf.random.normal(input_shape)\n>>> y = tf.keras.layers.Add()([x1, x2])\n>>> print(y.shape)\n(2, 3, 4)"
      },
      {
        "summary": "Used in a functional model:",
        "code": ">>> input1 = tf.keras.layers.Input(shape=(16,))\n>>> x1 = tf.keras.layers.Dense(8, activation='relu')(input1)\n>>> input2 = tf.keras.layers.Input(shape=(32,))\n>>> x2 = tf.keras.layers.Dense(8, activation='relu')(input2)\n>>> # equivalent to `added = tf.keras.layers.add([x1, x2])`\n>>> added = tf.keras.layers.Add()([x1, x2])\n>>> out = tf.keras.layers.Dense(4)(added)\n>>> model = tf.keras.models.Model(inputs=[input1, input2], outputs=out)"
      }
    ]
  },
  {
    "name": "Attention",
    "module": "tensorflow.keras.layers",
    "description": "Dot-product attention layer, a.k.a. Luong-style attention.\n\nInputs are `query` tensor of shape `[batch_size, Tq, dim]`, `value` tensor\nof shape `[batch_size, Tv, dim]` and `key` tensor of shape\n`[batch_size, Tv, dim]`. The calculation follows the steps:\n\n1. Calculate scores with shape `[batch_size, Tq, Tv]` as a `query`-`key` dot\n   product: `scores = tf.matmul(query, key, transpose_b=True)`.\n2. Use scores to calculate a distribution with shape\n   `[batch_size, Tq, Tv]`: `distribution = tf.nn.softmax(scores)`.\n3. Use `distribution` to create a linear combination of `value` with\n   shape `[batch_size, Tq, dim]`:\n   `return tf.matmul(distribution, value)`.",
    "attributes": [
      {
        "description": "If `True`, will create a scalar variable to scale the attention\n    scores.",
        "name": "use_scale"
      },
      {
        "description": "Boolean. Set to `True` for decoder self-attention. Adds a mask\n    such that position `i` cannot attend to positions `j > i`. This prevents\n    the flow of information from the future towards the past.  Defaults to\n    `False`.",
        "name": "causal"
      },
      {
        "description": "Float between 0 and 1. Fraction of the units to drop for the\n    attention scores. Defaults to 0.0.",
        "name": "dropout"
      },
      {
        "description": "List of the following tensors:\n    * query: Query `Tensor` of shape `[batch_size, Tq, dim]`.\n    * value: Value `Tensor` of shape `[batch_size, Tv, dim]`.\n    * key: Optional key `Tensor` of shape `[batch_size, Tv, dim]`. If not\n      given, will use `value` for both `key` and `value`, which is the\n      most common case.",
        "name": "inputs"
      },
      {
        "description": "List of the following tensors:\n    * query_mask: A boolean mask `Tensor` of shape `[batch_size, Tq]`.\n      If given, the output will be zero at the positions where\n      `mask==False`.\n    * value_mask: A boolean mask `Tensor` of shape `[batch_size, Tv]`.\n      If given, will apply the mask such that values at positions where\n      `mask==False` do not contribute to the result.",
        "name": "mask"
      },
      {
        "description": "bool, it `True`, returns the attention scores\n    (after masking and softmax) as an additional output argument.",
        "name": "return_attention_scores"
      },
      {
        "description": "Python boolean indicating whether the layer should behave in\n    training mode (adding dropout) or in inference mode (no dropout).",
        "name": "training"
      },
      {
        "name": "score_mode",
        "description": "Function to use to compute attention scores, one of\n    `{\"dot\", \"concat\"}`. `\"dot\"` refers to the dot product between the query\n    and key vectors. `\"concat\"` refers to the hyperbolic tangent of the\n    concatenation of the query and key vectors.\n\nCall Args:"
      },
      {
        "name": "use_causal_mask",
        "description": "Boolean. Set to `True` for decoder self-attention. Adds a\n    mask such that position `i` cannot attend to positions `j > i`. This\n    prevents the flow of information from the future towards the past.\n    Defaults to `False`.\n\nOutput:\n\n  Attention outputs of shape `[batch_size, Tq, dim]`.\n  [Optional] Attention scores after masking and softmax with shape\n    `[batch_size, Tq, Tv]`.\n\nThe meaning of `query`, `value` and `key` depend on the application. In the\ncase of text similarity, for example, `query` is the sequence embeddings of\nthe first piece of text and `value` is the sequence embeddings of the second\npiece of text. `key` is usually the same tensor as `value`.\n\nHere is a code example for using `Attention` in a CNN+Attention network:\n\n```python\n# Variable-length int sequences.\nquery_input = tf.keras.Input(shape=(None,), dtype='int32')\nvalue_input = tf.keras.Input(shape=(None,), dtype='int32')\n\n# Embedding lookup.\ntoken_embedding = tf.keras.layers.Embedding(input_dim=1000, output_dim=64)\n# Query embeddings of shape [batch_size, Tq, dimension].\nquery_embeddings = token_embedding(query_input)\n# Value embeddings of shape [batch_size, Tv, dimension].\nvalue_embeddings = token_embedding(value_input)\n\n# CNN layer.\ncnn_layer = tf.keras.layers.Conv1D(\n    filters=100,\n    kernel_size=4,\n    # Use 'same' padding so outputs have the same shape as inputs.\n    padding='same')\n# Query encoding of shape [batch_size, Tq, filters].\nquery_seq_encoding = cnn_layer(query_embeddings)\n# Value encoding of shape [batch_size, Tv, filters].\nvalue_seq_encoding = cnn_layer(value_embeddings)\n\n# Query-value attention of shape [batch_size, Tq, filters].\nquery_value_attention_seq = tf.keras.layers.Attention()(\n    [query_seq_encoding, value_seq_encoding])\n\n# Reduce over the sequence axis to produce encodings of shape\n# [batch_size, filters].\nquery_encoding = tf.keras.layers.GlobalAveragePooling1D()(\n    query_seq_encoding)\nquery_value_attention = tf.keras.layers.GlobalAveragePooling1D()(\n    query_value_attention_seq)\n\n# Concatenate query and document encodings to produce a DNN input layer.\ninput_layer = tf.keras.layers.Concatenate()(\n    [query_encoding, query_value_attention])\n\n# Add DNN layers, and create Model.\n# ...\n```"
      }
    ]
  },
  {
    "name": "Average",
    "module": "tensorflow.keras.layers",
    "category": "Tensor",
    "description": "Layer that averages a list of inputs element-wise.\n\nIt takes as input a list of tensors, all of the same shape, and returns\na single tensor (also of the same shape).",
    "inputs": [
      {
        "name": "inputs",
        "list": true
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> x1 = np.ones((2, 2))\n>>> x2 = np.zeros((2, 2))\n>>> y = tf.keras.layers.Average()([x1, x2])\n>>> y.numpy().tolist()\n[[0.5, 0.5], [0.5, 0.5]]"
      },
      {
        "summary": "Usage in a functional model:",
        "code": ">>> input1 = tf.keras.layers.Input(shape=(16,))\n>>> x1 = tf.keras.layers.Dense(8, activation='relu')(input1)\n>>> input2 = tf.keras.layers.Input(shape=(32,))\n>>> x2 = tf.keras.layers.Dense(8, activation='relu')(input2)\n>>> avg = tf.keras.layers.Average()([x1, x2])\n>>> out = tf.keras.layers.Dense(4)(avg)\n>>> model = tf.keras.models.Model(inputs=[input1, input2], outputs=out)"
      }
    ]
  },
  {
    "name": "AveragePooling1D",
    "module": "tensorflow.keras.layers",
    "category": "Pool",
    "description": "Average pooling for temporal data.\n\nDownsamples the input representation by taking the average value over the\nwindow defined by `pool_size`. The window is shifted by `strides`.  The\nresulting output when using \"valid\" padding option has a shape of:\n`output_shape = (input_shape - pool_size + 1) / strides)`\n\nThe resulting output shape when using the \"same\" padding option is:\n`output_shape = input_shape / strides`\n\nFor example, for strides=1 and padding=\"valid\":\n\n```\n>>> x = tf.constant([1., 2., 3., 4., 5.])\n>>> x = tf.reshape(x, [1, 5, 1])\n>>> x\n<tf.Tensor: shape=(1, 5, 1), dtype=float32, numpy=\n  array([[[1.],\n          [2.],\n          [3.],\n          [4.],\n          [5.]], dtype=float32)>\n>>> avg_pool_1d = tf.keras.layers.AveragePooling1D(pool_size=2,\n...    strides=1, padding='valid')\n>>> avg_pool_1d(x)\n<tf.Tensor: shape=(1, 4, 1), dtype=float32, numpy=\narray([[[1.5],\n        [2.5],\n        [3.5],\n        [4.5]]], dtype=float32)>\n```\n\nFor example, for strides=2 and padding=\"valid\":\n\n```\n>>> x = tf.constant([1., 2., 3., 4., 5.])\n>>> x = tf.reshape(x, [1, 5, 1])\n>>> x\n<tf.Tensor: shape=(1, 5, 1), dtype=float32, numpy=\n  array([[[1.],\n          [2.],\n          [3.],\n          [4.],\n          [5.]], dtype=float32)>\n>>> avg_pool_1d = tf.keras.layers.AveragePooling1D(pool_size=2,\n...    strides=2, padding='valid')\n>>> avg_pool_1d(x)\n<tf.Tensor: shape=(1, 2, 1), dtype=float32, numpy=\narray([[[1.5],\n        [3.5]]], dtype=float32)>\n```\n\nFor example, for strides=1 and padding=\"same\":\n\n```\n>>> x = tf.constant([1., 2., 3., 4., 5.])\n>>> x = tf.reshape(x, [1, 5, 1])\n>>> x\n<tf.Tensor: shape=(1, 5, 1), dtype=float32, numpy=\n  array([[[1.],\n          [2.],\n          [3.],\n          [4.],\n          [5.]], dtype=float32)>\n>>> avg_pool_1d = tf.keras.layers.AveragePooling1D(pool_size=2,\n...    strides=1, padding='same')\n>>> avg_pool_1d(x)\n<tf.Tensor: shape=(1, 5, 1), dtype=float32, numpy=\narray([[[1.5],\n        [2.5],\n        [3.5],\n        [4.5],\n        [5.]]], dtype=float32)>\n```",
    "attributes": [
      {
        "description": "Integer, size of the average pooling windows.",
        "name": "pool_size"
      },
      {
        "description": "Integer, or None. Factor by which to downscale.\n    E.g. 2 will halve the input.\n    If None, it will default to `pool_size`.",
        "name": "strides"
      },
      {
        "description": "One of `\"valid\"` or `\"same\"` (case-insensitive).\n    `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n    the left/right or up/down of the input such that output has the same\n    height/width dimension as the input.",
        "name": "padding"
      },
      {
        "description": "A string,\n    one of `channels_last` (default) or `channels_first`.\n    The ordering of the dimensions in the inputs.\n    `channels_last` corresponds to inputs with shape\n    `(batch, steps, features)` while `channels_first`\n    corresponds to inputs with shape\n    `(batch, features, steps)`.",
        "name": "data_format"
      }
    ],
    "inputs": [
      {
        "description": "- If `data_format='channels_last'`:\n  3D tensor with shape `(batch_size, steps, features)`.\n- If `data_format='channels_first'`:\n  3D tensor with shape `(batch_size, features, steps)`.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "- If `data_format='channels_last'`:\n  3D tensor with shape `(batch_size, downsampled_steps, features)`.\n- If `data_format='channels_first'`:\n  3D tensor with shape `(batch_size, features, downsampled_steps)`.",
        "name": "output"
      }
    ]
  },
  {
    "name": "AveragePooling2D",
    "module": "tensorflow.keras.layers",
    "category": "Pool",
    "description": "Average pooling operation for spatial data.\n\nDownsamples the input along its spatial dimensions (height and width)\nby taking the average value over an input window\n(of size defined by `pool_size`) for each channel of the input.\nThe window is shifted by `strides` along each dimension.\n\nThe resulting output when using `\"valid\"` padding option has a shape\n(number of rows or columns) of:\n`output_shape = math.floor((input_shape - pool_size) / strides) + 1`\n(when `input_shape >= pool_size`)\n\nThe resulting output shape when using the `\"same\"` padding option is:\n`output_shape = math.floor((input_shape - 1) / strides) + 1`\n\nFor example, for `strides=(1, 1)` and `padding=\"valid\"`:\n\n```\n>>> x = tf.constant([[1., 2., 3.],\n...                  [4., 5., 6.],\n...                  [7., 8., 9.]])\n>>> x = tf.reshape(x, [1, 3, 3, 1])\n>>> avg_pool_2d = tf.keras.layers.AveragePooling2D(pool_size=(2, 2),\n...    strides=(1, 1), padding='valid')\n>>> avg_pool_2d(x)\n<tf.Tensor: shape=(1, 2, 2, 1), dtype=float32, numpy=\n  array([[[[3.],\n           [4.]],\n          [[6.],\n           [7.]]]], dtype=float32)>\n```\n\nFor example, for `stride=(2, 2)` and `padding=\"valid\"`:\n\n```\n>>> x = tf.constant([[1., 2., 3., 4.],\n...                  [5., 6., 7., 8.],\n...                  [9., 10., 11., 12.]])\n>>> x = tf.reshape(x, [1, 3, 4, 1])\n>>> avg_pool_2d = tf.keras.layers.AveragePooling2D(pool_size=(2, 2),\n...    strides=(2, 2), padding='valid')\n>>> avg_pool_2d(x)\n<tf.Tensor: shape=(1, 1, 2, 1), dtype=float32, numpy=\n  array([[[[3.5],\n           [5.5]]]], dtype=float32)>\n```\n\nFor example, for `strides=(1, 1)` and `padding=\"same\"`:\n\n```\n>>> x = tf.constant([[1., 2., 3.],\n...                  [4., 5., 6.],\n...                  [7., 8., 9.]])\n>>> x = tf.reshape(x, [1, 3, 3, 1])\n>>> avg_pool_2d = tf.keras.layers.AveragePooling2D(pool_size=(2, 2),\n...    strides=(1, 1), padding='same')\n>>> avg_pool_2d(x)\n<tf.Tensor: shape=(1, 3, 3, 1), dtype=float32, numpy=\n  array([[[[3.],\n           [4.],\n           [4.5]],\n          [[6.],\n           [7.],\n           [7.5]],\n          [[7.5],\n           [8.5],\n           [9.]]]], dtype=float32)>\n```",
    "attributes": [
      {
        "default": "channels_last",
        "description": "A string,\n    one of `channels_last` (default) or `channels_first`.\n    The ordering of the dimensions in the inputs.\n    `channels_last` corresponds to inputs with shape\n    `(batch, height, width, channels)` while `channels_first`\n    corresponds to inputs with shape\n    `(batch, channels, height, width)`.\n    It defaults to the `image_data_format` value found in your\n    Keras config file at `~/.keras/keras.json`.\n    If you never set it, then it will be \"channels_last\".",
        "name": "data_format"
      },
      {
        "description": "integer or tuple of 2 integers,\n    factors by which to downscale (vertical, horizontal).\n    `(2, 2)` will halve the input in both spatial dimension.\n    If only one integer is specified, the same window length\n    will be used for both dimensions.",
        "name": "pool_size"
      },
      {
        "description": "Integer, tuple of 2 integers, or None.\n    Strides values.\n    If None, it will default to `pool_size`.",
        "name": "strides"
      },
      {
        "description": "One of `\"valid\"` or `\"same\"` (case-insensitive).\n    `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n    the left/right or up/down of the input such that output has the same\n    height/width dimension as the input.",
        "name": "padding"
      }
    ],
    "inputs": [
      {
        "description": "- If `data_format='channels_last'`:\n  4D tensor with shape `(batch_size, rows, cols, channels)`.\n- If `data_format='channels_first'`:\n  4D tensor with shape `(batch_size, channels, rows, cols)`.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "- If `data_format='channels_last'`:\n  4D tensor with shape `(batch_size, pooled_rows, pooled_cols, channels)`.\n- If `data_format='channels_first'`:\n  4D tensor with shape `(batch_size, channels, pooled_rows, pooled_cols)`.",
        "name": "output"
      }
    ]
  },
  {
    "name": "AveragePooling3D",
    "module": "tensorflow.keras.layers",
    "description": "Average pooling operation for 3D data (spatial or spatio-temporal).\n\nDownsamples the input along its spatial dimensions (depth, height, and\nwidth) by taking the average value over an input window\n(of size defined by `pool_size`) for each channel of the input.\nThe window is shifted by `strides` along each dimension.",
    "attributes": [
      {
        "description": "tuple of 3 integers,\n    factors by which to downscale (dim1, dim2, dim3).\n    `(2, 2, 2)` will halve the size of the 3D input in each dimension.",
        "name": "pool_size"
      },
      {
        "description": "tuple of 3 integers, or None. Strides values.",
        "name": "strides"
      },
      {
        "description": "One of `\"valid\"` or `\"same\"` (case-insensitive).\n    `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n    the left/right or up/down of the input such that output has the same\n    height/width dimension as the input.",
        "name": "padding"
      },
      {
        "default": "channels_last",
        "description": "A string,\n    one of `channels_last` (default) or `channels_first`.\n    The ordering of the dimensions in the inputs.\n    `channels_last` corresponds to inputs with shape\n    `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n    while `channels_first` corresponds to inputs with shape\n    `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n    It defaults to the `image_data_format` value found in your\n    Keras config file at `~/.keras/keras.json`.\n    If you never set it, then it will be \"channels_last\".",
        "name": "data_format"
      }
    ],
    "inputs": [
      {
        "description": "- If `data_format='channels_last'`:\n  5D tensor with shape:\n  `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n- If `data_format='channels_first'`:\n  5D tensor with shape:\n  `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "- If `data_format='channels_last'`:\n  5D tensor with shape:\n  `(batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)`\n- If `data_format='channels_first'`:\n  5D tensor with shape:\n  `(batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": "depth = 30\nheight = 30\nwidth = 30\ninput_channels = 3\n\ninputs = tf.keras.Input(shape=(depth, height, width, input_channels))\nlayer = tf.keras.layers.AveragePooling3D(pool_size=3)\noutputs = layer(inputs)  # Shape: (batch_size, 10, 10, 10, 3)"
      }
    ]
  },
  {
    "name": "BatchNorm",
    "category": "Normalization",
    "attributes": [
      {
        "default": -1,
        "name": "axis"
      },
      {
        "default": 0.001,
        "name": "epsilon"
      },
      {
        "default": 0.99,
        "name": "momentum"
      },
      {
        "default": true,
        "name": "scale"
      },
      {
        "default": true,
        "name": "center"
      },
      {
        "default": {
          "class_name": "Ones",
          "config": {}
        },
        "name": "gamma_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "Zeros",
          "config": {}
        },
        "name": "moving_mean_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "Ones",
          "config": {}
        },
        "name": "moving_variance_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "Zeros",
          "config": {}
        },
        "name": "beta_initializer",
        "visible": false
      },
      {
        "name": "beta_regularizer",
        "visible": false
      },
      {
        "name": "gamma_regularizer",
        "visible": false
      },
      {
        "name": "beta_constraint"
      },
      {
        "name": "gamma_constraint"
      }
    ],
    "inputs": [
      {
        "name": "input"
      },
      {
        "name": "gamma"
      },
      {
        "name": "beta"
      },
      {
        "name": "running_mean"
      },
      {
        "name": "running_std"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ]
  },
  {
    "name": "BatchNormalization",
    "module": "tensorflow.keras.layers",
    "category": "Normalization",
    "description": "Layer that normalizes its inputs.\n\nBatch normalization applies a transformation that maintains the mean output\nclose to 0 and the output standard deviation close to 1.\n\nImportantly, batch normalization works differently during training and\nduring inference.\n\n**During training** (i.e. when using `fit()` or when calling the layer/model\nwith the argument `training=True`), the layer normalizes its output using\nthe mean and standard deviation of the current batch of inputs. That is to\nsay, for each channel being normalized, the layer returns\n`gamma * (batch - mean(batch)) / sqrt(var(batch) + epsilon) + beta`, where:\n\n- `epsilon` is small constant (configurable as part of the constructor\narguments)\n- `gamma` is a learned scaling factor (initialized as 1), which\ncan be disabled by passing `scale=False` to the constructor.\n- `beta` is a learned offset factor (initialized as 0), which\ncan be disabled by passing `center=False` to the constructor.\n\n**During inference** (i.e. when using `evaluate()` or `predict()` or when\ncalling the layer/model with the argument `training=False` (which is the\ndefault), the layer normalizes its output using a moving average of the\nmean and standard deviation of the batches it has seen during training. That\nis to say, it returns\n`gamma * (batch - self.moving_mean) / sqrt(self.moving_var+epsilon) + beta`.\n\n`self.moving_mean` and `self.moving_var` are non-trainable variables that\nare updated each time the layer in called in training mode, as such:\n\n- `moving_mean = moving_mean * momentum + mean(batch) * (1 - momentum)`\n- `moving_var = moving_var * momentum + var(batch) * (1 - momentum)`\n\nAs such, the layer will only normalize its inputs during inference\n*after having been trained on data that has similar statistics as the\ninference data*.\n\nWhen `synchronized=True` is set and if this layer is used within a\n`tf.distribute` strategy, there will be an `allreduce` call\nto aggregate batch statistics across all replicas at every\ntraining step. Setting `synchronized` has no impact when the model is\ntrained without specifying any distribution strategy.\n\nExample usage:\n\n```python\nstrategy = tf.distribute.MirroredStrategy()\n\nwith strategy.scope():\n  model = tf.keras.Sequential()\n  model.add(tf.keras.layers.Dense(16))\n  model.add(tf.keras.layers.BatchNormalization(synchronized=True))\n```",
    "attributes": [
      {
        "default": -1,
        "description": "Integer, the axis that should be normalized (typically the features\n    axis). For instance, after a `Conv2D` layer with\n    `data_format=\"channels_first\"`, set `axis=1` in `BatchNormalization`.",
        "name": "axis"
      },
      {
        "default": 0.001,
        "description": "Small float added to variance to avoid dividing by zero.",
        "name": "epsilon"
      },
      {
        "default": 0.99,
        "description": "Momentum for the moving average.",
        "name": "momentum"
      },
      {
        "default": true,
        "description": "If True, multiply by `gamma`. If False, `gamma` is not used. When\n    the next layer is linear (also e.g. `nn.relu`), this can be disabled\n    since the scaling will be done by the next layer.",
        "name": "scale",
        "type": "boolean"
      },
      {
        "default": true,
        "description": "If True, add offset of `beta` to normalized tensor. If False,\n    `beta` is ignored.",
        "name": "center",
        "type": "boolean"
      },
      {
        "default": {
          "class_name": "Ones",
          "config": {}
        },
        "description": "Initializer for the gamma weight.",
        "name": "gamma_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "Zeros",
          "config": {}
        },
        "description": "Initializer for the moving mean.",
        "name": "moving_mean_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "Ones",
          "config": {}
        },
        "description": "Initializer for the moving variance.",
        "name": "moving_variance_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "Zeros",
          "config": {}
        },
        "description": "Initializer for the beta weight.",
        "name": "beta_initializer",
        "visible": false
      },
      {
        "description": "Optional regularizer for the beta weight.",
        "name": "beta_regularizer",
        "visible": false
      },
      {
        "description": "Optional regularizer for the gamma weight.",
        "name": "gamma_regularizer",
        "visible": false
      },
      {
        "description": "Optional constraint for the beta weight.",
        "name": "beta_constraint"
      },
      {
        "description": "Optional constraint for the gamma weight.",
        "name": "gamma_constraint"
      },
      {
        "description": "Whether to use [Batch Renormalization](\n    https://arxiv.org/abs/1702.03275). This adds extra variables during\n      training. The inference is the same for either value of this parameter.",
        "name": "renorm"
      },
      {
        "description": "A dictionary that may map keys 'rmax', 'rmin', 'dmax' to\n    scalar `Tensors` used to clip the renorm correction. The correction `(r,\n    d)` is used as `corrected_value = normalized_value * r + d`, with `r`\n    clipped to [rmin, rmax], and `d` to [-dmax, dmax]. Missing rmax, rmin,\n    dmax are set to inf, 0, inf, respectively.",
        "name": "renorm_clipping"
      },
      {
        "description": "Momentum used to update the moving means and standard\n    deviations with renorm. Unlike `momentum`, this affects training and\n    should be neither too small (which would add noise) nor too large (which\n    would give stale estimates). Note that `momentum` is still applied to get\n    the means and variances for inference.",
        "name": "renorm_momentum"
      },
      {
        "description": "if `True`, use a faster, fused implementation, or raise a ValueError\n    if the fused implementation cannot be used. If `None`, use the faster\n    implementation if possible. If False, do not used the fused\n    implementation.",
        "name": "fused"
      },
      {
        "description": "Boolean, if `True` the variables will be marked as trainable.",
        "name": "trainable"
      },
      {
        "description": "An `int`. By default, `virtual_batch_size` is `None`,\n    which means batch normalization is performed across the whole batch. When\n    `virtual_batch_size` is not `None`, instead perform \"Ghost Batch\n    Normalization\", which creates virtual sub-batches which are each\n    normalized separately (with shared gamma, beta, and moving statistics).\n    Must divide the actual batch size during execution.",
        "name": "virtual_batch_size"
      },
      {
        "description": "A function taking the `Tensor` containing the (dynamic) shape of\n    the input tensor and returning a pair (scale, bias) to apply to the\n    normalized values (before gamma and beta), only during training. For\n    example, if axis==-1,\n      `adjustment = lambda shape: (\n        tf.random.uniform(shape[-1:], 0.93, 1.07),\n        tf.random.uniform(shape[-1:], -0.1, 0.1))` will scale the normalized\n          value by up to 7% up or down, then shift the result by up to 0.1\n          (with independent scaling and bias for each feature but shared\n          across all examples), and finally apply gamma and/or beta. If\n          `None`, no adjustment is applied. Cannot be specified if\n          virtual_batch_size is specified.",
        "name": "adjustment"
      },
      {
        "name": "synchronized",
        "description": "If True, synchronizes the global batch statistics (mean and\n    variance) for the layer across all devices at each training step in a\n    distributed training strategy. If False, each replica uses its own\n    local batch statistics. Only relevant when used inside a\n    `tf.distribute` strategy."
      }
    ],
    "inputs": [
      {
        "description": "Arbitrary. Use the keyword argument `input_shape` (tuple of\nintegers, does not include the samples axis) when using this layer as the\nfirst layer in a model.",
        "name": "input"
      },
      {
        "name": "gamma"
      },
      {
        "name": "beta"
      },
      {
        "name": "moving_mean"
      },
      {
        "name": "moving_variance"
      }
    ],
    "outputs": [
      {
        "description": "Same shape as input.\n\nReference:\n  - [Ioffe and Szegedy, 2015](https://arxiv.org/abs/1502.03167).\n\n**About setting `layer.trainable = False` on a `BatchNormalization` layer:**\n\nThe meaning of setting `layer.trainable = False` is to freeze the layer,\ni.e. its internal state will not change during training:\nits trainable weights will not be updated\nduring `fit()` or `train_on_batch()`, and its state updates will not be run.\n\nUsually, this does not necessarily mean that the layer is run in inference\nmode (which is normally controlled by the `training` argument that can\nbe passed when calling a layer). \"Frozen state\" and \"inference mode\"\nare two separate concepts.\n\nHowever, in the case of the `BatchNormalization` layer, **setting\n`trainable = False` on the layer means that the layer will be\nsubsequently run in inference mode** (meaning that it will use\nthe moving mean and the moving variance to normalize the current batch,\nrather than using the mean and variance of the current batch).\n\nThis behavior has been introduced in TensorFlow 2.0, in order\nto enable `layer.trainable = False` to produce the most commonly\nexpected behavior in the convnet fine-tuning use case.\n\nNote that:\n  - Setting `trainable` on an model containing other layers will\n    recursively set the `trainable` value of all inner layers.\n  - If the value of the `trainable`\n    attribute is changed after calling `compile()` on a model,\n    the new value doesn't take effect for this model\n    until `compile()` is called again.",
        "name": "output"
      }
    ],
    "references": [
      {
        "description": "[Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)"
      }
    ]
  },
  {
    "name": "Bidirectional",
    "module": "tensorflow.keras.layers",
    "category": "Wrapper",
    "description": "Bidirectional wrapper for RNNs.",
    "attributes": [
      {
        "default": "concat",
        "description": "Mode by which outputs of the forward and backward RNNs will be\n    combined. One of {'sum', 'mul', 'concat', 'ave', None}. If None, the\n    outputs will not be combined, they will be returned as a list. Default\n    value is 'concat'.",
        "name": "merge_mode"
      },
      {
        "description": "`keras.layers.RNN` instance, such as `keras.layers.LSTM` or\n    `keras.layers.GRU`. It could also be a `keras.layers.Layer` instance\n    that meets the following criteria:\n    1. Be a sequence-processing layer (accepts 3D+ inputs).\n    2. Have a `go_backwards`, `return_sequences` and `return_state`\n      attribute (with the same semantics as for the `RNN` class).\n    3. Have an `input_spec` attribute.\n    4. Implement serialization via `get_config()` and `from_config()`.\n    Note that the recommended way to create new RNN layers is to write a\n    custom RNN cell and use it with `keras.layers.RNN`, instead of\n    subclassing `keras.layers.Layer` directly.\n    - When the `returns_sequences` is true, the output of the masked\n    timestep will be zero regardless of the layer's original\n    `zero_output_for_mask` value.",
        "name": "layer"
      },
      {
        "description": "Initial weights to load in the Bidirectional model\n",
        "name": "weights"
      },
      {
        "description": "Optional `keras.layers.RNN`, or `keras.layers.Layer`\n    instance to be used to handle backwards input processing.\n    If `backward_layer` is not provided, the layer instance passed as the\n    `layer` argument will be used to generate the backward layer\n    automatically.\n    Note that the provided `backward_layer` layer should have properties\n    matching those of the `layer` argument, in particular it should have the\n    same values for `stateful`, `return_states`, `return_sequences`, etc.\n    In addition, `backward_layer` and `layer` should have different\n    `go_backwards` argument values.\n    A `ValueError` will be raised if these requirements are not met.",
        "name": "backward_layer"
      }
    ],
    "inputs": [
      {
        "name": "input"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": "model = Sequential()\nmodel.add(Bidirectional(LSTM(10, return_sequences=True),\n                             input_shape=(5, 10)))\nmodel.add(Bidirectional(LSTM(10)))\nmodel.add(Dense(5))\nmodel.add(Activation('softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\n# With custom backward layer\nmodel = Sequential()\nforward_layer = LSTM(10, return_sequences=True)\nbackward_layer = LSTM(10, activation='relu', return_sequences=True,\n                      go_backwards=True)\nmodel.add(Bidirectional(forward_layer, backward_layer=backward_layer,\n                        input_shape=(5, 10)))\nmodel.add(Dense(5))\nmodel.add(Activation('softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
      }
    ]
  },
  {
    "name": "Concatenate",
    "module": "tensorflow.keras.layers",
    "category": "Tensor",
    "description": "Layer that concatenates a list of inputs.\n\nIt takes as input a list of tensors, all of the same shape except\nfor the concatenation axis, and returns a single tensor that is the\nconcatenation of all inputs.\n\n```\n>>> x = np.arange(20).reshape(2, 2, 5)\n>>> print(x)\n[[[ 0  1  2  3  4]\n  [ 5  6  7  8  9]]\n [[10 11 12 13 14]\n  [15 16 17 18 19]]]\n>>> y = np.arange(20, 30).reshape(2, 1, 5)\n>>> print(y)\n[[[20 21 22 23 24]]\n [[25 26 27 28 29]]]\n>>> tf.keras.layers.Concatenate(axis=1)([x, y])\n<tf.Tensor: shape=(2, 3, 5), dtype=int64, numpy=\narray([[[ 0,  1,  2,  3,  4],\n        [ 5,  6,  7,  8,  9],\n        [20, 21, 22, 23, 24]],\n       [[10, 11, 12, 13, 14],\n        [15, 16, 17, 18, 19],\n        [25, 26, 27, 28, 29]]])>\n```\n\n```\n>>> x1 = tf.keras.layers.Dense(8)(np.arange(10).reshape(5, 2))\n>>> x2 = tf.keras.layers.Dense(8)(np.arange(10, 20).reshape(5, 2))\n>>> concatted = tf.keras.layers.Concatenate()([x1, x2])\n>>> concatted.shape\nTensorShape([5, 16])\n```",
    "attributes": [
      {
        "description": "Axis along which to concatenate.",
        "name": "axis"
      },
      {
        "description": "standard layer keyword arguments.\n",
        "name": "**kwargs"
      }
    ],
    "inputs": [
      {
        "name": "inputs",
        "list": true
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ]
  },
  {
    "name": "Conv1D",
    "module": "tensorflow.keras.layers",
    "category": "Layer",
    "description": "1D convolution layer (e.g. temporal convolution).\n\nThis layer creates a convolution kernel that is convolved\nwith the layer input over a single spatial (or temporal) dimension\nto produce a tensor of outputs.\nIf `use_bias` is True, a bias vector is created and added to the outputs.\nFinally, if `activation` is not `None`,\nit is applied to the outputs as well.\n\nWhen using this layer as the first layer in a model,\nprovide an `input_shape` argument\n(tuple of integers or `None`, e.g.\n`(10, 128)` for sequences of 10 vectors of 128-dimensional vectors,\nor `(None, 128)` for variable-length sequences of 128-dimensional vectors.",
    "attributes": [
      {
        "default": "linear",
        "description": "Activation function to use.\n    If you don't specify anything, no activation is applied\n    (see `keras.activations`).",
        "name": "activation"
      },
      {
        "default": "valid",
        "description": "One of `\"valid\"`, `\"same\"` or `\"causal\"` (case-insensitive).\n    `\"valid\"` means no padding. `\"same\"` results in padding with zeros\n    evenly to the left/right or up/down of the input such that output has\n    the same height/width dimension as the input.\n    `\"causal\"` results in causal (dilated) convolutions, e.g. `output[t]`\n    does not depend on `input[t+1:]`. Useful when modeling temporal data\n    where the model should not violate the temporal order.\n    See [WaveNet: A Generative Model for Raw Audio, section\n      2.1](https://arxiv.org/abs/1609.03499).",
        "name": "padding"
      },
      {
        "default": true,
        "description": "Boolean, whether the layer uses a bias vector.",
        "name": "use_bias",
        "visible": false
      },
      {
        "default": "channels_last",
        "description": "A string, one of `channels_last` (default) or\n    `channels_first`. The ordering of the dimensions in the inputs.\n    `channels_last` corresponds to inputs with shape `(batch_size, width,\n    channels)` while `channels_first` corresponds to inputs with shape\n    `(batch_size, channels, width)`. Note that the `channels_first` format\n    is currently not supported by TensorFlow on CPU.",
        "name": "data_format"
      },
      {
        "default": [
          1
        ],
        "description": "An integer or tuple/list of a single integer,\n    specifying the stride length of the convolution.\n    Specifying any stride value != 1 is incompatible with specifying\n    any `dilation_rate` value != 1.",
        "name": "strides"
      },
      {
        "default": [
          1
        ],
        "description": "an integer or tuple/list of a single integer, specifying\n    the dilation rate to use for dilated convolution.\n    Currently, specifying any `dilation_rate` value != 1 is\n    incompatible with specifying any `strides` value != 1.",
        "name": "dilation_rate"
      },
      {
        "default": {
          "class_name": "Zeros",
          "config": {}
        },
        "description": "Initializer for the bias vector\n    (see `keras.initializers`). Defaults to 'zeros'.",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "VarianceScaling",
          "config": {
            "distribution": "uniform",
            "mode": "fan_avg",
            "scale": 1,
            "seed": null
          }
        },
        "description": "Initializer for the `kernel` weights matrix\n    (see `keras.initializers`). Defaults to 'glorot_uniform'.",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "description": "Integer, the dimensionality of the output space\n    (i.e. the number of output filters in the convolution).",
        "name": "filters"
      },
      {
        "description": "An integer or tuple/list of a single integer,\n    specifying the length of the 1D convolution window.",
        "name": "kernel_size"
      },
      {
        "description": "Regularizer function applied to\n    the `kernel` weights matrix (see `keras.regularizers`).",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the bias vector\n    (see `keras.regularizers`).",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to\n    the output of the layer (its \"activation\")\n    (see `keras.regularizers`).",
        "name": "activity_regularizer",
        "visible": false
      },
      {
        "description": "Constraint function applied to the kernel matrix\n    (see `keras.constraints`).",
        "name": "kernel_constraint"
      },
      {
        "description": "Constraint function applied to the bias vector\n    (see `keras.constraints`).",
        "name": "bias_constraint"
      },
      {
        "description": "A positive integer specifying the number of groups in which the\n    input is split along the channel axis. Each group is convolved\n    separately with `filters / groups` filters. The output is the\n    concatenation of all the `groups` results along the channel axis.\n    Input channels and `filters` must both be divisible by `groups`.",
        "name": "groups"
      }
    ],
    "inputs": [
      {
        "description": "3+D tensor with shape: `batch_shape + (steps, input_dim)`",
        "name": "input"
      },
      {
        "name": "kernel"
      },
      {
        "name": "bias"
      }
    ],
    "outputs": [
      {
        "description": "3+D tensor with shape: `batch_shape + (new_steps, filters)`\n  `steps` value might have changed due to padding or strides.",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> # The inputs are 128-length vectors with 10 timesteps, and the\n>>> # batch size is 4.\n>>> input_shape = (4, 10, 128)\n>>> x = tf.random.normal(input_shape)\n>>> y = tf.keras.layers.Conv1D(\n... 32, 3, activation='relu',input_shape=input_shape[1:])(x)\n>>> print(y.shape)\n(4, 8, 32)"
      },
      {
        "code": ">>> # With extended batch shape [4, 7] (e.g. weather data where batch\n>>> # dimensions correspond to spatial location and the third dimension\n>>> # corresponds to time.)\n>>> input_shape = (4, 7, 10, 128)\n>>> x = tf.random.normal(input_shape)\n>>> y = tf.keras.layers.Conv1D(\n... 32, 3, activation='relu', input_shape=input_shape[2:])(x)\n>>> print(y.shape)\n(4, 7, 8, 32)"
      }
    ]
  },
  {
    "name": "Conv2D",
    "module": "tensorflow.keras.layers",
    "category": "Layer",
    "description": "2D convolution layer (e.g. spatial convolution over images).\n\nThis layer creates a convolution kernel that is convolved\nwith the layer input to produce a tensor of\noutputs. If `use_bias` is True,\na bias vector is created and added to the outputs. Finally, if\n`activation` is not `None`, it is applied to the outputs as well.\n\nWhen using this layer as the first layer in a model,\nprovide the keyword argument `input_shape`\n(tuple of integers or `None`, does not include the sample axis),\ne.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\nin `data_format=\"channels_last\"`. You can use `None` when\na dimension has variable size.",
    "attributes": [
      {
        "default": "linear",
        "description": "Activation function to use. If you don't specify anything, no\n    activation is applied (see `keras.activations`).",
        "name": "activation"
      },
      {
        "default": "valid",
        "description": "one of `\"valid\"` or `\"same\"` (case-insensitive).\n    `\"valid\"` means no padding. `\"same\"` results in padding with zeros\n    evenly to the left/right or up/down of the input. When `padding=\"same\"`\n    and `strides=1`, the output has the same size as the input.",
        "name": "padding"
      },
      {
        "default": true,
        "description": "Boolean, whether the layer uses a bias vector.",
        "name": "use_bias",
        "type": "boolean",
        "visible": false
      },
      {
        "default": "channels_last",
        "description": "A string, one of `channels_last` (default) or\n    `channels_first`.  The ordering of the dimensions in the inputs.\n    `channels_last` corresponds to inputs with shape `(batch_size, height,\n    width, channels)` while `channels_first` corresponds to inputs with\n    shape `(batch_size, channels, height, width)`. It defaults to the\n    `image_data_format` value found in your Keras config file at\n    `~/.keras/keras.json`. If you never set it, then it will be\n    `channels_last`. Note that the `channels_first` format is currently not\n    supported by TensorFlow on CPU.",
        "name": "data_format"
      },
      {
        "default": [
          1,
          1
        ],
        "description": "An integer or tuple/list of 2 integers, specifying the strides of\n    the convolution along the height and width. Can be a single integer to\n    specify the same value for all spatial dimensions. Specifying any stride\n    value != 1 is incompatible with specifying any `dilation_rate` value !=\n    1.",
        "name": "strides"
      },
      {
        "default": [
          1,
          1
        ],
        "description": "an integer or tuple/list of 2 integers, specifying the\n    dilation rate to use for dilated convolution. Can be a single integer to\n    specify the same value for all spatial dimensions. Currently, specifying\n    any `dilation_rate` value != 1 is incompatible with specifying any\n    stride value != 1.",
        "name": "dilation_rate"
      },
      {
        "default": {
          "class_name": "Zeros",
          "config": {}
        },
        "description": "Initializer for the bias vector (see\n    `keras.initializers`). Defaults to 'zeros'.",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "VarianceScaling",
          "config": {
            "distribution": "uniform",
            "mode": "fan_avg",
            "scale": 1,
            "seed": null
          }
        },
        "description": "Initializer for the `kernel` weights matrix (see\n    `keras.initializers`). Defaults to 'glorot_uniform'.",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "description": "Integer, the dimensionality of the output space (i.e. the number\n    of output filters in the convolution).",
        "name": "filters"
      },
      {
        "description": "An integer or tuple/list of 2 integers, specifying the height\n    and width of the 2D convolution window. Can be a single integer to\n    specify the same value for all spatial dimensions.",
        "name": "kernel_size"
      },
      {
        "description": "Regularizer function applied to the `kernel` weights\n    matrix (see `keras.regularizers`).",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the bias vector (see\n    `keras.regularizers`).",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the output of the\n    layer (its \"activation\") (see `keras.regularizers`).",
        "name": "activity_regularizer",
        "visible": false
      },
      {
        "description": "Constraint function applied to the kernel matrix (see\n    `keras.constraints`).",
        "name": "kernel_constraint",
        "visible": false
      },
      {
        "description": "Constraint function applied to the bias vector (see\n    `keras.constraints`).",
        "name": "bias_constraint",
        "visible": false
      },
      {
        "description": "A positive integer specifying the number of groups in which the\n    input is split along the channel axis. Each group is convolved\n    separately with `filters / groups` filters. The output is the\n    concatenation of all the `groups` results along the channel axis. Input\n    channels and `filters` must both be divisible by `groups`.",
        "name": "groups"
      }
    ],
    "inputs": [
      {
        "description": "4+D tensor with shape: `batch_shape + (channels, rows, cols)` if\n  `data_format='channels_first'`\nor 4+D tensor with shape: `batch_shape + (rows, cols, channels)` if\n  `data_format='channels_last'`.",
        "name": "input"
      },
      {
        "name": "kernel"
      },
      {
        "name": "bias"
      }
    ],
    "outputs": [
      {
        "description": "4+D tensor with shape: `batch_shape + (filters, new_rows, new_cols)` if\n`data_format='channels_first'` or 4+D tensor with shape: `batch_shape +\n  (new_rows, new_cols, filters)` if `data_format='channels_last'`.  `rows`\n  and `cols` values might have changed due to padding.",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> # The inputs are 28x28 RGB images with `channels_last` and the batch\n>>> # size is 4.\n>>> input_shape = (4, 28, 28, 3)\n>>> x = tf.random.normal(input_shape)\n>>> y = tf.keras.layers.Conv2D(\n... 2, 3, activation='relu', input_shape=input_shape[1:])(x)\n>>> print(y.shape)\n(4, 26, 26, 2)"
      },
      {
        "code": ">>> # With `dilation_rate` as 2.\n>>> input_shape = (4, 28, 28, 3)\n>>> x = tf.random.normal(input_shape)\n>>> y = tf.keras.layers.Conv2D(\n...     2, 3,\n...     activation='relu',\n...     dilation_rate=2,\n...     input_shape=input_shape[1:])(x)\n>>> print(y.shape)\n(4, 24, 24, 2)"
      },
      {
        "code": ">>> # With `padding` as \"same\".\n>>> input_shape = (4, 28, 28, 3)\n>>> x = tf.random.normal(input_shape)\n>>> y = tf.keras.layers.Conv2D(\n... 2, 3, activation='relu', padding=\"same\", input_shape=input_shape[1:])(x)\n>>> print(y.shape)\n(4, 28, 28, 2)"
      },
      {
        "code": ">>> # With extended batch shape [4, 7]:\n>>> input_shape = (4, 7, 28, 28, 3)\n>>> x = tf.random.normal(input_shape)\n>>> y = tf.keras.layers.Conv2D(\n... 2, 3, activation='relu', input_shape=input_shape[2:])(x)\n>>> print(y.shape)\n(4, 7, 26, 26, 2)"
      }
    ]
  },
  {
    "name": "Conv2DTranspose",
    "module": "tensorflow.keras.layers",
    "category": "Layer",
    "description": "Transposed convolution layer (sometimes called Deconvolution).\n\nThe need for transposed convolutions generally arises\nfrom the desire to use a transformation going in the opposite direction\nof a normal convolution, i.e., from something that has the shape of the\noutput of some convolution to something that has the shape of its input\nwhile maintaining a connectivity pattern that is compatible with\nsaid convolution.\n\nWhen using this layer as the first layer in a model,\nprovide the keyword argument `input_shape`\n(tuple of integers or `None`, does not include the sample axis),\ne.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\nin `data_format=\"channels_last\"`.",
    "attributes": [
      {
        "description": "Integer, the dimensionality of the output space\n    (i.e. the number of output filters in the convolution).",
        "name": "filters"
      },
      {
        "description": "An integer or tuple/list of 2 integers, specifying the\n    height and width of the 2D convolution window.\n    Can be a single integer to specify the same value for\n    all spatial dimensions.",
        "name": "kernel_size"
      },
      {
        "description": "An integer or tuple/list of 2 integers,\n    specifying the strides of the convolution along the height and width.\n    Can be a single integer to specify the same value for\n    all spatial dimensions.\n    Specifying any stride value != 1 is incompatible with specifying\n    any `dilation_rate` value != 1.",
        "name": "strides"
      },
      {
        "description": "one of `\"valid\"` or `\"same\"` (case-insensitive).\n    `\"valid\"` means no padding. `\"same\"` results in padding with zeros\n    evenly to the left/right or up/down of the input such that output has\n    the same height/width dimension as the input.",
        "name": "padding"
      },
      {
        "default": "channels_last",
        "description": "A string,\n    one of `channels_last` (default) or `channels_first`.\n    The ordering of the dimensions in the inputs.\n    `channels_last` corresponds to inputs with shape\n    `(batch_size, height, width, channels)` while `channels_first`\n    corresponds to inputs with shape\n    `(batch_size, channels, height, width)`.\n    It defaults to the `image_data_format` value found in your\n    Keras config file at `~/.keras/keras.json`.\n    If you never set it, then it will be \"channels_last\".",
        "name": "data_format"
      },
      {
        "description": "an integer, specifying the dilation rate for all spatial\n    dimensions for dilated convolution. Specifying different dilation rates\n    for different dimensions is not supported.\n    Currently, specifying any `dilation_rate` value != 1 is\n    incompatible with specifying any stride value != 1.",
        "name": "dilation_rate"
      },
      {
        "description": "Activation function to use.\n    If you don't specify anything, no activation is applied\n    (see `keras.activations`).",
        "name": "activation"
      },
      {
        "default": true,
        "description": "Boolean, whether the layer uses a bias vector.",
        "name": "use_bias",
        "visible": false
      },
      {
        "default": {
          "class_name": "VarianceScaling",
          "config": {
            "distribution": "uniform",
            "mode": "fan_avg",
            "scale": 1,
            "seed": null
          }
        },
        "description": "Initializer for the `kernel` weights matrix\n    (see `keras.initializers`). Defaults to 'glorot_uniform'.",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "Zeros",
          "config": {}
        },
        "description": "Initializer for the bias vector\n    (see `keras.initializers`). Defaults to 'zeros'.",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to\n    the `kernel` weights matrix (see `keras.regularizers`).",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the bias vector\n    (see `keras.regularizers`).",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to\n    the output of the layer (its \"activation\") (see `keras.regularizers`).",
        "name": "activity_regularizer",
        "visible": false
      },
      {
        "description": "Constraint function applied to the kernel matrix\n    (see `keras.constraints`).",
        "name": "kernel_constraint"
      },
      {
        "description": "Constraint function applied to the bias vector\n    (see `keras.constraints`).",
        "name": "bias_constraint"
      },
      {
        "description": "An integer or tuple/list of 2 integers,\n    specifying the amount of padding along the height and width\n    of the output tensor.\n    Can be a single integer to specify the same value for all\n    spatial dimensions.\n    The amount of output padding along a given dimension must be\n    lower than the stride along that same dimension.\n    If set to `None` (default), the output shape is inferred.",
        "name": "output_padding"
      }
    ],
    "inputs": [
      {
        "description": "4D tensor with shape:\n`(batch_size, channels, rows, cols)` if data_format='channels_first'\nor 4D tensor with shape:\n`(batch_size, rows, cols, channels)` if data_format='channels_last'.",
        "name": "input"
      },
      {
        "name": "kernel"
      },
      {
        "name": "bias"
      }
    ],
    "outputs": [
      {
        "description": "4D tensor with shape:\n`(batch_size, filters, new_rows, new_cols)` if\ndata_format='channels_first'\nor 4D tensor with shape:\n`(batch_size, new_rows, new_cols, filters)` if\ndata_format='channels_last'.  `rows` and `cols` values might have changed\ndue to padding.\nIf `output_padding` is specified:\n```\nnew_rows = ((rows - 1) * strides[0] + kernel_size[0] - 2 * padding[0] +\noutput_padding[0])\nnew_cols = ((cols - 1) * strides[1] + kernel_size[1] - 2 * padding[1] +\noutput_padding[1])\n```",
        "name": "output"
      }
    ],
    "references": [
      {
        "description": "[A guide to convolution arithmetic for deep learning](https://arxiv.org/abs/1603.07285v1)"
      },
      {
        "description": "[Deconvolutional Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)"
      }
    ]
  },
  {
    "name": "Conv3D",
    "module": "tensorflow.keras.layers",
    "category": "Layer",
    "description": "3D convolution layer (e.g. spatial convolution over volumes).\n\nThis layer creates a convolution kernel that is convolved\nwith the layer input to produce a tensor of\noutputs. If `use_bias` is True,\na bias vector is created and added to the outputs. Finally, if\n`activation` is not `None`, it is applied to the outputs as well.\n\nWhen using this layer as the first layer in a model,\nprovide the keyword argument `input_shape`\n(tuple of integers or `None`, does not include the sample axis),\ne.g. `input_shape=(128, 128, 128, 1)` for 128x128x128 volumes\nwith a single channel,\nin `data_format=\"channels_last\"`.",
    "attributes": [
      {
        "description": "Integer, the dimensionality of the output space (i.e. the number\n    of output filters in the convolution).",
        "name": "filters"
      },
      {
        "description": "An integer or tuple/list of 3 integers, specifying the depth,\n    height and width of the 3D convolution window. Can be a single integer\n    to specify the same value for all spatial dimensions.",
        "name": "kernel_size"
      },
      {
        "description": "An integer or tuple/list of 3 integers, specifying the strides of\n    the convolution along each spatial dimension. Can be a single integer to\n    specify the same value for all spatial dimensions. Specifying any stride\n    value != 1 is incompatible with specifying any `dilation_rate` value !=\n    1.",
        "name": "strides"
      },
      {
        "description": "one of `\"valid\"` or `\"same\"` (case-insensitive).\n    `\"valid\"` means no padding. `\"same\"` results in padding with zeros\n    evenly to the left/right or up/down of the input such that output has\n    the same height/width dimension as the input.",
        "name": "padding"
      },
      {
        "description": "A string, one of `channels_last` (default) or\n    `channels_first`.  The ordering of the dimensions in the inputs.\n    `channels_last` corresponds to inputs with shape `batch_shape +\n    (spatial_dim1, spatial_dim2, spatial_dim3, channels)` while\n    `channels_first` corresponds to inputs with shape `batch_shape +\n    (channels, spatial_dim1, spatial_dim2, spatial_dim3)`. It defaults to\n    the `image_data_format` value found in your Keras config file at\n    `~/.keras/keras.json`. If you never set it, then it will be\n    \"channels_last\". Note that the `channels_first` format is currently not\n    supported by TensorFlow on CPU.",
        "name": "data_format"
      },
      {
        "description": "an integer or tuple/list of 3 integers, specifying the\n    dilation rate to use for dilated convolution. Can be a single integer to\n    specify the same value for all spatial dimensions. Currently, specifying\n    any `dilation_rate` value != 1 is incompatible with specifying any\n    stride value != 1.",
        "name": "dilation_rate"
      },
      {
        "description": "Activation function to use. If you don't specify anything, no\n    activation is applied (see `keras.activations`).",
        "name": "activation"
      },
      {
        "default": true,
        "description": "Boolean, whether the layer uses a bias vector.",
        "name": "use_bias",
        "visible": false
      },
      {
        "description": "Initializer for the `kernel` weights matrix (see\n    `keras.initializers`). Defaults to 'glorot_uniform'.",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "description": "Initializer for the bias vector (see\n    `keras.initializers`). Defaults to 'zeros'.",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the `kernel` weights\n    matrix (see `keras.regularizers`).",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the bias vector (see\n    `keras.regularizers`).",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the output of the\n    layer (its \"activation\") (see `keras.regularizers`).",
        "name": "activity_regularizer",
        "visible": false
      },
      {
        "description": "Constraint function applied to the kernel matrix (see\n    `keras.constraints`).",
        "name": "kernel_constraint"
      },
      {
        "description": "Constraint function applied to the bias vector (see\n    `keras.constraints`).",
        "name": "bias_constraint"
      },
      {
        "description": "A positive integer specifying the number of groups in which the\n    input is split along the channel axis. Each group is convolved\n    separately with `filters / groups` filters. The output is the\n    concatenation of all the `groups` results along the channel axis. Input\n    channels and `filters` must both be divisible by `groups`.",
        "name": "groups"
      }
    ],
    "inputs": [
      {
        "description": "5+D tensor with shape: `batch_shape + (channels, conv_dim1, conv_dim2,\n  conv_dim3)` if data_format='channels_first'\nor 5+D tensor with shape: `batch_shape + (conv_dim1, conv_dim2, conv_dim3,\n  channels)` if data_format='channels_last'.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "5+D tensor with shape: `batch_shape + (filters, new_conv_dim1,\n  new_conv_dim2, new_conv_dim3)` if data_format='channels_first'\nor 5+D tensor with shape: `batch_shape + (new_conv_dim1, new_conv_dim2,\n  new_conv_dim3, filters)` if data_format='channels_last'.\n  `new_conv_dim1`, `new_conv_dim2` and `new_conv_dim3` values might have\n  changed due to padding.",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> # The inputs are 28x28x28 volumes with a single channel, and the\n>>> # batch size is 4\n>>> input_shape =(4, 28, 28, 28, 1)\n>>> x = tf.random.normal(input_shape)\n>>> y = tf.keras.layers.Conv3D(\n... 2, 3, activation='relu', input_shape=input_shape[1:])(x)\n>>> print(y.shape)\n(4, 26, 26, 26, 2)"
      },
      {
        "code": ">>> # With extended batch shape [4, 7], e.g. a batch of 4 videos of\n>>> # 3D frames, with 7 frames per video.\n>>> input_shape = (4, 7, 28, 28, 28, 1)\n>>> x = tf.random.normal(input_shape)\n>>> y = tf.keras.layers.Conv3D(\n... 2, 3, activation='relu', input_shape=input_shape[2:])(x)\n>>> print(y.shape)\n(4, 7, 26, 26, 26, 2)"
      }
    ]
  },
  {
    "name": "ConvLSTM2D",
    "module": "tensorflow.keras.layers",
    "description": "2D Convolutional LSTM.\n\nSimilar to an LSTM layer, but the input transformations\nand recurrent transformations are both convolutional.",
    "attributes": [
      {
        "description": "Integer, the dimensionality of the output space (i.e. the number\n    of output filters in the convolution).",
        "name": "filters"
      },
      {
        "description": "An integer or tuple/list of n integers, specifying the\n    dimensions of the convolution window.",
        "name": "kernel_size"
      },
      {
        "description": "An integer or tuple/list of n integers, specifying the strides of\n    the convolution. Specifying any stride value != 1 is incompatible with\n    specifying any `dilation_rate` value != 1.",
        "name": "strides"
      },
      {
        "description": "One of `\"valid\"` or `\"same\"` (case-insensitive). `\"valid\"` means\n    no padding. `\"same\"` results in padding evenly to the left/right or\n    up/down of the input such that output has the same height/width\n    dimension as the input.",
        "name": "padding"
      },
      {
        "default": "channels_last",
        "description": "A string, one of `channels_last` (default) or\n    `channels_first`.  The ordering of the dimensions in the inputs.\n    `channels_last` corresponds to inputs with shape `(batch, time, ...,\n    channels)` while `channels_first` corresponds to inputs with shape\n    `(batch, time, channels, ...)`. It defaults to the `image_data_format`\n    value found in your Keras config file at `~/.keras/keras.json`. If you\n    never set it, then it will be \"channels_last\".",
        "name": "data_format"
      },
      {
        "description": "An integer or tuple/list of n integers, specifying the\n    dilation rate to use for dilated convolution. Currently, specifying any\n    `dilation_rate` value != 1 is incompatible with specifying any `strides`\n    value != 1.",
        "name": "dilation_rate"
      },
      {
        "description": "Activation function to use. By default hyperbolic tangent\n    activation function is applied (`tanh(x)`).",
        "name": "activation"
      },
      {
        "description": "Activation function to use for the recurrent step.",
        "name": "recurrent_activation"
      },
      {
        "default": true,
        "description": "Boolean, whether the layer uses a bias vector.",
        "name": "use_bias",
        "visible": false
      },
      {
        "description": "Initializer for the `kernel` weights matrix, used for\n    the linear transformation of the inputs.",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "description": "Initializer for the `recurrent_kernel` weights\n    matrix, used for the linear transformation of the recurrent state.",
        "name": "recurrent_initializer",
        "visible": false
      },
      {
        "description": "Initializer for the bias vector.",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "description": "Boolean. If True, add 1 to the bias of the forget gate\n    at initialization. Use in combination with `bias_initializer=\"zeros\"`.\n    This is recommended in [Jozefowicz et al., 2015](\n    http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf)",
        "name": "unit_forget_bias"
      },
      {
        "description": "Regularizer function applied to the `kernel` weights\n    matrix.",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the\n    `recurrent_kernel` weights matrix.",
        "name": "recurrent_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the bias vector.",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to.",
        "name": "activity_regularizer",
        "visible": false
      },
      {
        "description": "Constraint function applied to the `kernel` weights\n    matrix.",
        "name": "kernel_constraint",
        "visible": false
      },
      {
        "description": "Constraint function applied to the\n    `recurrent_kernel` weights matrix.",
        "name": "recurrent_constraint",
        "visible": false
      },
      {
        "description": "Constraint function applied to the bias vector.",
        "name": "bias_constraint",
        "visible": false
      },
      {
        "description": "Boolean. Whether to return the last output in the output\n    sequence, or the full sequence. (default False)",
        "name": "return_sequences"
      },
      {
        "description": "Boolean (default False). If True, process the input sequence\n    backwards.",
        "name": "go_backwards"
      },
      {
        "description": "Boolean (default False). If True, the last state for each sample\n    at index i in a batch will be used as initial state for the sample of\n    index i in the following batch.",
        "name": "stateful"
      },
      {
        "default": 0,
        "description": "Float between 0 and 1. Fraction of the units to drop for the\n    linear transformation of the inputs.",
        "name": "dropout"
      },
      {
        "description": "Float between 0 and 1. Fraction of the units to drop\n    for the linear transformation of the recurrent state.",
        "name": "recurrent_dropout"
      },
      {
        "description": "Boolean Whether to return the last state in addition to the\n    output. (default False)",
        "name": "return_state"
      }
    ],
    "inputs": [
      {
        "description": "- If data_format='channels_first'\n    5D tensor with shape:\n    `(samples, time, channels, rows, cols)`\n- If data_format='channels_last'\n    5D tensor with shape:\n    `(samples, time, rows, cols, channels)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "- If `return_state`: a list of tensors. The first tensor is the output.\n  The remaining tensors are the last states,\n  each 4D tensor with shape: `(samples, filters, new_rows, new_cols)` if\n    data_format='channels_first'\n  or shape: `(samples, new_rows, new_cols, filters)` if\n    data_format='channels_last'. `rows` and `cols` values might have\n    changed due to padding.\n- If `return_sequences`: 5D tensor with shape: `(samples, timesteps,\n  filters, new_rows, new_cols)` if data_format='channels_first'\n  or shape: `(samples, timesteps, new_rows, new_cols, filters)` if\n    data_format='channels_last'.\n- Else, 4D tensor with shape: `(samples, filters, new_rows, new_cols)` if\n  data_format='channels_first'\n  or shape: `(samples, new_rows, new_cols, filters)` if\n    data_format='channels_last'.",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": "steps = 10\nheight = 32\nwidth = 32\ninput_channels = 3\noutput_channels = 6\n\ninputs = tf.keras.Input(shape=(steps, height, width, input_channels))\nlayer = tf.keras.layers.ConvLSTM2D(filters=output_channels, kernel_size=3)\noutputs = layer(inputs)"
      }
    ],
    "references": [
      {
        "description": "[Shi et al., 2015](http://arxiv.org/abs/1506.04214v1) (the current implementation does not include the feedback loop on the cells output)."
      }
    ]
  },
  {
    "name": "Convolution2D",
    "module": "tensorflow.keras.layers",
    "category": "Layer",
    "description": "2D convolution layer (e.g. spatial convolution over images).\n\nThis layer creates a convolution kernel that is convolved\nwith the layer input to produce a tensor of\noutputs. If `use_bias` is True,\na bias vector is created and added to the outputs. Finally, if\n`activation` is not `None`, it is applied to the outputs as well.\n\nWhen using this layer as the first layer in a model,\nprovide the keyword argument `input_shape`\n(tuple of integers or `None`, does not include the sample axis),\ne.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\nin `data_format=\"channels_last\"`. You can use `None` when\na dimension has variable size.",
    "attributes": [
      {
        "default": "linear",
        "description": "Activation function to use. If you don't specify anything, no\n    activation is applied (see `keras.activations`).",
        "name": "activation"
      },
      {
        "default": "valid",
        "description": "one of `\"valid\"` or `\"same\"` (case-insensitive).\n    `\"valid\"` means no padding. `\"same\"` results in padding with zeros\n    evenly to the left/right or up/down of the input. When `padding=\"same\"`\n    and `strides=1`, the output has the same size as the input.",
        "name": "padding"
      },
      {
        "default": true,
        "description": "Boolean, whether the layer uses a bias vector.",
        "name": "use_bias",
        "visible": false
      },
      {
        "default": "channels_last",
        "description": "A string, one of `channels_last` (default) or\n    `channels_first`.  The ordering of the dimensions in the inputs.\n    `channels_last` corresponds to inputs with shape `(batch_size, height,\n    width, channels)` while `channels_first` corresponds to inputs with\n    shape `(batch_size, channels, height, width)`. It defaults to the\n    `image_data_format` value found in your Keras config file at\n    `~/.keras/keras.json`. If you never set it, then it will be\n    `channels_last`. Note that the `channels_first` format is currently not\n    supported by TensorFlow on CPU.",
        "name": "data_format"
      },
      {
        "default": [
          1,
          1
        ],
        "description": "An integer or tuple/list of 2 integers, specifying the strides of\n    the convolution along the height and width. Can be a single integer to\n    specify the same value for all spatial dimensions. Specifying any stride\n    value != 1 is incompatible with specifying any `dilation_rate` value !=\n    1.",
        "name": "strides"
      },
      {
        "default": [
          1,
          1
        ],
        "description": "an integer or tuple/list of 2 integers, specifying the\n    dilation rate to use for dilated convolution. Can be a single integer to\n    specify the same value for all spatial dimensions. Currently, specifying\n    any `dilation_rate` value != 1 is incompatible with specifying any\n    stride value != 1.",
        "name": "dilation_rate"
      },
      {
        "default": 1,
        "name": "depth_multiplier"
      },
      {
        "default": {
          "class_name": "Zeros",
          "config": {}
        },
        "description": "Initializer for the bias vector (see\n    `keras.initializers`). Defaults to 'zeros'.",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "VarianceScaling",
          "config": {
            "distribution": "uniform",
            "mode": "fan_avg",
            "scale": 1,
            "seed": null
          }
        },
        "description": "Initializer for the `kernel` weights matrix (see\n    `keras.initializers`). Defaults to 'glorot_uniform'.",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "description": "Integer, the dimensionality of the output space (i.e. the number\n    of output filters in the convolution).",
        "name": "filters"
      },
      {
        "description": "An integer or tuple/list of 2 integers, specifying the height\n    and width of the 2D convolution window. Can be a single integer to\n    specify the same value for all spatial dimensions.",
        "name": "kernel_size"
      },
      {
        "description": "Regularizer function applied to the `kernel` weights\n    matrix (see `keras.regularizers`).",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the bias vector (see\n    `keras.regularizers`).",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the output of the\n    layer (its \"activation\") (see `keras.regularizers`).",
        "name": "activity_regularizer",
        "visible": false
      },
      {
        "description": "Constraint function applied to the kernel matrix (see\n    `keras.constraints`).",
        "name": "kernel_constraint"
      },
      {
        "description": "Constraint function applied to the bias vector (see\n    `keras.constraints`).",
        "name": "bias_constraint"
      },
      {
        "description": "A positive integer specifying the number of groups in which the\n    input is split along the channel axis. Each group is convolved\n    separately with `filters / groups` filters. The output is the\n    concatenation of all the `groups` results along the channel axis. Input\n    channels and `filters` must both be divisible by `groups`.",
        "name": "groups"
      }
    ],
    "inputs": [
      {
        "description": "4+D tensor with shape: `batch_shape + (channels, rows, cols)` if\n  `data_format='channels_first'`\nor 4+D tensor with shape: `batch_shape + (rows, cols, channels)` if\n  `data_format='channels_last'`.",
        "name": "input"
      },
      {
        "name": "kernel"
      },
      {
        "name": "bias"
      }
    ],
    "outputs": [
      {
        "description": "4+D tensor with shape: `batch_shape + (filters, new_rows, new_cols)` if\n`data_format='channels_first'` or 4+D tensor with shape: `batch_shape +\n  (new_rows, new_cols, filters)` if `data_format='channels_last'`.  `rows`\n  and `cols` values might have changed due to padding.",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> # The inputs are 28x28 RGB images with `channels_last` and the batch\n>>> # size is 4.\n>>> input_shape = (4, 28, 28, 3)\n>>> x = tf.random.normal(input_shape)\n>>> y = tf.keras.layers.Conv2D(\n... 2, 3, activation='relu', input_shape=input_shape[1:])(x)\n>>> print(y.shape)\n(4, 26, 26, 2)"
      },
      {
        "code": ">>> # With `dilation_rate` as 2.\n>>> input_shape = (4, 28, 28, 3)\n>>> x = tf.random.normal(input_shape)\n>>> y = tf.keras.layers.Conv2D(\n...     2, 3,\n...     activation='relu',\n...     dilation_rate=2,\n...     input_shape=input_shape[1:])(x)\n>>> print(y.shape)\n(4, 24, 24, 2)"
      },
      {
        "code": ">>> # With `padding` as \"same\".\n>>> input_shape = (4, 28, 28, 3)\n>>> x = tf.random.normal(input_shape)\n>>> y = tf.keras.layers.Conv2D(\n... 2, 3, activation='relu', padding=\"same\", input_shape=input_shape[1:])(x)\n>>> print(y.shape)\n(4, 28, 28, 2)"
      },
      {
        "code": ">>> # With extended batch shape [4, 7]:\n>>> input_shape = (4, 7, 28, 28, 3)\n>>> x = tf.random.normal(input_shape)\n>>> y = tf.keras.layers.Conv2D(\n... 2, 3, activation='relu', input_shape=input_shape[2:])(x)\n>>> print(y.shape)\n(4, 7, 26, 26, 2)"
      }
    ]
  },
  {
    "name": "Cropping1D",
    "module": "tensorflow.keras.layers",
    "category": "Shape",
    "description": "Cropping layer for 1D input (e.g. temporal sequence).\n\nIt crops along the time dimension (axis 1).",
    "attributes": [
      {
        "description": "Int or tuple of int (length 2)\n    How many units should be trimmed off at the beginning and end of\n    the cropping dimension (axis 1).\n    If a single int is provided, the same value will be used for both.",
        "name": "cropping"
      }
    ],
    "inputs": [
      {
        "description": "3D tensor with shape `(batch_size, axis_to_crop, features)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "3D tensor with shape `(batch_size, cropped_axis, features)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> input_shape = (2, 3, 2)\n>>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n>>> print(x)\n[[[ 0  1]\n  [ 2  3]\n  [ 4  5]]\n [[ 6  7]\n  [ 8  9]\n  [10 11]]]\n>>> y = tf.keras.layers.Cropping1D(cropping=1)(x)\n>>> print(y)\ntf.Tensor(\n  [[[2 3]]\n   [[8 9]]], shape=(2, 1, 2), dtype=int64)"
      }
    ]
  },
  {
    "name": "Cropping2D",
    "module": "tensorflow.keras.layers",
    "category": "Shape",
    "description": "Cropping layer for 2D input (e.g. picture).\n\nIt crops along spatial dimensions, i.e. height and width.",
    "attributes": [
      {
        "description": "Int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n    - If int: the same symmetric cropping\n      is applied to height and width.\n    - If tuple of 2 ints:\n      interpreted as two different\n      symmetric cropping values for height and width:\n      `(symmetric_height_crop, symmetric_width_crop)`.\n    - If tuple of 2 tuples of 2 ints:\n      interpreted as\n      `((top_crop, bottom_crop), (left_crop, right_crop))`",
        "name": "cropping"
      },
      {
        "description": "A string,\n    one of `channels_last` (default) or `channels_first`.\n    The ordering of the dimensions in the inputs.\n    `channels_last` corresponds to inputs with shape\n    `(batch_size, height, width, channels)` while `channels_first`\n    corresponds to inputs with shape\n    `(batch_size, channels, height, width)`.\n    It defaults to the `image_data_format` value found in your\n    Keras config file at `~/.keras/keras.json`.\n    If you never set it, then it will be \"channels_last\".",
        "name": "data_format"
      }
    ],
    "inputs": [
      {
        "description": "4D tensor with shape:\n- If `data_format` is `\"channels_last\"`:\n  `(batch_size, rows, cols, channels)`\n- If `data_format` is `\"channels_first\"`:\n  `(batch_size, channels, rows, cols)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "4D tensor with shape:\n- If `data_format` is `\"channels_last\"`:\n  `(batch_size, cropped_rows, cropped_cols, channels)`\n- If `data_format` is `\"channels_first\"`:\n  `(batch_size, channels, cropped_rows, cropped_cols)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> input_shape = (2, 28, 28, 3)\n>>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n>>> y = tf.keras.layers.Cropping2D(cropping=((2, 2), (4, 4)))(x)\n>>> print(y.shape)\n(2, 24, 20, 3)"
      }
    ]
  },
  {
    "name": "Cropping3D",
    "module": "tensorflow.keras.layers",
    "category": "Shape",
    "description": "Cropping layer for 3D data (e.g. spatial or spatio-temporal).\n\n  Examples:\n\n```\n>>> input_shape = (2, 28, 28, 10, 3)\n>>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n>>> y = tf.keras.layers.Cropping3D(cropping=(2, 4, 2))(x)\n>>> print(y.shape)\n(2, 24, 20, 6, 3)\n```",
    "attributes": [
      {
        "description": "Int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.\n    - If int: the same symmetric cropping\n      is applied to depth, height, and width.\n    - If tuple of 3 ints: interpreted as two different\n      symmetric cropping values for depth, height, and width:\n      `(symmetric_dim1_crop, symmetric_dim2_crop, symmetric_dim3_crop)`.\n    - If tuple of 3 tuples of 2 ints: interpreted as\n      `((left_dim1_crop, right_dim1_crop), (left_dim2_crop,\n        right_dim2_crop), (left_dim3_crop, right_dim3_crop))`",
        "name": "cropping"
      },
      {
        "description": "A string,\n    one of `channels_last` (default) or `channels_first`.\n    The ordering of the dimensions in the inputs.\n    `channels_last` corresponds to inputs with shape\n    `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n    while `channels_first` corresponds to inputs with shape\n    `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n    It defaults to the `image_data_format` value found in your\n    Keras config file at `~/.keras/keras.json`.\n    If you never set it, then it will be \"channels_last\".",
        "name": "data_format"
      }
    ],
    "inputs": [
      {
        "description": "5D tensor with shape:\n- If `data_format` is `\"channels_last\"`:\n  `(batch_size, first_axis_to_crop, second_axis_to_crop,\n  third_axis_to_crop, depth)`\n- If `data_format` is `\"channels_first\"`:\n  `(batch_size, depth, first_axis_to_crop, second_axis_to_crop,\n    third_axis_to_crop)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "5D tensor with shape:\n- If `data_format` is `\"channels_last\"`:\n  `(batch_size, first_cropped_axis, second_cropped_axis,\n  third_cropped_axis, depth)`\n- If `data_format` is `\"channels_first\"`:\n  `(batch_size, depth, first_cropped_axis, second_cropped_axis,\n    third_cropped_axis)`",
        "name": "output"
      }
    ]
  },
  {
    "name": "CuDNNGRU",
    "description": "Fast GRU implementation backed by [CuDNN](https://developer.nvidia.com/cudnn).\n\nCan only be run on GPU, with the TensorFlow backend.\n",
    "attributes": [
      {
        "description": "Positive integer, dimensionality of the output space.",
        "name": "units"
      },
      {
        "description": "Initializer for the `kernel` weights matrix,\n    used for the linear transformation of the inputs.\n    (see [initializers](https://keras.io/initializers)).",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "description": "Initializer for the `recurrent_kernel`\n    weights matrix,\n    used for the linear transformation of the recurrent state.\n    (see [initializers](https://keras.io/initializers)).",
        "name": "recurrent_initializer",
        "visible": false
      },
      {
        "description": "Initializer for the bias vector\n    (see [initializers](https://keras.io/initializers)).",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to\n    the `kernel` weights matrix\n    (see [regularizer](https://keras.io/regularizers)).",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to\n    the `recurrent_kernel` weights matrix\n    (see [regularizer](https://keras.io/regularizers)).",
        "name": "recurrent_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the bias vector\n    (see [regularizer](https://keras.io/regularizers)).",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to\n    the output of the layer (its \"activation\").\n    (see [regularizer](https://keras.io/regularizers)).",
        "name": "activity_regularizer",
        "visible": false
      },
      {
        "description": "Constraint function applied to\n    the `kernel` weights matrix\n    (see [constraints](https://keras.io/constraints)).",
        "name": "kernel_constraint"
      },
      {
        "description": "Constraint function applied to\n    the `recurrent_kernel` weights matrix\n    (see [constraints](https://keras.io/constraints)).",
        "name": "recurrent_constraint"
      },
      {
        "description": "Constraint function applied to the bias vector\n    (see [constraints](https://keras.io/constraints)).",
        "name": "bias_constraint"
      },
      {
        "description": "Boolean. Whether to return the last output.\n    in the output sequence, or the full sequence.",
        "name": "return_sequences"
      },
      {
        "description": "Boolean. Whether to return the last state\n    in addition to the output.",
        "name": "return_state"
      },
      {
        "description": "Boolean (default False). If True, the last state\n    for each sample at index i in a batch will be used as initial\n    state for the sample of index i in the following batch.\n",
        "name": "stateful"
      }
    ]
  },
  {
    "name": "CuDNNLSTM",
    "description": "Fast LSTM implementation with [CuDNN](https://developer.nvidia.com/cudnn).\n\nCan only be run on GPU, with the TensorFlow backend.\n",
    "attributes": [
      {
        "description": "Positive integer, dimensionality of the output space.",
        "name": "units"
      },
      {
        "description": "Initializer for the `kernel` weights matrix,\n    used for the linear transformation of the inputs.\n    (see [initializers](https://keras.io/initializers)).",
        "name": "kernel_initializer"
      },
      {
        "description": "Initializer for the `recurrent_kernel`\n    weights matrix,\n    used for the linear transformation of the recurrent state.\n    (see [initializers](https://keras.io/initializers)).",
        "name": "recurrent_initializer"
      },
      {
        "description": "Initializer for the bias vector\n    (see [initializers](https://keras.io/initializers)).",
        "name": "bias_initializer"
      },
      {
        "description": "Boolean.\n    If True, add 1 to the bias of the forget gate at initialization.\n    Setting it to true will also force `bias_initializer=\"zeros\"`.\n    This is recommended in [Jozefowicz et al. (2015)](\n    http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).",
        "name": "unit_forget_bias"
      },
      {
        "description": "Regularizer function applied to\n    the `kernel` weights matrix\n    (see [regularizer](https://keras.io/regularizers)).",
        "name": "kernel_regularizer"
      },
      {
        "description": "Regularizer function applied to\n    the `recurrent_kernel` weights matrix\n    (see [regularizer](https://keras.io/regularizers)).",
        "name": "recurrent_regularizer"
      },
      {
        "description": "Regularizer function applied to the bias vector\n    (see [regularizer](https://keras.io/regularizers)).",
        "name": "bias_regularizer"
      },
      {
        "description": "Regularizer function applied to\n    the output of the layer (its \"activation\").\n    (see [regularizer](https://keras.io/regularizers)).",
        "name": "activity_regularizer"
      },
      {
        "description": "Constraint function applied to\n    the `kernel` weights matrix\n    (see [constraints](https://keras.io/constraints)).",
        "name": "kernel_constraint"
      },
      {
        "description": "Constraint function applied to\n    the `recurrent_kernel` weights matrix\n    (see [constraints](https://keras.io/constraints)).",
        "name": "recurrent_constraint"
      },
      {
        "description": "Constraint function applied to the bias vector\n    (see [constraints](https://keras.io/constraints)).",
        "name": "bias_constraint"
      },
      {
        "description": "Boolean. Whether to return the last output.\n    in the output sequence, or the full sequence.",
        "name": "return_sequences"
      },
      {
        "description": "Boolean. Whether to return the last state\n    in addition to the output.",
        "name": "return_state"
      },
      {
        "description": "Boolean (default False). If True, the last state\n    for each sample at index i in a batch will be used as initial\n    state for the sample of index i in the following batch.\n",
        "name": "stateful"
      }
    ]
  },
  {
    "name": "Dense",
    "module": "tensorflow.keras.layers",
    "category": "Layer",
    "description": "Just your regular densely-connected NN layer.\n\n`Dense` implements the operation:\n`output = activation(dot(input, kernel) + bias)`\nwhere `activation` is the element-wise activation function\npassed as the `activation` argument, `kernel` is a weights matrix\ncreated by the layer, and `bias` is a bias vector created by the layer\n(only applicable if `use_bias` is `True`). These are all attributes of\n`Dense`.\n\nNote: If the input to the layer has a rank greater than 2, then `Dense`\ncomputes the dot product between the `inputs` and the `kernel` along the\nlast axis of the `inputs` and axis 0 of the `kernel` (using `tf.tensordot`).\nFor example, if input has dimensions `(batch_size, d0, d1)`, then we create\na `kernel` with shape `(d1, units)`, and the `kernel` operates along axis 2\nof the `input`, on every sub-tensor of shape `(1, 1, d1)` (there are\n`batch_size * d0` such sub-tensors).  The output in this case will have\nshape `(batch_size, d0, units)`.\n\nBesides, layer attributes cannot be modified after the layer has been called\nonce (except the `trainable` attribute).\nWhen a popular kwarg `input_shape` is passed, then keras will create\nan input layer to insert before the current layer. This can be treated\nequivalent to explicitly defining an `InputLayer`.",
    "attributes": [
      {
        "description": "Positive integer, dimensionality of the output space.",
        "name": "units"
      },
      {
        "default": "linear",
        "description": "Activation function to use.\n        If you don't specify anything, no activation is applied\n        (ie. \"linear\" activation: `a(x) = x`).",
        "name": "activation"
      },
      {
        "default": true,
        "description": "Boolean, whether the layer uses a bias vector.",
        "name": "use_bias",
        "type": "boolean"
      },
      {
        "default": {
          "class_name": "VarianceScaling",
          "config": {
            "distribution": "uniform",
            "mode": "fan_avg",
            "scale": 1,
            "seed": null
          }
        },
        "description": "Initializer for the `kernel` weights matrix.",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "Zeros",
          "config": {}
        },
        "description": "Initializer for the bias vector.",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to\n        the `kernel` weights matrix.",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the bias vector.",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to\n        the output of the layer (its \"activation\").",
        "name": "activity_regularizer",
        "visible": false
      },
      {
        "description": "Constraint function applied to\n        the `kernel` weights matrix.",
        "name": "kernel_constraint"
      },
      {
        "description": "Constraint function applied to the bias vector.",
        "name": "bias_constraint"
      }
    ],
    "inputs": [
      {
        "description": "N-D tensor with shape: `(batch_size, ..., input_dim)`.\nThe most common situation would be\na 2D input with shape `(batch_size, input_dim)`.",
        "name": "input",
        "type": "T"
      },
      {
        "name": "kernel",
        "type": "T"
      },
      {
        "name": "bias",
        "type": "T"
      }
    ],
    "outputs": [
      {
        "description": "N-D tensor with shape: `(batch_size, ..., units)`.\nFor instance, for a 2D input with shape `(batch_size, input_dim)`,\nthe output would have shape `(batch_size, units)`.",
        "name": "output",
        "type": "T"
      }
    ],
    "examples": [
      {
        "code": ">>> # Create a `Sequential` model and add a Dense layer as the first layer.\n>>> model = tf.keras.models.Sequential()\n>>> model.add(tf.keras.Input(shape=(16,)))\n>>> model.add(tf.keras.layers.Dense(32, activation='relu'))\n>>> # Now the model will take as input arrays of shape (None, 16)\n>>> # and output arrays of shape (None, 32).\n>>> # Note that after the first layer, you don't need to specify\n>>> # the size of the input anymore:\n>>> model.add(tf.keras.layers.Dense(32))\n>>> model.output_shape\n(None, 32)"
      }
    ]
  },
  {
    "name": "DepthwiseConv2D",
    "category": "Layer",
    "attributes": [
      {
        "default": "linear",
        "name": "activation"
      },
      {
        "default": "valid",
        "name": "padding"
      },
      {
        "default": true,
        "name": "use_bias",
        "type": "boolean",
        "visible": false
      },
      {
        "default": "channels_last",
        "name": "data_format"
      },
      {
        "default": [
          1,
          1
        ],
        "name": "strides"
      },
      {
        "default": [
          1,
          1
        ],
        "name": "dilation_rate"
      },
      {
        "default": {
          "class_name": "Zeros",
          "config": {}
        },
        "name": "bias_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "VarianceScaling",
          "config": {
            "distribution": "uniform",
            "mode": "fan_avg",
            "scale": 1,
            "seed": null
          }
        },
        "name": "depthwise_initializer",
        "visible": false
      },
      {
        "default": 1,
        "name": "depth_multiplier"
      }
    ],
    "inputs": [
      {
        "name": "input"
      },
      {
        "name": "kernel"
      },
      {
        "name": "bias"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ]
  },
  {
    "name": "Dot",
    "module": "tensorflow.keras.layers",
    "description": "Layer that computes a dot product between samples in two tensors.\n\nE.g. if applied to a list of two tensors `a` and `b` of shape\n`(batch_size, n)`, the output will be a tensor of shape `(batch_size, 1)`\nwhere each entry `i` will be the dot product between\n`a[i]` and `b[i]`.\n\n```\n>>> x = np.arange(10).reshape(1, 5, 2)\n>>> print(x)\n[[[0 1]\n  [2 3]\n  [4 5]\n  [6 7]\n  [8 9]]]\n>>> y = np.arange(10, 20).reshape(1, 2, 5)\n>>> print(y)\n[[[10 11 12 13 14]\n  [15 16 17 18 19]]]\n>>> tf.keras.layers.Dot(axes=(1, 2))([x, y])\n<tf.Tensor: shape=(1, 2, 2), dtype=int64, numpy=\narray([[[260, 360],\n        [320, 445]]])>\n```\n\n```\n>>> x1 = tf.keras.layers.Dense(8)(np.arange(10).reshape(5, 2))\n>>> x2 = tf.keras.layers.Dense(8)(np.arange(10, 20).reshape(5, 2))\n>>> dotted = tf.keras.layers.Dot(axes=1)([x1, x2])\n>>> dotted.shape\nTensorShape([5, 1])\n```",
    "attributes": [
      {
        "description": "Integer or tuple of integers,\n    axis or axes along which to take the dot product.",
        "name": "axes"
      },
      {
        "description": "Whether to L2-normalize samples along the\n    dot product axis before taking the dot product.\n    If set to True, then the output of the dot product\n    is the cosine proximity between the two samples.",
        "name": "normalize"
      },
      {
        "description": "Standard layer keyword arguments.\n",
        "name": "**kwargs"
      }
    ],
    "inputs": [
      {
        "name": "x"
      },
      {
        "name": "y"
      }
    ],
    "outputs": [
      {
        "name": "z"
      }
    ]
  },
  {
    "name": "Dropout",
    "module": "tensorflow.keras.layers",
    "category": "Dropout",
    "description": "Applies Dropout to the input.\n\nThe Dropout layer randomly sets input units to 0 with a frequency of `rate`\nat each step during training time, which helps prevent overfitting.\nInputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over\nall inputs is unchanged.\n\nNote that the Dropout layer only applies when `training` is set to True\nsuch that no values are dropped during inference. When using `model.fit`,\n`training` will be appropriately set to True automatically, and in other\ncontexts, you can set the kwarg explicitly to True when calling the layer.\n\n(This is in contrast to setting `trainable=False` for a Dropout layer.\n`trainable` does not affect the layer's behavior, as Dropout does\nnot have any variables/weights that can be frozen during training.)\n\n```\n>>> tf.random.set_seed(0)\n>>> layer = tf.keras.layers.Dropout(.2, input_shape=(2,))\n>>> data = np.arange(10).reshape(5, 2).astype(np.float32)\n>>> print(data)\n[[0. 1.]\n [2. 3.]\n [4. 5.]\n [6. 7.]\n [8. 9.]]\n>>> outputs = layer(data, training=True)\n>>> print(outputs)\ntf.Tensor(\n[[ 0.    1.25]\n [ 2.5   3.75]\n [ 5.    6.25]\n [ 7.5   8.75]\n [10.    0.  ]], shape=(5, 2), dtype=float32)\n```",
    "attributes": [
      {
        "description": "Float between 0 and 1. Fraction of the input units to drop.",
        "name": "rate"
      },
      {
        "description": "1D integer tensor representing the shape of the\n    binary dropout mask that will be multiplied with the input.\n    For instance, if your inputs have shape\n    `(batch_size, timesteps, features)` and\n    you want the dropout mask to be the same for all timesteps,\n    you can use `noise_shape=(batch_size, 1, features)`.",
        "name": "noise_shape"
      },
      {
        "description": "A Python integer to use as random seed.",
        "name": "seed"
      }
    ],
    "inputs": [
      {
        "name": "input"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ],
    "references": [
      {
        "description": "[Dropout: A Simple Way to Prevent Neural Networks from Overfitting]( http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)"
      }
    ]
  },
  {
    "name": "ELU",
    "module": "tensorflow.keras.layers",
    "category": "Activation",
    "description": "Exponential Linear Unit.\n\nIt follows:\n\n```\n  f(x) =  alpha * (exp(x) - 1.) for x < 0\n  f(x) = x for x >= 0\n```",
    "attributes": [
      {
        "description": "Scale for the negative factor.",
        "name": "alpha"
      }
    ],
    "inputs": [
      {
        "description": "Arbitrary. Use the keyword argument `input_shape`\n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "Same shape as the input.",
        "name": "output"
      }
    ],
    "references": [
      {
        "description": "[Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)](https://arxiv.org/abs/1511.07289v1)"
      }
    ]
  },
  {
    "name": "Embedding",
    "module": "tensorflow.keras.layers",
    "category": "Transform",
    "description": "Turns positive integers (indexes) into dense vectors of fixed size.\n\ne.g. `[[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]`\n\nThis layer can only be used on positive integer inputs of a fixed range. The\n`tf.keras.layers.TextVectorization`, `tf.keras.layers.StringLookup`,\nand `tf.keras.layers.IntegerLookup` preprocessing layers can help prepare\ninputs for an `Embedding` layer.\n\nThis layer accepts `tf.Tensor` and `tf.RaggedTensor` inputs. It cannot be\ncalled with `tf.SparseTensor` input.",
    "attributes": [
      {
        "default": false,
        "description": "Boolean, whether or not the input value 0 is a special\n    \"padding\" value that should be masked out. This is useful when using\n    recurrent layers which may take variable length input. If this is\n    `True`, then all subsequent layers in the model need to support masking\n    or an exception will be raised. If mask_zero is set to True, as a\n    consequence, index 0 cannot be used in the vocabulary (input_dim should\n    equal size of vocabulary + 1).",
        "name": "mask_zero"
      },
      {
        "default": {
          "class_name": "RandomUniform",
          "config": {
            "maxval": 0.05,
            "minval": -0.05,
            "seed": null
          }
        },
        "description": "Initializer for the `embeddings`\n    matrix (see `keras.initializers`).",
        "name": "embeddings_initializer",
        "visible": false
      },
      {
        "description": "Integer. Size of the vocabulary,\n    i.e. maximum integer index + 1.",
        "name": "input_dim"
      },
      {
        "description": "Integer. Dimension of the dense embedding.",
        "name": "output_dim"
      },
      {
        "description": "Regularizer function applied to\n    the `embeddings` matrix (see `keras.regularizers`).",
        "name": "embeddings_regularizer",
        "visible": false
      },
      {
        "description": "Constraint function applied to\n    the `embeddings` matrix (see `keras.constraints`).",
        "name": "embeddings_constraint"
      },
      {
        "description": "Length of input sequences, when it is constant.\n    This argument is required if you are going to connect\n    `Flatten` then `Dense` layers upstream\n    (without it, the shape of the dense outputs cannot be computed).",
        "name": "input_length"
      },
      {
        "description": "Regularizer function applied to\n    the output of the layer (its \"activation\").\n    (see [regularizer](https://keras.io/regularizers)).",
        "name": "activity_regularizer"
      },
      {
        "name": "sparse",
        "description": "If True, calling this layer returns a `tf.SparseTensor`. If False,\n    the layer returns a dense `tf.Tensor`. For an entry with no features in\n    a sparse tensor (entry with value 0), the embedding vector of index 0 is\n    returned by default."
      }
    ],
    "inputs": [
      {
        "description": "2D tensor with shape: `(batch_size, input_length)`.",
        "name": "input"
      },
      {
        "name": "embeddings"
      }
    ],
    "outputs": [
      {
        "description": "3D tensor with shape: `(batch_size, input_length, output_dim)`.\n\n**Note on variable placement:**\nBy default, if a GPU is available, the embedding matrix will be placed on\nthe GPU. This achieves the best performance, but it might cause issues:\n\n- You may be using an optimizer that does not support sparse GPU kernels.\nIn this case you will see an error upon training your model.\n- Your embedding matrix may be too large to fit on your GPU. In this case\nyou will see an Out Of Memory (OOM) error.\n\nIn such cases, you should place the embedding matrix on the CPU memory.\nYou can do so with a device scope, as such:\n\n```python\nwith tf.device('cpu:0'):\n  embedding_layer = Embedding(...)\n  embedding_layer.build()\n```\n\nThe pre-built `embedding_layer` instance can then be added to a `Sequential`\nmodel (e.g. `model.add(embedding_layer)`), called in a Functional model\n(e.g. `x = embedding_layer(x)`), or used in a subclassed model.",
        "name": "output"
      }
    ],
    "references": [
      {
        "description": "[A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](http://arxiv.org/abs/1512.05287)"
      }
    ],
    "examples": [
      {
        "code": ">>> model = tf.keras.Sequential()\n>>> model.add(tf.keras.layers.Embedding(1000, 64, input_length=10))\n>>> # The model will take as input an integer matrix of size (batch,\n>>> # input_length), and the largest integer (i.e. word index) in the input\n>>> # should be no larger than 999 (vocabulary size).\n>>> # Now model.output_shape is (None, 10, 64), where `None` is the batch\n>>> # dimension.\n>>> input_array = np.random.randint(1000, size=(32, 10))\n>>> model.compile('rmsprop', 'mse')\n>>> output_array = model.predict(input_array)\n>>> print(output_array.shape)\n(32, 10, 64)"
      }
    ]
  },
  {
    "name": "Flatten",
    "module": "tensorflow.keras.layers",
    "category": "Shape",
    "description": "Flattens the input. Does not affect the batch size.\n\nNote: If inputs are shaped `(batch,)` without a feature axis, then\nflattening adds an extra channel dimension and output shape is `(batch, 1)`.",
    "attributes": [
      {
        "default": "channels_last",
        "description": "A string,\n    one of `channels_last` (default) or `channels_first`.\n    The ordering of the dimensions in the inputs.\n    `channels_last` corresponds to inputs with shape\n    `(batch, ..., channels)` while `channels_first` corresponds to\n    inputs with shape `(batch, channels, ...)`.\n    It defaults to the `image_data_format` value found in your\n    Keras config file at `~/.keras/keras.json`.\n    If you never set it, then it will be \"channels_last\".",
        "name": "data_format"
      }
    ],
    "inputs": [
      {
        "name": "input"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> model = tf.keras.Sequential()\n>>> model.add(tf.keras.layers.Conv2D(64, 3, 3, input_shape=(3, 32, 32)))\n>>> model.output_shape\n(None, 1, 10, 64)"
      },
      {
        "code": ">>> model.add(Flatten())\n>>> model.output_shape\n(None, 640)"
      }
    ]
  },
  {
    "name": "GlobalAveragePooling1D",
    "module": "tensorflow.keras.layers",
    "category": "Pool",
    "description": "Global average pooling operation for temporal data.",
    "attributes": [
      {
        "description": "A string,\n    one of `channels_last` (default) or `channels_first`.\n    The ordering of the dimensions in the inputs.\n    `channels_last` corresponds to inputs with shape\n    `(batch, steps, features)` while `channels_first`\n    corresponds to inputs with shape\n    `(batch, features, steps)`.",
        "name": "data_format"
      },
      {
        "name": "keepdims",
        "description": "A boolean, whether to keep the temporal dimension or not.\n    If `keepdims` is `False` (default), the rank of the tensor is reduced\n    for spatial dimensions.\n    If `keepdims` is `True`, the temporal dimension are retained with\n    length 1.\n    The behavior is the same as for `tf.reduce_mean` or `np.mean`."
      }
    ],
    "inputs": [
      {
        "description": "- If `data_format='channels_last'`:\n  3D tensor with shape:\n  `(batch_size, steps, features)`\n- If `data_format='channels_first'`:\n  3D tensor with shape:\n  `(batch_size, features, steps)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "- If `keepdims`=False:\n  2D tensor with shape `(batch_size, features)`.\n- If `keepdims`=True:\n  - If `data_format='channels_last'`:\n    3D tensor with shape `(batch_size, 1, features)`\n  - If `data_format='channels_first'`:\n    3D tensor with shape `(batch_size, features, 1)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> input_shape = (2, 3, 4)\n>>> x = tf.random.normal(input_shape)\n>>> y = tf.keras.layers.GlobalAveragePooling1D()(x)\n>>> print(y.shape)\n(2, 4)"
      }
    ]
  },
  {
    "name": "GlobalAveragePooling2D",
    "module": "tensorflow.keras.layers",
    "category": "Pool",
    "description": "Global average pooling operation for spatial data.",
    "attributes": [
      {
        "default": "channels_last",
        "description": "A string,\n      one of `channels_last` (default) or `channels_first`.\n      The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape\n      `(batch, height, width, channels)` while `channels_first`\n      corresponds to inputs with shape\n      `(batch, channels, height, width)`.\n      It defaults to the `image_data_format` value found in your\n      Keras config file at `~/.keras/keras.json`.\n      If you never set it, then it will be \"channels_last\".",
        "name": "data_format"
      },
      {
        "name": "keepdims",
        "description": "A boolean, whether to keep the spatial dimensions or not.\n      If `keepdims` is `False` (default), the rank of the tensor is reduced\n      for spatial dimensions.\n      If `keepdims` is `True`, the spatial dimensions are retained with\n      length 1.\n      The behavior is the same as for `tf.reduce_mean` or `np.mean`."
      }
    ],
    "inputs": [
      {
        "description": "- If `data_format='channels_last'`:\n  4D tensor with shape `(batch_size, rows, cols, channels)`.\n- If `data_format='channels_first'`:\n  4D tensor with shape `(batch_size, channels, rows, cols)`.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "- If `keepdims`=False:\n  2D tensor with shape `(batch_size, channels)`.\n- If `keepdims`=True:\n  - If `data_format='channels_last'`:\n    4D tensor with shape `(batch_size, 1, 1, channels)`\n  - If `data_format='channels_first'`:\n    4D tensor with shape `(batch_size, channels, 1, 1)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> input_shape = (2, 4, 5, 3)\n>>> x = tf.random.normal(input_shape)\n>>> y = tf.keras.layers.GlobalAveragePooling2D()(x)\n>>> print(y.shape)\n(2, 3)"
      }
    ]
  },
  {
    "name": "GlobalMaxPooling1D",
    "module": "tensorflow.keras.layers",
    "category": "Pool",
    "description": "Global max pooling operation for 1D temporal data.\n\nDownsamples the input representation by taking the maximum value over\nthe time dimension.\n\nFor example:\n\n```\n>>> x = tf.constant([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]])\n>>> x = tf.reshape(x, [3, 3, 1])\n>>> x\n<tf.Tensor: shape=(3, 3, 1), dtype=float32, numpy=\narray([[[1.], [2.], [3.]],\n       [[4.], [5.], [6.]],\n       [[7.], [8.], [9.]]], dtype=float32)>\n>>> max_pool_1d = tf.keras.layers.GlobalMaxPooling1D()\n>>> max_pool_1d(x)\n<tf.Tensor: shape=(3, 1), dtype=float32, numpy=\narray([[3.],\n       [6.],\n       [9.], dtype=float32)>\n```",
    "attributes": [
      {
        "description": "A string,\n    one of `channels_last` (default) or `channels_first`.\n    The ordering of the dimensions in the inputs.\n    `channels_last` corresponds to inputs with shape\n    `(batch, steps, features)` while `channels_first`\n    corresponds to inputs with shape\n    `(batch, features, steps)`.",
        "name": "data_format"
      },
      {
        "name": "keepdims",
        "description": "A boolean, whether to keep the temporal dimension or not.\n    If `keepdims` is `False` (default), the rank of the tensor is reduced\n    for spatial dimensions.\n    If `keepdims` is `True`, the temporal dimension are retained with\n    length 1.\n    The behavior is the same as for `tf.reduce_max` or `np.max`."
      }
    ],
    "inputs": [
      {
        "description": "- If `data_format='channels_last'`:\n  3D tensor with shape:\n  `(batch_size, steps, features)`\n- If `data_format='channels_first'`:\n  3D tensor with shape:\n  `(batch_size, features, steps)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "- If `keepdims`=False:\n  2D tensor with shape `(batch_size, features)`.\n- If `keepdims`=True:\n  - If `data_format='channels_last'`:\n    3D tensor with shape `(batch_size, 1, features)`\n  - If `data_format='channels_first'`:\n    3D tensor with shape `(batch_size, features, 1)`",
        "name": "output"
      }
    ]
  },
  {
    "name": "GlobalMaxPooling2D",
    "module": "tensorflow.keras.layers",
    "category": "Pool",
    "description": "Global max pooling operation for spatial data.",
    "attributes": [
      {
        "default": "channels_last",
        "description": "A string,\n    one of `channels_last` (default) or `channels_first`.\n    The ordering of the dimensions in the inputs.\n    `channels_last` corresponds to inputs with shape\n    `(batch, height, width, channels)` while `channels_first`\n    corresponds to inputs with shape\n    `(batch, channels, height, width)`.\n    It defaults to the `image_data_format` value found in your\n    Keras config file at `~/.keras/keras.json`.\n    If you never set it, then it will be \"channels_last\".",
        "name": "data_format"
      },
      {
        "name": "keepdims",
        "description": "A boolean, whether to keep the spatial dimensions or not.\n    If `keepdims` is `False` (default), the rank of the tensor is reduced\n    for spatial dimensions.\n    If `keepdims` is `True`, the spatial dimensions are retained with\n    length 1.\n    The behavior is the same as for `tf.reduce_max` or `np.max`."
      }
    ],
    "inputs": [
      {
        "description": "- If `data_format='channels_last'`:\n  4D tensor with shape `(batch_size, rows, cols, channels)`.\n- If `data_format='channels_first'`:\n  4D tensor with shape `(batch_size, channels, rows, cols)`.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "- If `keepdims`=False:\n  2D tensor with shape `(batch_size, channels)`.\n- If `keepdims`=True:\n  - If `data_format='channels_last'`:\n    4D tensor with shape `(batch_size, 1, 1, channels)`\n  - If `data_format='channels_first'`:\n    4D tensor with shape `(batch_size, channels, 1, 1)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> input_shape = (2, 4, 5, 3)\n>>> x = tf.random.normal(input_shape)\n>>> y = tf.keras.layers.GlobalMaxPool2D()(x)\n>>> print(y.shape)\n(2, 3)"
      }
    ]
  },
  {
    "name": "GRU",
    "module": "tensorflow.keras.layers",
    "category": "Layer",
    "description": "Gated Recurrent Unit - Cho et al. 2014.\n\nSee [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)\nfor details about the usage of RNN API.\n\nBased on available runtime hardware and constraints, this layer\nwill choose different implementations (cuDNN-based or pure-TensorFlow)\nto maximize the performance. If a GPU is available and all\nthe arguments to the layer meet the requirement of the cuDNN kernel\n(see below for details), the layer will use a fast cuDNN implementation.\n\nThe requirements to use the cuDNN implementation are:\n\n1. `activation` == `tanh`\n2. `recurrent_activation` == `sigmoid`\n3. `recurrent_dropout` == 0\n4. `unroll` is `False`\n5. `use_bias` is `True`\n6. `reset_after` is `True`\n7. Inputs, if use masking, are strictly right-padded.\n8. Eager execution is enabled in the outermost context.\n\nThere are two variants of the GRU implementation. The default one is based\non [v3](https://arxiv.org/abs/1406.1078v3) and has reset gate applied to\nhidden state before matrix multiplication. The other one is based on\n[original](https://arxiv.org/abs/1406.1078v1) and has the order reversed.\n\nThe second variant is compatible with CuDNNGRU (GPU-only) and allows\ninference on CPU. Thus it has separate biases for `kernel` and\n`recurrent_kernel`. To use this variant, set `reset_after=True` and\n`recurrent_activation='sigmoid'`.\n\nFor example:\n\n```\n>>> inputs = tf.random.normal([32, 10, 8])\n>>> gru = tf.keras.layers.GRU(4)\n>>> output = gru(inputs)\n>>> print(output.shape)\n(32, 4)\n>>> gru = tf.keras.layers.GRU(4, return_sequences=True, return_state=True)\n>>> whole_sequence_output, final_state = gru(inputs)\n>>> print(whole_sequence_output.shape)\n(32, 10, 4)\n>>> print(final_state.shape)\n(32, 4)\n```",
    "attributes": [
      {
        "default": "tanh",
        "description": "Activation function to use.",
        "name": "activation"
      },
      {
        "default": "hard_sigmoid",
        "description": "Activation function to use\n    for the recurrent step.",
        "name": "recurrent_activation"
      },
      {
        "default": true,
        "description": "Boolean, (default `True`), whether the layer uses a bias vector.",
        "name": "use_bias",
        "visible": false
      },
      {
        "default": {
          "class_name": "VarianceScaling",
          "config": {
            "distribution": "uniform",
            "mode": "fan_avg",
            "scale": 1,
            "seed": null
          }
        },
        "description": "Initializer for the `kernel` weights matrix,\n    used for the linear transformation of the inputs. Default:\n    `glorot_uniform`.",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "Orthogonal",
          "config": {
            "gain": 1,
            "seed": null
          }
        },
        "description": "Initializer for the `recurrent_kernel`\n     weights matrix, used for the linear transformation of the recurrent\n     state. Default: `orthogonal`.",
        "name": "recurrent_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "Zeros",
          "config": {}
        },
        "description": "Initializer for the bias vector. Default: `zeros`.",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "default": 0,
        "description": "Float between 0 and 1. Fraction of the units to drop for the\n    linear transformation of the inputs. Default: 0.",
        "name": "dropout"
      },
      {
        "default": 1,
        "description": "Implementation mode, either 1 or 2.\n    Mode 1 will structure its operations as a larger number of\n    smaller dot products and additions, whereas mode 2 will\n    batch them into fewer, larger operations. These modes will\n    have different performance profiles on different hardware and\n    for different applications. Default: 2.",
        "name": "implementation"
      },
      {
        "default": false,
        "description": "Boolean. Whether to return the last output\n    in the output sequence, or the full sequence. Default: `False`.",
        "name": "return_sequences"
      },
      {
        "default": false,
        "description": "Boolean. Whether to return the last state in addition to the\n    output. Default: `False`.",
        "name": "return_state"
      },
      {
        "default": false,
        "description": "Boolean (default `False`).\n    If True, process the input sequence backwards and return the\n    reversed sequence.",
        "name": "go_backwards"
      },
      {
        "default": false,
        "description": "Boolean (default False). If True, the last state\n    for each sample at index i in a batch will be used as initial\n    state for the sample of index i in the following batch.",
        "name": "stateful"
      },
      {
        "default": false,
        "description": "Boolean (default False).\n    If True, the network will be unrolled,\n    else a symbolic loop will be used.\n    Unrolling can speed-up a RNN,\n    although it tends to be more memory-intensive.\n    Unrolling is only suitable for short sequences.",
        "name": "unroll"
      },
      {
        "description": "Positive integer, dimensionality of the output space.",
        "name": "units"
      },
      {
        "description": "Regularizer function applied to the `kernel` weights\n    matrix. Default: `None`.",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the\n    `recurrent_kernel` weights matrix. Default: `None`.",
        "name": "recurrent_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the bias vector.",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the output of the\n    layer (its \"activation\"). Default: `None`.",
        "name": "activity_regularizer",
        "visible": false
      },
      {
        "description": "Constraint function applied to the `kernel` weights\n    matrix. Default: `None`.",
        "name": "kernel_constraint"
      },
      {
        "description": "Constraint function applied to the\n    `recurrent_kernel` weights matrix. Default: `None`.",
        "name": "recurrent_constraint"
      },
      {
        "description": "Constraint function applied to the bias vector. Default:\n    `None`.",
        "name": "bias_constraint"
      },
      {
        "description": "Float between 0 and 1. Fraction of the units to drop\n    for the linear transformation of the recurrent state. Default: 0.",
        "name": "recurrent_dropout"
      },
      {
        "description": "`None`.",
        "name": "Default"
      },
      {
        "description": "GRU convention (whether to apply reset gate after or\n    before matrix multiplication). False = \"before\",\n    True = \"after\" (default and cuDNN compatible).",
        "name": "reset_after"
      },
      {
        "description": "The shape format of the `inputs` and `outputs` tensors.\n    If True, the inputs and outputs will be in shape\n    `[timesteps, batch, feature]`, whereas in the False case, it will be\n    `[batch, timesteps, feature]`. Using `time_major = True` is a bit more\n    efficient because it avoids transposes at the beginning and end of the\n    RNN calculation. However, most TensorFlow data is batch-major, so by\n    default this function accepts input and emits output in batch-major\n    form.",
        "name": "time_major"
      }
    ],
    "inputs": [
      {
        "name": "input"
      },
      {
        "name": "kernel"
      },
      {
        "name": "recurrent_kernel"
      },
      {
        "name": "bias"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ],
    "references": [
      {
        "description": "[Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](https://arxiv.org/abs/1406.1078)"
      },
      {
        "description": "[On the Properties of Neural Machine Translation: Encoder-Decoder Approaches](https://arxiv.org/abs/1409.1259)"
      },
      {
        "description": "[Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling](https://arxiv.org/abs/1412.3555v1)"
      },
      {
        "description": "[A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](https://arxiv.org/abs/1512.05287)"
      }
    ]
  },
  {
    "name": "GRUCell",
    "module": "tensorflow.keras.layers",
    "description": "Cell class for the GRU layer.\n\nSee [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)\nfor details about the usage of RNN API.\n\nThis class processes one step within the whole time sequence input, whereas\n`tf.keras.layer.GRU` processes the whole sequence.\n\nFor example:\n\n```\n>>> inputs = tf.random.normal([32, 10, 8])\n>>> rnn = tf.keras.layers.RNN(tf.keras.layers.GRUCell(4))\n>>> output = rnn(inputs)\n>>> print(output.shape)\n(32, 4)\n>>> rnn = tf.keras.layers.RNN(\n...    tf.keras.layers.GRUCell(4),\n...    return_sequences=True,\n...    return_state=True)\n>>> whole_sequence_output, final_state = rnn(inputs)\n>>> print(whole_sequence_output.shape)\n(32, 10, 4)\n>>> print(final_state.shape)\n(32, 4)\n```",
    "attributes": [
      {
        "description": "Positive integer, dimensionality of the output space.",
        "name": "units"
      },
      {
        "description": "Activation function to use. Default: hyperbolic tangent\n    (`tanh`). If you pass None, no activation is applied\n    (ie. \"linear\" activation: `a(x) = x`).",
        "name": "activation"
      },
      {
        "description": "Activation function to use for the recurrent step.",
        "name": "recurrent_activation"
      },
      {
        "default": true,
        "description": "Boolean, (default `True`), whether the layer uses a bias vector.",
        "name": "use_bias",
        "visible": false
      },
      {
        "description": "Initializer for the `kernel` weights matrix,\n    used for the linear transformation of the inputs. Default:\n    `glorot_uniform`.",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "description": "Initializer for the `recurrent_kernel`\n    weights matrix, used for the linear transformation of the recurrent\n    state.  Default: `orthogonal`.",
        "name": "recurrent_initializer",
        "visible": false
      },
      {
        "description": "Initializer for the bias vector. Default: `zeros`.",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the `kernel` weights\n    matrix. Default: `None`.",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the\n    `recurrent_kernel` weights matrix. Default: `None`.",
        "name": "recurrent_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the bias vector.",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Constraint function applied to the `kernel` weights\n    matrix. Default: `None`.",
        "name": "kernel_constraint"
      },
      {
        "description": "Constraint function applied to the\n    `recurrent_kernel` weights matrix. Default: `None`.",
        "name": "recurrent_constraint"
      },
      {
        "description": "Constraint function applied to the bias vector. Default:\n    `None`.",
        "name": "bias_constraint"
      },
      {
        "default": 0,
        "description": "Float between 0 and 1. Fraction of the units to drop for the\n    linear transformation of the inputs. Default: 0.",
        "name": "dropout"
      },
      {
        "default": 0,
        "description": "Float between 0 and 1. Fraction of the units to drop\n    for the linear transformation of the recurrent state. Default: 0.",
        "name": "recurrent_dropout"
      },
      {
        "description": "Implementation mode, either 1 or 2.\n    Mode 1 will structure its operations as a larger number of\n    smaller dot products and additions, whereas mode 2 (default) will\n    batch them into fewer, larger operations. These modes will\n    have different performance profiles on different hardware and\n    for different applications. Default: 2.",
        "name": "implementation"
      },
      {
        "description": "`None`.",
        "name": "Default"
      },
      {
        "description": "GRU convention (whether to apply reset gate after or\n    before matrix multiplication). False = \"before\",\n    True = \"after\" (default and cuDNN compatible).",
        "name": "reset_after"
      }
    ]
  },
  {
    "name": "HardSigmoid",
    "category": "Activation"
  },
  {
    "name": "InputLayer",
    "module": "tensorflow.keras.layers",
    "category": "Data",
    "description": "Layer to be used as an entry point into a Network (a graph of layers).\n\nIt can either wrap an existing tensor (pass an `input_tensor` argument)\nor create a placeholder tensor (pass arguments `input_shape`, and\noptionally, `dtype`).\n\nIt is generally recommend to use the Keras Functional model via `Input`,\n(which creates an `InputLayer`) without directly using `InputLayer`.\n\nWhen using `InputLayer` with the Keras Sequential model, it can be skipped\nby moving the `input_shape` parameter to the first layer after the\n`InputLayer`.\n\nThis class can create placeholders for `tf.Tensors`, `tf.SparseTensors`, and\n`tf.RaggedTensors` by choosing `sparse=True` or `ragged=True`. Note that\n`sparse` and `ragged` can't be configured to `True` at the same time.",
    "attributes": [
      {
        "description": "Shape tuple (not including the batch axis), or\n        `TensorShape` instance (not including the batch axis).",
        "name": "input_shape"
      },
      {
        "description": "Optional input batch size (integer or `None`).",
        "name": "batch_size"
      },
      {
        "description": "Optional datatype of the input. When not provided, the Keras\n        default `float` type will be used.",
        "name": "dtype"
      },
      {
        "description": "Optional tensor to use as layer input. If set, the layer\n        will use the `tf.TypeSpec` of this tensor rather\n        than creating a new placeholder tensor.",
        "name": "input_tensor"
      },
      {
        "description": "Boolean, whether the placeholder created is meant to be sparse.\n        Default to `False`.",
        "name": "sparse"
      },
      {
        "description": "Boolean, whether the placeholder created is meant to be ragged.\n        In this case, values of `None` in the `shape` argument represent\n        ragged dimensions. For more information about `tf.RaggedTensor`, see\n        [this guide](https://www.tensorflow.org/guide/ragged_tensor).\n        Default to `False`.",
        "name": "ragged"
      },
      {
        "description": "Optional name of the layer (string).",
        "name": "name"
      },
      {
        "description": "A `tf.TypeSpec` object to create Input from. This\n        `tf.TypeSpec` represents the entire batch. When provided, all other\n        args except name must be `None`.",
        "name": "type_spec"
      }
    ],
    "examples": [
      {
        "code": "# With explicit InputLayer.\nmodel = tf.keras.Sequential([\n  tf.keras.layers.InputLayer(input_shape=(4,)),\n  tf.keras.layers.Dense(8)])\nmodel.compile(tf.keras.optimizers.RMSprop(0.001), loss='mse')\nmodel.fit(np.zeros((10, 4)),\n          np.ones((10, 8)))\n\n# Without InputLayer and let the first layer to have the input_shape.\n# Keras will add a input for the model behind the scene.\nmodel = tf.keras.Sequential([\n  tf.keras.layers.Dense(8, input_shape=(4,))])\nmodel.compile(tf.keras.optimizers.RMSprop(0.001), loss='mse')\nmodel.fit(np.zeros((10, 4)),\n          np.ones((10, 8)))"
      }
    ]
  },
  {
    "name": "InputSpec",
    "module": "tensorflow.keras.layers",
    "category": "Data",
    "description": "Specifies the rank, dtype and shape of every input to a layer.\n\nLayers can expose (if appropriate) an `input_spec` attribute:\nan instance of `InputSpec`, or a nested structure of `InputSpec` instances\n(one per input tensor). These objects enable the layer to run input\ncompatibility checks for input structure, input rank, input shape, and\ninput dtype.\n\nA None entry in a shape is compatible with any dimension,\na None shape is compatible with any shape.",
    "attributes": [
      {
        "description": "Expected DataType of the input.",
        "name": "dtype"
      },
      {
        "description": "Shape tuple, expected shape of the input\n    (may include None for unchecked axes). Includes the batch size.",
        "name": "shape"
      },
      {
        "description": "Integer, expected rank of the input.",
        "name": "ndim"
      },
      {
        "description": "Integer, maximum rank of the input.",
        "name": "max_ndim"
      },
      {
        "description": "Integer, minimum rank of the input.",
        "name": "min_ndim"
      },
      {
        "description": "Dictionary mapping integer axes to\n    a specific dimension value.",
        "name": "axes"
      },
      {
        "description": "If True, then allow inputs of rank N+1 as long\n    as the last axis of the input is 1, as well as inputs of rank N-1\n    as long as the last axis of the spec is 1.",
        "name": "allow_last_axis_squeeze"
      },
      {
        "description": "Expected key corresponding to this input when passing data as\n    a dictionary.",
        "name": "name"
      }
    ],
    "examples": [
      {
        "code": "class MyLayer(Layer):\n    def __init__(self):\n        super(MyLayer, self).__init__()\n        # The layer will accept inputs with\n        # shape (?, 28, 28) & (?, 28, 28, 1)\n        # and raise an appropriate error message otherwise.\n        self.input_spec = InputSpec(\n            shape=(None, 28, 28, 1),\n            allow_last_axis_squeeze=True)"
      }
    ]
  },
  {
    "name": "Lambda",
    "module": "tensorflow.keras.layers",
    "description": "Wraps arbitrary expressions as a `Layer` object.\n\nThe `Lambda` layer exists so that arbitrary expressions can be used\nas a `Layer` when constructing `Sequential`\nand Functional API models. `Lambda` layers are best suited for simple\noperations or quick experimentation. For more advanced use cases, follow\n[this guide](\nhttps://www.tensorflow.org/guide/keras/custom_layers_and_models)\nfor subclassing `tf.keras.layers.Layer`.\n\nWARNING: `tf.keras.layers.Lambda` layers have (de)serialization limitations!\n\nThe main reason to subclass `tf.keras.layers.Layer` instead of using a\n`Lambda` layer is saving and inspecting a Model. `Lambda` layers\nare saved by serializing the Python bytecode, which is fundamentally\nnon-portable. They should only be loaded in the same environment where\nthey were saved. Subclassed layers can be saved in a more portable way\nby overriding their `get_config` method. Models that rely on\nsubclassed Layers are also often easier to visualize and reason about.",
    "attributes": [
      {
        "description": "The function to be evaluated. Takes input tensor as first\n    argument.",
        "name": "function"
      },
      {
        "description": "Expected output shape from function. This argument can be\n    inferred if not explicitly provided. Can be a tuple or function. If a\n    tuple, it only specifies the first dimension onward;\n    sample dimension is assumed either the same as the input:\n    `output_shape = (input_shape[0], ) + output_shape` or, the input is\n    `None` and the sample dimension is also `None`:\n    `output_shape = (None, ) + output_shape` If a function, it specifies the\n    entire shape as a function of the input shape:\n    `output_shape = f(input_shape)`",
        "name": "output_shape"
      },
      {
        "description": "Optional dictionary of keyword arguments to be passed to the\n    function.\nInput shape: Arbitrary. Use the keyword argument input_shape (tuple of\n  integers, does not include the samples axis) when using this layer as the\n  first layer in a model.\nOutput shape: Specified by `output_shape` argument",
        "name": "arguments"
      },
      {
        "description": "Either None (indicating no masking) or a callable with the same\n    signature as the `compute_mask` layer method, or a tensor that will be\n    returned as output mask regardless of what the input is.",
        "name": "mask"
      }
    ],
    "inputs": [
      {
        "description": "Arbitrary. Use the keyword argument input_shape (tuple of\nintegers, does not include the samples axis) when using this layer as the\nfirst layer in a model.",
        "name": "inputs",
        "list": true
      }
    ],
    "outputs": [
      {
        "description": "Specified by `output_shape` argument",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": "# add a x -> x^2 layer\nmodel.add(Lambda(lambda x: x ** 2))"
      },
      {
        "code": "# add a layer that returns the concatenation\n# of the positive part of the input and\n# the opposite of the negative part\n\ndef antirectifier(x):\n    x -= K.mean(x, axis=1, keepdims=True)\n    x = K.l2_normalize(x, axis=1)\n    pos = K.relu(x)\n    neg = K.relu(-x)\n    return K.concatenate([pos, neg], axis=1)\n\nmodel.add(Lambda(antirectifier))"
      }
    ]
  },
  {
    "name": "LeakyReLU",
    "module": "tensorflow.keras.layers",
    "category": "Activation",
    "description": "Leaky version of a Rectified Linear Unit.\n\nIt allows a small gradient when the unit is not active:\n\n```\n  f(x) = alpha * x if x < 0\n  f(x) = x if x >= 0\n```",
    "attributes": [
      {
        "description": "Float >= 0. Negative slope coefficient. Default to 0.3.",
        "name": "alpha"
      }
    ],
    "inputs": [
      {
        "description": "Arbitrary. Use the keyword argument `input_shape`\n(tuple of integers, does not include the batch axis)\nwhen using this layer as the first layer in a model.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "Same shape as the input.",
        "name": "output"
      }
    ],
    "references": [
      {
        "description": "[Rectifier Nonlinearities Improve Neural Network Acoustic Models]( https://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf)"
      }
    ],
    "examples": [
      {
        "code": ">>> layer = tf.keras.layers.LeakyReLU()\n>>> output = layer([-3.0, -1.0, 0.0, 2.0])\n>>> list(output.numpy())\n[-0.9, -0.3, 0.0, 2.0]\n>>> layer = tf.keras.layers.LeakyReLU(alpha=0.1)\n>>> output = layer([-3.0, -1.0, 0.0, 2.0])\n>>> list(output.numpy())\n[-0.3, -0.1, 0.0, 2.0]"
      }
    ]
  },
  {
    "name": "LocallyConnected1D",
    "module": "tensorflow.keras.layers",
    "category": "Layer",
    "description": "Locally-connected layer for 1D inputs.\n\nThe `LocallyConnected1D` layer works similarly to\nthe `Conv1D` layer, except that weights are unshared,\nthat is, a different set of filters is applied at each different patch\nof the input.\n\nNote: layer attributes cannot be modified after the layer has been called\nonce (except the `trainable` attribute).",
    "attributes": [
      {
        "description": "Integer, the dimensionality of the output space (i.e. the\n      number of output filters in the convolution).",
        "name": "filters"
      },
      {
        "description": "An integer or tuple/list of a single integer, specifying\n      the length of the 1D convolution window.",
        "name": "kernel_size"
      },
      {
        "description": "An integer or tuple/list of a single integer, specifying the\n      stride length of the convolution.",
        "name": "strides"
      },
      {
        "description": "Currently only supports `\"valid\"` (case-insensitive). `\"same\"`\n      may be supported in the future. `\"valid\"` means no padding.",
        "name": "padding"
      },
      {
        "description": "Activation function to use. If you don't specify anything,\n      no activation is applied (ie. \"linear\" activation: `a(x) = x`).",
        "name": "activation"
      },
      {
        "description": "Boolean, whether the layer uses a bias vector.",
        "name": "use_bias"
      },
      {
        "description": "Initializer for the `kernel` weights matrix.",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "description": "Initializer for the bias vector.",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the `kernel` weights\n      matrix.",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the bias vector.",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the output of the\n      layer (its \"activation\")..",
        "name": "activity_regularizer",
        "visible": false
      },
      {
        "description": "Constraint function applied to the kernel matrix.",
        "name": "kernel_constraint"
      },
      {
        "description": "Constraint function applied to the bias vector.",
        "name": "bias_constraint"
      },
      {
        "default": "channels_last",
        "description": "A string, one of `channels_last` (default) or\n      `channels_first`. The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape `(batch, length,\n      channels)` while `channels_first` corresponds to inputs with shape\n      `(batch, channels, length)`. It defaults to the `image_data_format`\n      value found in your Keras config file at `~/.keras/keras.json`. If you\n      never set it, then it will be \"channels_last\".",
        "name": "data_format"
      },
      {
        "description": "implementation mode, either `1`, `2`, or `3`. `1` loops\n      over input spatial locations to perform the forward pass. It is\n      memory-efficient but performs a lot of (small) ops.  `2` stores layer\n      weights in a dense but sparsely-populated 2D matrix and implements the\n      forward pass as a single matrix-multiply. It uses a lot of RAM but\n      performs few (large) ops.  `3` stores layer weights in a sparse tensor\n      and implements the forward pass as a single sparse matrix-multiply.\n        How to choose:\n        `1`: large, dense models,\n        `2`: small models,\n        `3`: large, sparse models,  where \"large\" stands for large\n          input/output activations (i.e. many `filters`, `input_filters`,\n          large `input_size`, `output_size`), and \"sparse\" stands for few\n          connections between inputs and outputs, i.e. small ratio\n          `filters * input_filters * kernel_size / (input_size * strides)`,\n          where inputs to and outputs of the layer are assumed to have\n          shapes `(input_size, input_filters)`, `(output_size, filters)`\n          respectively.  It is recommended to benchmark each in the setting\n          of interest to pick the most efficient one (in terms of speed and\n          memory usage). Correct choice of implementation can lead to\n          dramatic speed improvements (e.g. 50X), potentially at the expense\n          of RAM.  Also, only `padding=\"valid\"` is supported by\n          `implementation=1`.",
        "name": "implementation"
      }
    ],
    "inputs": [
      {
        "description": "3D tensor with shape: `(batch_size, steps, input_dim)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "3D tensor with shape: `(batch_size, new_steps, filters)` `steps` value\n  might have changed due to padding or strides.",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": "    # apply a unshared weight convolution 1d of length 3 to a sequence with\n    # 10 timesteps, with 64 output filters\n    model = Sequential()\n    model.add(LocallyConnected1D(64, 3, input_shape=(10, 32)))\n    # now model.output_shape == (None, 8, 64)\n    # add a new conv1d on top\n    model.add(LocallyConnected1D(32, 3))\n    # now model.output_shape == (None, 6, 32)"
      }
    ]
  },
  {
    "name": "LocallyConnected2D",
    "module": "tensorflow.keras.layers",
    "category": "Layer",
    "description": "Locally-connected layer for 2D inputs.\n\nThe `LocallyConnected2D` layer works similarly\nto the `Conv2D` layer, except that weights are unshared,\nthat is, a different set of filters is applied at each\ndifferent patch of the input.\n\nNote: layer attributes cannot be modified after the layer has been called\nonce (except the `trainable` attribute).",
    "attributes": [
      {
        "description": "Integer, the dimensionality of the output space (i.e. the\n      number of output filters in the convolution).",
        "name": "filters"
      },
      {
        "description": "An integer or tuple/list of 2 integers, specifying the\n      width and height of the 2D convolution window. Can be a single integer\n      to specify the same value for all spatial dimensions.",
        "name": "kernel_size"
      },
      {
        "description": "An integer or tuple/list of 2 integers, specifying the strides\n      of the convolution along the width and height. Can be a single integer\n      to specify the same value for all spatial dimensions.",
        "name": "strides"
      },
      {
        "description": "Currently only support `\"valid\"` (case-insensitive). `\"same\"`\n      will be supported in future. `\"valid\"` means no padding.",
        "name": "padding"
      },
      {
        "default": "channels_last",
        "description": "A string, one of `channels_last` (default) or\n      `channels_first`. The ordering of the dimensions in the inputs.\n      `channels_last` corresponds to inputs with shape `(batch, height,\n        width, channels)` while `channels_first` corresponds to inputs with\n        shape\n      `(batch, channels, height, width)`. It defaults to the\n      `image_data_format` value found in your Keras config file at\n      `~/.keras/keras.json`. If you never set it, then it will be\n      \"channels_last\".",
        "name": "data_format"
      },
      {
        "description": "Activation function to use. If you don't specify anything,\n      no activation is applied (ie. \"linear\" activation: `a(x) = x`).",
        "name": "activation"
      },
      {
        "description": "Boolean, whether the layer uses a bias vector.",
        "name": "use_bias",
        "visible": false
      },
      {
        "description": "Initializer for the `kernel` weights matrix.",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "description": "Initializer for the bias vector.",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the `kernel` weights\n      matrix.",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the bias vector.",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the output of the\n      layer (its \"activation\").",
        "name": "activity_regularizer"
      },
      {
        "description": "Constraint function applied to the kernel matrix.",
        "name": "kernel_constraint"
      },
      {
        "description": "Constraint function applied to the bias vector.",
        "name": "bias_constraint"
      },
      {
        "description": "implementation mode, either `1`, `2`, or `3`. `1` loops\n      over input spatial locations to perform the forward pass. It is\n      memory-efficient but performs a lot of (small) ops.  `2` stores layer\n      weights in a dense but sparsely-populated 2D matrix and implements the\n      forward pass as a single matrix-multiply. It uses a lot of RAM but\n      performs few (large) ops.  `3` stores layer weights in a sparse tensor\n      and implements the forward pass as a single sparse matrix-multiply.\n        How to choose:\n        `1`: large, dense models,\n        `2`: small models,\n        `3`: large, sparse models,  where \"large\" stands for large\n          input/output activations (i.e. many `filters`, `input_filters`,\n          large `np.prod(input_size)`, `np.prod(output_size)`), and \"sparse\"\n          stands for few connections between inputs and outputs, i.e. small\n          ratio `filters * input_filters * np.prod(kernel_size) /\n          (np.prod(input_size) * np.prod(strides))`, where inputs to and\n          outputs of the layer are assumed to have shapes `input_size +\n          (input_filters,)`, `output_size + (filters,)` respectively. It is\n          recommended to benchmark each in the setting of interest to pick\n          the most efficient one (in terms of speed and memory usage).\n          Correct choice of implementation can lead to dramatic speed\n          improvements (e.g. 50X), potentially at the expense of RAM. Also,\n          only `padding=\"valid\"` is supported by `implementation=1`.",
        "name": "implementation"
      }
    ],
    "inputs": [
      {
        "description": "4D tensor with shape: `(samples, channels, rows, cols)` if\n  data_format='channels_first'\nor 4D tensor with shape: `(samples, rows, cols, channels)` if\n  data_format='channels_last'.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "4D tensor with shape: `(samples, filters, new_rows, new_cols)` if\n  data_format='channels_first'\nor 4D tensor with shape: `(samples, new_rows, new_cols, filters)` if\n  data_format='channels_last'. `rows` and `cols` values might have\n  changed due to padding.",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": "    # apply a 3x3 unshared weights convolution with 64 output filters on a\n    32x32 image\n    # with `data_format=\"channels_last\"`:\n    model = Sequential()\n    model.add(LocallyConnected2D(64, (3, 3), input_shape=(32, 32, 3)))\n    # now model.output_shape == (None, 30, 30, 64)\n    # notice that this layer will consume (30*30)*(3*3*3*64) + (30*30)*64\n    parameters\n\n    # add a 3x3 unshared weights convolution on top, with 32 output filters:\n    model.add(LocallyConnected2D(32, (3, 3)))\n    # now model.output_shape == (None, 28, 28, 32)"
      }
    ]
  },
  {
    "name": "LSTM",
    "module": "tensorflow.keras.layers",
    "category": "Layer",
    "description": "Long Short-Term Memory layer - Hochreiter 1997.\n\nSee [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)\nfor details about the usage of RNN API.\n\nBased on available runtime hardware and constraints, this layer\nwill choose different implementations (cuDNN-based or pure-TensorFlow)\nto maximize the performance. If a GPU is available and all\nthe arguments to the layer meet the requirement of the cuDNN kernel\n(see below for details), the layer will use a fast cuDNN implementation.\n\nThe requirements to use the cuDNN implementation are:\n\n1. `activation` == `tanh`\n2. `recurrent_activation` == `sigmoid`\n3. `recurrent_dropout` == 0\n4. `unroll` is `False`\n5. `use_bias` is `True`\n6. Inputs, if use masking, are strictly right-padded.\n7. Eager execution is enabled in the outermost context.\n\nFor example:\n\n```\n>>> inputs = tf.random.normal([32, 10, 8])\n>>> lstm = tf.keras.layers.LSTM(4)\n>>> output = lstm(inputs)\n>>> print(output.shape)\n(32, 4)\n>>> lstm = tf.keras.layers.LSTM(4, return_sequences=True, return_state=True)\n>>> whole_seq_output, final_memory_state, final_carry_state = lstm(inputs)\n>>> print(whole_seq_output.shape)\n(32, 10, 4)\n>>> print(final_memory_state.shape)\n(32, 4)\n>>> print(final_carry_state.shape)\n(32, 4)\n```",
    "attributes": [
      {
        "description": "Positive integer, dimensionality of the output space.",
        "name": "units"
      },
      {
        "default": "tanh",
        "description": "Activation function to use.",
        "name": "activation"
      },
      {
        "default": "hard_sigmoid",
        "description": "Activation function to use for the recurrent step.",
        "name": "recurrent_activation"
      },
      {
        "description": "Boolean (default `True`), whether the layer uses a bias vector.",
        "name": "use_bias",
        "visible": false
      },
      {
        "description": "Initializer for the `kernel` weights matrix, used for\n    the linear transformation of the inputs. Default: `glorot_uniform`.",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "description": "Initializer for the `recurrent_kernel` weights\n    matrix, used for the linear transformation of the recurrent state.",
        "name": "recurrent_initializer",
        "visible": false
      },
      {
        "description": "Initializer for the bias vector. Default: `zeros`.",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "default": true,
        "description": "Boolean (default `True`). If True, add 1 to the bias of\n    the forget gate at initialization. Setting it to true will also force\n    `bias_initializer=\"zeros\"`. This is recommended in [Jozefowicz et\n        al.](http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf).",
        "name": "unit_forget_bias"
      },
      {
        "description": "Regularizer function applied to the `kernel` weights\n    matrix. Default: `None`.",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the\n    `recurrent_kernel` weights matrix. Default: `None`.",
        "name": "recurrent_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the bias vector.",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the output of the\n    layer (its \"activation\"). Default: `None`.",
        "name": "activity_regularizer",
        "visible": false
      },
      {
        "description": "Constraint function applied to the `kernel` weights\n    matrix. Default: `None`.",
        "name": "kernel_constraint",
        "visible": false
      },
      {
        "description": "Constraint function applied to the\n    `recurrent_kernel` weights matrix. Default: `None`.",
        "name": "recurrent_constraint",
        "visible": false
      },
      {
        "description": "Constraint function applied to the bias vector. Default:\n    `None`.",
        "name": "bias_constraint",
        "visible": false
      },
      {
        "default": 0,
        "description": "Float between 0 and 1. Fraction of the units to drop for the\n    linear transformation of the inputs. Default: 0.",
        "name": "dropout"
      },
      {
        "default": 0,
        "description": "Float between 0 and 1. Fraction of the units to drop\n    for the linear transformation of the recurrent state. Default: 0.",
        "name": "recurrent_dropout"
      },
      {
        "default": 1,
        "description": "Implementation mode, either 1 or 2. Mode 1 will structure\n    its operations as a larger number of smaller dot products and additions,\n    whereas mode 2 will batch them into fewer, larger operations. These modes\n    will have different performance profiles on different hardware and for\n    different applications. Default: 2.",
        "name": "implementation"
      },
      {
        "default": false,
        "description": "Boolean. Whether to return the last output in the output\n    sequence, or the full sequence. Default: `False`.",
        "name": "return_sequences"
      },
      {
        "default": false,
        "description": "Boolean. Whether to return the last state in addition to the\n    output. Default: `False`.",
        "name": "return_state"
      },
      {
        "default": false,
        "description": "Boolean (default `False`). If True, process the input\n    sequence backwards and return the reversed sequence.",
        "name": "go_backwards"
      },
      {
        "default": false,
        "description": "Boolean (default `False`). If True, the last state for each\n  sample at index i in a batch will be used as initial state for the sample\n    of index i in the following batch.",
        "name": "stateful"
      },
      {
        "default": false,
        "description": "Boolean (default `False`). If True, the network will be unrolled,\n    else a symbolic loop will be used. Unrolling can speed-up a RNN,\n    although it tends to be more memory-intensive. Unrolling is only\n    suitable for short sequences.",
        "name": "unroll"
      },
      {
        "description": "`None`.",
        "name": "Default"
      },
      {
        "description": "The shape format of the `inputs` and `outputs` tensors.\n    If True, the inputs and outputs will be in shape\n    `[timesteps, batch, feature]`, whereas in the False case, it will be\n    `[batch, timesteps, feature]`. Using `time_major = True` is a bit more\n    efficient because it avoids transposes at the beginning and end of the\n    RNN calculation. However, most TensorFlow data is batch-major, so by\n    default this function accepts input and emits output in batch-major\n    form.",
        "name": "time_major"
      }
    ],
    "inputs": [
      {
        "name": "input"
      },
      {
        "name": "kernel"
      },
      {
        "name": "recurrent_kernel"
      },
      {
        "name": "bias"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ],
    "references": [
      {
        "description": "[Long short-term memory](http://www.bioinf.jku.at/publications/older/2604.pdf)"
      },
      {
        "description": "[Learning to forget: Continual prediction with LSTM](http://www.mitpressjournals.org/doi/pdf/10.1162/089976600300015015)"
      },
      {
        "description": "[Supervised sequence labeling with recurrent neural networks](http://www.cs.toronto.edu/~graves/preprint.pdf)"
      },
      {
        "description": "[A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](https://arxiv.org/abs/1512.05287)"
      }
    ]
  },
  {
    "name": "LSTMCell",
    "module": "tensorflow.keras.layers",
    "description": "Cell class for the LSTM layer.\n\nSee [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)\nfor details about the usage of RNN API.\n\nThis class processes one step within the whole time sequence input, whereas\n`tf.keras.layer.LSTM` processes the whole sequence.\n\nFor example:\n\n```\n>>> inputs = tf.random.normal([32, 10, 8])\n>>> rnn = tf.keras.layers.RNN(tf.keras.layers.LSTMCell(4))\n>>> output = rnn(inputs)\n>>> print(output.shape)\n(32, 4)\n>>> rnn = tf.keras.layers.RNN(\n...    tf.keras.layers.LSTMCell(4),\n...    return_sequences=True,\n...    return_state=True)\n>>> whole_seq_output, final_memory_state, final_carry_state = rnn(inputs)\n>>> print(whole_seq_output.shape)\n(32, 10, 4)\n>>> print(final_memory_state.shape)\n(32, 4)\n>>> print(final_carry_state.shape)\n(32, 4)\n```",
    "attributes": [
      {
        "description": "Positive integer, dimensionality of the output space.",
        "name": "units"
      },
      {
        "description": "`a(x) = x`).",
        "name": "activation"
      },
      {
        "description": "Activation function to use for the recurrent step.",
        "name": "recurrent_activation"
      },
      {
        "default": true,
        "description": "Boolean, (default `True`), whether the layer uses a bias vector.",
        "name": "use_bias"
      },
      {
        "description": "Initializer for the `kernel` weights matrix, used for\n    the linear transformation of the inputs. Default: `glorot_uniform`.",
        "name": "kernel_initializer"
      },
      {
        "description": "Initializer for the `recurrent_kernel` weights\n    matrix, used for the linear transformation of the recurrent state.",
        "name": "recurrent_initializer"
      },
      {
        "description": "Initializer for the bias vector. Default: `zeros`.",
        "name": "bias_initializer"
      },
      {
        "description": "Boolean (default `True`). If True, add 1 to the bias of\n    the forget gate at initialization. Setting it to true will also force\n    `bias_initializer=\"zeros\"`. This is recommended in [Jozefowicz et\n      al.](https://github.com/mlresearch/v37/blob/gh-pages/jozefowicz15.pdf)",
        "name": "unit_forget_bias"
      },
      {
        "description": "Regularizer function applied to the `kernel` weights\n    matrix. Default: `None`.",
        "name": "kernel_regularizer"
      },
      {
        "description": "Regularizer function applied to\n    the `recurrent_kernel` weights matrix. Default: `None`.",
        "name": "recurrent_regularizer"
      },
      {
        "description": "Regularizer function applied to the bias vector.",
        "name": "bias_regularizer"
      },
      {
        "description": "Constraint function applied to the `kernel` weights\n    matrix. Default: `None`.",
        "name": "kernel_constraint"
      },
      {
        "description": "Constraint function applied to the\n    `recurrent_kernel` weights matrix. Default: `None`.",
        "name": "recurrent_constraint"
      },
      {
        "description": "Constraint function applied to the bias vector. Default:\n    `None`.",
        "name": "bias_constraint"
      },
      {
        "default": 0,
        "description": "Float between 0 and 1. Fraction of the units to drop for the\n    linear transformation of the inputs. Default: 0.",
        "name": "dropout"
      },
      {
        "default": 0,
        "description": "Float between 0 and 1. Fraction of the units to drop\n    for the linear transformation of the recurrent state. Default: 0.",
        "name": "recurrent_dropout"
      },
      {
        "description": "Implementation mode, either 1 or 2.\n    Mode 1 will structure its operations as a larger number of smaller dot\n    products and additions, whereas mode 2 (default) will batch them into\n    fewer, larger operations. These modes will have different performance\n    profiles on different hardware and for different applications. Default: 2.",
        "name": "implementation"
      },
      {
        "description": "`None`.",
        "name": "Default"
      }
    ]
  },
  {
    "name": "Masking",
    "module": "tensorflow.keras.layers",
    "description": "Masks a sequence by using a mask value to skip timesteps.\n\nFor each timestep in the input tensor (dimension #1 in the tensor),\nif all values in the input tensor at that timestep\nare equal to `mask_value`, then the timestep will be masked (skipped)\nin all downstream layers (as long as they support masking).\n\nIf any downstream layer does not support masking yet receives such\nan input mask, an exception will be raised.",
    "attributes": [
      {
        "description": "Either None or mask value to skip\n",
        "name": "mask_value"
      }
    ],
    "examples": [
      {
        "summary": "Consider a Numpy data array `x` of shape `(samples, timesteps, features)`,\nto be fed to an LSTM layer. You want to mask timestep #3 and #5 because you\nlack data for these timesteps. You can:\n- Set `x[:, 3, :] = 0.` and `x[:, 5, :] = 0.`\n- Insert a `Masking` layer with `mask_value=0.` before the LSTM layer:",
        "code": "samples, timesteps, features = 32, 10, 8\ninputs = np.random.random([samples, timesteps, features]).astype(np.float32)\ninputs[:, 3, :] = 0.\ninputs[:, 5, :] = 0.\n\nmodel = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Masking(mask_value=0.,\n                                  input_shape=(timesteps, features)))\nmodel.add(tf.keras.layers.LSTM(32))\n\noutput = model(inputs)\n# The time step 3 and 5 will be skipped from LSTM calculation."
      }
    ]
  },
  {
    "name": "Maximum",
    "module": "tensorflow.keras.layers",
    "category": "Tensor",
    "description": "Layer that computes the maximum (element-wise) a list of inputs.\n\nIt takes as input a list of tensors, all of the same shape, and returns\na single tensor (also of the same shape).\n\n```\n>>> tf.keras.layers.Maximum()([np.arange(5).reshape(5, 1),\n...                            np.arange(5, 10).reshape(5, 1)])\n<tf.Tensor: shape=(5, 1), dtype=int64, numpy=\narray([[5],\n     [6],\n     [7],\n     [8],\n     [9]])>\n```\n\n```\n>>> x1 = tf.keras.layers.Dense(8)(np.arange(10).reshape(5, 2))\n>>> x2 = tf.keras.layers.Dense(8)(np.arange(10, 20).reshape(5, 2))\n>>> maxed = tf.keras.layers.Maximum()([x1, x2])\n>>> maxed.shape\nTensorShape([5, 8])\n```",
    "inputs": [
      {
        "name": "inputs",
        "list": true
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ]
  },
  {
    "name": "MaxPooling1D",
    "module": "tensorflow.keras.layers",
    "category": "Pool",
    "description": "Max pooling operation for 1D temporal data.\n\nDownsamples the input representation by taking the maximum value over a\nspatial window of size `pool_size`. The window is shifted by `strides`.  The\nresulting output, when using the `\"valid\"` padding option, has a shape of:\n`output_shape = (input_shape - pool_size + 1) / strides)`\n\nThe resulting output shape when using the `\"same\"` padding option is:\n`output_shape = input_shape / strides`\n\nFor example, for `strides=1` and `padding=\"valid\"`:\n\n```\n>>> x = tf.constant([1., 2., 3., 4., 5.])\n>>> x = tf.reshape(x, [1, 5, 1])\n>>> max_pool_1d = tf.keras.layers.MaxPooling1D(pool_size=2,\n...    strides=1, padding='valid')\n>>> max_pool_1d(x)\n<tf.Tensor: shape=(1, 4, 1), dtype=float32, numpy=\narray([[[2.],\n        [3.],\n        [4.],\n        [5.]]], dtype=float32)>\n```\n\nFor example, for `strides=2` and `padding=\"valid\"`:\n\n```\n>>> x = tf.constant([1., 2., 3., 4., 5.])\n>>> x = tf.reshape(x, [1, 5, 1])\n>>> max_pool_1d = tf.keras.layers.MaxPooling1D(pool_size=2,\n...    strides=2, padding='valid')\n>>> max_pool_1d(x)\n<tf.Tensor: shape=(1, 2, 1), dtype=float32, numpy=\narray([[[2.],\n        [4.]]], dtype=float32)>\n```\n\nFor example, for `strides=1` and `padding=\"same\"`:\n\n```\n>>> x = tf.constant([1., 2., 3., 4., 5.])\n>>> x = tf.reshape(x, [1, 5, 1])\n>>> max_pool_1d = tf.keras.layers.MaxPooling1D(pool_size=2,\n...    strides=1, padding='same')\n>>> max_pool_1d(x)\n<tf.Tensor: shape=(1, 5, 1), dtype=float32, numpy=\narray([[[2.],\n        [3.],\n        [4.],\n        [5.],\n        [5.]]], dtype=float32)>\n```",
    "attributes": [
      {
        "default": "channels_last",
        "description": "A string,\n    one of `channels_last` (default) or `channels_first`.\n    The ordering of the dimensions in the inputs.\n    `channels_last` corresponds to inputs with shape\n    `(batch, steps, features)` while `channels_first`\n    corresponds to inputs with shape\n    `(batch, features, steps)`.",
        "name": "data_format"
      },
      {
        "default": "valid",
        "description": "One of `\"valid\"` or `\"same\"` (case-insensitive).\n    `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n    the left/right or up/down of the input such that output has the same\n    height/width dimension as the input.",
        "name": "padding"
      },
      {
        "default": [
          2,
          2
        ],
        "description": "Integer, size of the max pooling window.",
        "name": "pool_size"
      },
      {
        "default": [
          2,
          2
        ],
        "description": "Integer, or None. Specifies how much the pooling window moves\n    for each pooling step.\n    If None, it will default to `pool_size`.",
        "name": "strides"
      }
    ],
    "inputs": [
      {
        "description": "- If `data_format='channels_last'`:\n  3D tensor with shape `(batch_size, steps, features)`.\n- If `data_format='channels_first'`:\n  3D tensor with shape `(batch_size, features, steps)`.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "- If `data_format='channels_last'`:\n  3D tensor with shape `(batch_size, downsampled_steps, features)`.\n- If `data_format='channels_first'`:\n  3D tensor with shape `(batch_size, features, downsampled_steps)`.",
        "name": "output"
      }
    ]
  },
  {
    "name": "MaxPooling2D",
    "module": "tensorflow.keras.layers",
    "category": "Pool",
    "description": "Max pooling operation for 2D spatial data.\n\nDownsamples the input along its spatial dimensions (height and width)\nby taking the maximum value over an input window\n(of size defined by `pool_size`) for each channel of the input.\nThe window is shifted by `strides` along each dimension.\n\nThe resulting output,\nwhen using the `\"valid\"` padding option, has a spatial shape\n(number of rows or columns) of:\n`output_shape = math.floor((input_shape - pool_size) / strides) + 1`\n(when `input_shape >= pool_size`)\n\nThe resulting output shape when using the `\"same\"` padding option is:\n`output_shape = math.floor((input_shape - 1) / strides) + 1`\n\nFor example, for `strides=(1, 1)` and `padding=\"valid\"`:\n\n```\n>>> x = tf.constant([[1., 2., 3.],\n...                  [4., 5., 6.],\n...                  [7., 8., 9.]])\n>>> x = tf.reshape(x, [1, 3, 3, 1])\n>>> max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n...    strides=(1, 1), padding='valid')\n>>> max_pool_2d(x)\n<tf.Tensor: shape=(1, 2, 2, 1), dtype=float32, numpy=\n  array([[[[5.],\n           [6.]],\n          [[8.],\n           [9.]]]], dtype=float32)>\n```\n\nFor example, for `strides=(2, 2)` and `padding=\"valid\"`:\n\n```\n>>> x = tf.constant([[1., 2., 3., 4.],\n...                  [5., 6., 7., 8.],\n...                  [9., 10., 11., 12.]])\n>>> x = tf.reshape(x, [1, 3, 4, 1])\n>>> max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n...    strides=(2, 2), padding='valid')\n>>> max_pool_2d(x)\n<tf.Tensor: shape=(1, 1, 2, 1), dtype=float32, numpy=\n  array([[[[6.],\n           [8.]]]], dtype=float32)>\n```\n\nUsage Example:\n\n```\n>>> input_image = tf.constant([[[[1.], [1.], [2.], [4.]],\n...                            [[2.], [2.], [3.], [2.]],\n...                            [[4.], [1.], [1.], [1.]],\n...                            [[2.], [2.], [1.], [4.]]]])\n>>> output = tf.constant([[[[1], [0]],\n...                       [[0], [1]]]])\n>>> model = tf.keras.models.Sequential()\n>>> model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n...    input_shape=(4, 4, 1)))\n>>> model.compile('adam', 'mean_squared_error')\n>>> model.predict(input_image, steps=1)\narray([[[[2.],\n         [4.]],\n        [[4.],\n         [4.]]]], dtype=float32)\n```\n\nFor example, for stride=(1, 1) and padding=\"same\":\n\n```\n>>> x = tf.constant([[1., 2., 3.],\n...                  [4., 5., 6.],\n...                  [7., 8., 9.]])\n>>> x = tf.reshape(x, [1, 3, 3, 1])\n>>> max_pool_2d = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n...    strides=(1, 1), padding='same')\n>>> max_pool_2d(x)\n<tf.Tensor: shape=(1, 3, 3, 1), dtype=float32, numpy=\n  array([[[[5.],\n           [6.],\n           [6.]],\n          [[8.],\n           [9.],\n           [9.]],\n          [[8.],\n           [9.],\n           [9.]]]], dtype=float32)>\n```",
    "attributes": [
      {
        "default": "channels_last",
        "description": "A string,\n    one of `channels_last` (default) or `channels_first`.\n    The ordering of the dimensions in the inputs.\n    `channels_last` corresponds to inputs with shape\n    `(batch, height, width, channels)` while `channels_first`\n    corresponds to inputs with shape\n    `(batch, channels, height, width)`.\n    It defaults to the `image_data_format` value found in your\n    Keras config file at `~/.keras/keras.json`.\n    If you never set it, then it will be \"channels_last\".",
        "name": "data_format"
      },
      {
        "default": "valid",
        "description": "One of `\"valid\"` or `\"same\"` (case-insensitive).\n    `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n    the left/right or up/down of the input such that output has the same\n    height/width dimension as the input.",
        "name": "padding"
      },
      {
        "default": [
          2,
          2
        ],
        "description": "integer or tuple of 2 integers,\n    window size over which to take the maximum.\n    `(2, 2)` will take the max value over a 2x2 pooling window.\n    If only one integer is specified, the same window length\n    will be used for both dimensions.",
        "name": "pool_size"
      },
      {
        "default": [
          2,
          2
        ],
        "description": "Integer, tuple of 2 integers, or None.\n    Strides values.  Specifies how far the pooling window moves\n    for each pooling step. If None, it will default to `pool_size`.",
        "name": "strides"
      }
    ],
    "inputs": [
      {
        "description": "- If `data_format='channels_last'`:\n  4D tensor with shape `(batch_size, rows, cols, channels)`.\n- If `data_format='channels_first'`:\n  4D tensor with shape `(batch_size, channels, rows, cols)`.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "- If `data_format='channels_last'`:\n  4D tensor with shape `(batch_size, pooled_rows, pooled_cols, channels)`.\n- If `data_format='channels_first'`:\n  4D tensor with shape `(batch_size, channels, pooled_rows, pooled_cols)`.",
        "name": "output"
      }
    ]
  },
  {
    "name": "MaxPooling3D",
    "module": "tensorflow.keras.layers",
    "category": "Pool",
    "description": "Max pooling operation for 3D data (spatial or spatio-temporal).\n\nDownsamples the input along its spatial dimensions (depth, height, and\nwidth) by taking the maximum value over an input window (of size defined by\n`pool_size`) for each channel of the input.  The window is shifted by\n`strides` along each dimension.",
    "attributes": [
      {
        "description": "Tuple of 3 integers,\n    factors by which to downscale (dim1, dim2, dim3).\n    `(2, 2, 2)` will halve the size of the 3D input in each dimension.",
        "name": "pool_size"
      },
      {
        "description": "tuple of 3 integers, or None. Strides values.",
        "name": "strides"
      },
      {
        "description": "One of `\"valid\"` or `\"same\"` (case-insensitive).\n    `\"valid\"` means no padding. `\"same\"` results in padding evenly to\n    the left/right or up/down of the input such that output has the same\n    height/width dimension as the input.",
        "name": "padding"
      },
      {
        "default": "channels_last",
        "description": "A string,\n    one of `channels_last` (default) or `channels_first`.\n    The ordering of the dimensions in the inputs.\n    `channels_last` corresponds to inputs with shape\n    `(batch, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n    while `channels_first` corresponds to inputs with shape\n    `(batch, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n    It defaults to the `image_data_format` value found in your\n    Keras config file at `~/.keras/keras.json`.\n    If you never set it, then it will be \"channels_last\".",
        "name": "data_format"
      }
    ],
    "inputs": [
      {
        "description": "- If `data_format='channels_last'`:\n  5D tensor with shape:\n  `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n- If `data_format='channels_first'`:\n  5D tensor with shape:\n  `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "- If `data_format='channels_last'`:\n  5D tensor with shape:\n  `(batch_size, pooled_dim1, pooled_dim2, pooled_dim3, channels)`\n- If `data_format='channels_first'`:\n  5D tensor with shape:\n  `(batch_size, channels, pooled_dim1, pooled_dim2, pooled_dim3)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": "depth = 30\nheight = 30\nwidth = 30\ninput_channels = 3\n\ninputs = tf.keras.Input(shape=(depth, height, width, input_channels))\nlayer = tf.keras.layers.MaxPooling3D(pool_size=3)\noutputs = layer(inputs)  # Shape: (batch_size, 10, 10, 10, 3)"
      }
    ]
  },
  {
    "name": "MultiHeadAttention",
    "module": "tensorflow.keras.layers",
    "description": "MultiHeadAttention layer.\n\nThis is an implementation of multi-headed attention as described in the\npaper \"Attention is all you Need\" (Vaswani et al., 2017).\nIf `query`, `key,` `value` are the same, then\nthis is self-attention. Each timestep in `query` attends to the\ncorresponding sequence in `key`, and returns a fixed-width vector.\n\nThis layer first projects `query`, `key` and `value`. These are\n(effectively) a list of tensors of length `num_attention_heads`, where the\ncorresponding shapes are `(batch_size, <query dimensions>, key_dim)`,\n`(batch_size, <key/value dimensions>, key_dim)`,\n`(batch_size, <key/value dimensions>, value_dim)`.\n\nThen, the query and key tensors are dot-producted and scaled. These are\nsoftmaxed to obtain attention probabilities. The value tensors are then\ninterpolated by these probabilities, then concatenated back to a single\ntensor.\n\nFinally, the result tensor with the last dimension as value_dim can take an\nlinear projection and return.\n\nWhen using `MultiHeadAttention` inside a custom layer, the custom layer must\nimplement its own `build()` method and call `MultiHeadAttention`'s\n`_build_from_signature()` there.\nThis enables weights to be restored correctly when the model is loaded.",
    "attributes": [
      {
        "description": "Number of attention heads.",
        "name": "num_heads"
      },
      {
        "description": "Size of each attention head for query and key.",
        "name": "key_dim"
      },
      {
        "description": "Size of each attention head for value.",
        "name": "value_dim"
      },
      {
        "description": "Dropout probability.",
        "name": "dropout"
      },
      {
        "description": "Boolean, whether the dense layers use bias vectors/matrices.",
        "name": "use_bias"
      },
      {
        "description": "The expected shape of an output tensor, besides the batch\n        and sequence dims. If not specified, projects back to the query\n        feature dim (the query input's last dimension).",
        "name": "output_shape"
      },
      {
        "description": "axes over which the attention is applied. `None` means\n        attention over all axes, but batch, heads, and features.",
        "name": "attention_axes"
      },
      {
        "description": "Initializer for dense layer kernels.",
        "name": "kernel_initializer"
      },
      {
        "description": "Initializer for dense layer biases.",
        "name": "bias_initializer"
      },
      {
        "description": "Regularizer for dense layer kernels.",
        "name": "kernel_regularizer"
      },
      {
        "description": "Regularizer for dense layer biases.",
        "name": "bias_regularizer"
      },
      {
        "description": "Regularizer for dense layer activity.",
        "name": "activity_regularizer"
      },
      {
        "description": "Constraint for dense layer kernels.",
        "name": "kernel_constraint"
      },
      {
        "description": "Constraint for dense layer kernels.",
        "name": "bias_constraint"
      }
    ],
    "examples": [
      {
        "summary": "Performs 1D cross-attention over two sequence inputs with an attention mask.\nReturns the additional attention weights over heads.",
        "code": ">>> layer = MultiHeadAttention(num_heads=2, key_dim=2)\n>>> target = tf.keras.Input(shape=[8, 16])\n>>> source = tf.keras.Input(shape=[4, 16])\n>>> output_tensor, weights = layer(target, source,\n...                                return_attention_scores=True)\n>>> print(output_tensor.shape)\n(None, 8, 16)\n>>> print(weights.shape)\n(None, 2, 8, 4)"
      },
      {
        "summary": "Performs 2D self-attention over a 5D input tensor on axes 2 and 3.",
        "code": ">>> layer = MultiHeadAttention(\n...     num_heads=2, key_dim=2, attention_axes=(2, 3))\n>>> input_tensor = tf.keras.Input(shape=[5, 3, 4, 16])\n>>> output_tensor = layer(input_tensor, input_tensor)\n>>> print(output_tensor.shape)\n(None, 5, 3, 4, 16)"
      }
    ]
  },
  {
    "name": "Multiply",
    "module": "tensorflow.keras.layers",
    "description": "Layer that multiplies (element-wise) a list of inputs.\n\nIt takes as input a list of tensors, all of the same shape, and returns\na single tensor (also of the same shape).\n\n```\n>>> tf.keras.layers.Multiply()([np.arange(5).reshape(5, 1),\n...                             np.arange(5, 10).reshape(5, 1)])\n<tf.Tensor: shape=(5, 1), dtype=int64, numpy=\narray([[ 0],\n     [ 6],\n     [14],\n     [24],\n     [36]])>\n```\n\n```\n>>> x1 = tf.keras.layers.Dense(8)(np.arange(10).reshape(5, 2))\n>>> x2 = tf.keras.layers.Dense(8)(np.arange(10, 20).reshape(5, 2))\n>>> multiplied = tf.keras.layers.Multiply()([x1, x2])\n>>> multiplied.shape\nTensorShape([5, 8])\n```",
    "inputs": [
      {
        "name": "inputs",
        "list": true
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ]
  },
  {
    "name": "Permute",
    "module": "tensorflow.keras.layers",
    "category": "Shape",
    "description": "Permutes the dimensions of the input according to a given pattern.\n\nUseful e.g. connecting RNNs and convnets.",
    "attributes": [
      {
        "description": "Tuple of integers. Permutation pattern does not include the\n    samples dimension. Indexing starts at 1.\n    For instance, `(2, 1)` permutes the first and second dimensions\n    of the input.",
        "name": "dims"
      }
    ],
    "inputs": [
      {
        "description": "Arbitrary. Use the keyword argument `input_shape`\n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "Same as the input shape, but with the dimensions re-ordered according\nto the specified pattern.",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": "model = Sequential()\nmodel.add(Permute((2, 1), input_shape=(10, 64)))\n# now: model.output_shape == (None, 64, 10)\n# note: `None` is the batch dimension"
      }
    ]
  },
  {
    "name": "PReLU",
    "module": "tensorflow.keras.layers",
    "category": "Activation",
    "description": "Parametric Rectified Linear Unit.\n\nIt follows:\n\n```\n  f(x) = alpha * x for x < 0\n  f(x) = x for x >= 0\n```\n\nwhere `alpha` is a learned array with the same shape as x.",
    "attributes": [
      {
        "description": "Initializer function for the weights.",
        "name": "alpha_initializer"
      },
      {
        "description": "Regularizer for the weights.",
        "name": "alpha_regularizer",
        "visible": false
      },
      {
        "description": "Constraint for the weights.",
        "name": "alpha_constraint"
      },
      {
        "description": "The axes along which to share learnable\n    parameters for the activation function.\n    For example, if the incoming feature maps\n    are from a 2D convolution\n    with output shape `(batch, height, width, channels)`,\n    and you wish to share parameters across space\n    so that each filter only has one set of parameters,\n    set `shared_axes=[1, 2]`.",
        "name": "shared_axes"
      }
    ],
    "inputs": [
      {
        "description": "Arbitrary. Use the keyword argument `input_shape`\n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.",
        "name": "input"
      },
      {
        "name": "params"
      }
    ],
    "outputs": [
      {
        "description": "Same shape as the input.",
        "name": "output"
      }
    ],
    "references": [
      {
        "description": "[Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification](https://arxiv.org/abs/1502.01852)"
      }
    ]
  },
  {
    "name": "ReLU",
    "module": "tensorflow.keras.layers",
    "category": "Activation",
    "description": "Rectified Linear Unit activation function.\n\nWith default values, it returns element-wise `max(x, 0)`.\n\nOtherwise, it follows:\n\n```\n  f(x) = max_value if x >= max_value\n  f(x) = x if threshold <= x < max_value\n  f(x) = negative_slope * (x - threshold) otherwise\n```",
    "attributes": [
      {
        "description": "Float >= 0. Maximum activation value. Default to None, which\n    means unlimited.",
        "name": "max_value"
      },
      {
        "description": "Float >= 0. Negative slope coefficient. Default to 0.",
        "name": "negative_slope"
      },
      {
        "description": "Float >= 0. Threshold value for thresholded activation. Default\n    to 0.",
        "name": "threshold"
      }
    ],
    "inputs": [
      {
        "description": "Arbitrary. Use the keyword argument `input_shape`\n(tuple of integers, does not include the batch axis)\nwhen using this layer as the first layer in a model.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "Same shape as the input.",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> layer = tf.keras.layers.ReLU()\n>>> output = layer([-3.0, -1.0, 0.0, 2.0])\n>>> list(output.numpy())\n[0.0, 0.0, 0.0, 2.0]\n>>> layer = tf.keras.layers.ReLU(max_value=1.0)\n>>> output = layer([-3.0, -1.0, 0.0, 2.0])\n>>> list(output.numpy())\n[0.0, 0.0, 0.0, 1.0]\n>>> layer = tf.keras.layers.ReLU(negative_slope=1.0)\n>>> output = layer([-3.0, -1.0, 0.0, 2.0])\n>>> list(output.numpy())\n[-3.0, -1.0, 0.0, 2.0]\n>>> layer = tf.keras.layers.ReLU(threshold=1.5)\n>>> output = layer([-3.0, -1.0, 1.0, 2.0])\n>>> list(output.numpy())\n[0.0, 0.0, 0.0, 2.0]"
      }
    ]
  },
  {
    "name": "RepeatVector",
    "module": "tensorflow.keras.layers",
    "category": "Shape",
    "description": "Repeats the input n times.",
    "attributes": [
      {
        "description": "Integer, repetition factor.\nInput shape: 2D tensor of shape `(num_samples, features)`.\nOutput shape: 3D tensor of shape `(num_samples, n, features)`.",
        "name": "n"
      }
    ],
    "inputs": [
      {
        "description": "2D tensor of shape `(num_samples, features)`.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "3D tensor of shape `(num_samples, n, features)`.",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": "model = Sequential()\nmodel.add(Dense(32, input_dim=32))\n# now: model.output_shape == (None, 32)\n# note: `None` is the batch dimension\n\nmodel.add(RepeatVector(3))\n# now: model.output_shape == (None, 3, 32)"
      }
    ]
  },
  {
    "name": "Reshape",
    "module": "tensorflow.keras.layers",
    "category": "Shape",
    "description": "Layer that reshapes inputs into the given shape.",
    "attributes": [
      {
        "description": "target shape. Tuple of integers.\n    Does not include the batch axis.\n",
        "name": "target_shape"
      }
    ],
    "inputs": [
      {
        "description": "Arbitrary, although all dimensions in the input shape must be known/fixed.\nUse the keyword argument `input_shape` (tuple of integers, does not\ninclude the samples/batch size axis) when using this layer as the first\nlayer in a model.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "`(batch_size,) + target_shape`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> # as first layer in a Sequential model\n>>> model = tf.keras.Sequential()\n>>> model.add(tf.keras.layers.Reshape((3, 4), input_shape=(12,)))\n>>> # model.output_shape == (None, 3, 4), `None` is the batch size.\n>>> model.output_shape\n(None, 3, 4)"
      },
      {
        "code": ">>> # as intermediate layer in a Sequential model\n>>> model.add(tf.keras.layers.Reshape((6, 2)))\n>>> model.output_shape\n(None, 6, 2)"
      },
      {
        "code": ">>> # also supports shape inference using `-1` as dimension\n>>> model.add(tf.keras.layers.Reshape((-1, 2, 2)))\n>>> model.output_shape\n(None, 3, 2, 2)"
      }
    ]
  },
  {
    "name": "RNN",
    "module": "tensorflow.keras.layers",
    "category": "Layer",
    "description": "Base class for recurrent layers.\n\nSee [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)\nfor details about the usage of RNN API.",
    "attributes": [
      {
        "default": false,
        "description": "Boolean (default `False`). Whether to return the last\n    output in the output sequence, or the full sequence.",
        "name": "return_sequences"
      },
      {
        "default": false,
        "description": "Boolean (default `False`). Whether to return the last state\n    in addition to the output.",
        "name": "return_state"
      },
      {
        "default": false,
        "description": "Boolean (default `False`).\n    If True, process the input sequence backwards and return the\n    reversed sequence.",
        "name": "go_backwards"
      },
      {
        "default": false,
        "description": "Boolean (default `False`). If True, the last state\n    for each sample at index i in a batch will be used as initial\n    state for the sample of index i in the following batch.",
        "name": "stateful"
      },
      {
        "default": false,
        "description": "Boolean (default `False`).\n    If True, the network will be unrolled, else a symbolic loop will be\n    used. Unrolling can speed-up a RNN, although it tends to be more\n    memory-intensive. Unrolling is only suitable for short sequences.",
        "name": "unroll"
      },
      {
        "description": "A RNN cell instance or a list of RNN cell instances.\n    A RNN cell is a class that has:\n    - A `call(input_at_t, states_at_t)` method, returning\n      `(output_at_t, states_at_t_plus_1)`. The call method of the\n      cell can also take the optional argument `constants`, see\n      section \"Note on passing external constants\" below.\n    - A `state_size` attribute. This can be a single integer\n      (single state) in which case it is the size of the recurrent\n      state. This can also be a list/tuple of integers (one size per state).\n      The `state_size` can also be TensorShape or tuple/list of\n      TensorShape, to represent high dimension state.\n    - A `output_size` attribute. This can be a single integer or a\n      TensorShape, which represent the shape of the output. For backward\n      compatible reason, if this attribute is not available for the\n      cell, the value will be inferred by the first element of the\n      `state_size`.\n    - A `get_initial_state(inputs=None, batch_size=None, dtype=None)`\n      method that creates a tensor meant to be fed to `call()` as the\n      initial state, if the user didn't specify any initial state via other\n      means. The returned initial state should have a shape of\n      [batch_size, cell.state_size]. The cell might choose to create a\n      tensor full of zeros, or full of other values based on the cell's\n      implementation.\n      `inputs` is the input tensor to the RNN layer, which should\n      contain the batch size as its shape[0], and also dtype. Note that\n      the shape[0] might be `None` during the graph construction. Either\n      the `inputs` or the pair of `batch_size` and `dtype` are provided.\n      `batch_size` is a scalar tensor that represents the batch size\n      of the inputs. `dtype` is `tf.DType` that represents the dtype of\n      the inputs.\n      For backward compatibility, if this method is not implemented\n      by the cell, the RNN layer will create a zero filled tensor with the\n      size of [batch_size, cell.state_size].\n    In the case that `cell` is a list of RNN cell instances, the cells\n    will be stacked on top of each other in the RNN, resulting in an\n    efficient stacked RNN.",
        "name": "cell"
      },
      {
        "description": "dimensionality of the input (integer).\n    This argument (or alternatively,\n    the keyword argument `input_shape`)\n    is required when using this layer as the first layer in a model.",
        "name": "input_dim"
      },
      {
        "description": "Length of input sequences, to be specified\n    when it is constant.\n    This argument is required if you are going to connect\n    `Flatten` then `Dense` layers upstream\n    (without it, the shape of the dense outputs cannot be computed).\n    Note that if the recurrent layer is not the first layer\n    in your model, you would need to specify the input length\n    at the level of the first layer\n    (e.g. via the `input_shape` argument)\n",
        "name": "input_length"
      },
      {
        "description": "The shape format of the `inputs` and `outputs` tensors.\n    If True, the inputs and outputs will be in shape\n    `(timesteps, batch, ...)`, whereas in the False case, it will be\n    `(batch, timesteps, ...)`. Using `time_major = True` is a bit more\n    efficient because it avoids transposes at the beginning and end of the\n    RNN calculation. However, most TensorFlow data is batch-major, so by\n    default this function accepts input and emits output in batch-major\n    form.",
        "name": "time_major"
      },
      {
        "description": "Boolean (default `False`).\n    Whether the output should use zeros for the masked timesteps. Note that\n    this field is only used when `return_sequences` is True and mask is\n    provided. It can useful if you want to reuse the raw output sequence of\n    the RNN without interference from the masked timesteps, eg, merging\n    bidirectional RNNs.",
        "name": "zero_output_for_mask"
      }
    ],
    "inputs": [
      {
        "description": "N-D tensor with shape `[batch_size, timesteps, ...]` or\n`[timesteps, batch_size, ...]` when time_major is True.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "- If `return_state`: a list of tensors. The first tensor is\n    the output. The remaining tensors are the last states,\n    each with shape `[batch_size, state_size]`, where `state_size` could\n    be a high dimension tensor shape.\n  - If `return_sequences`: N-D tensor with shape\n    `[batch_size, timesteps, output_size]`, where `output_size` could\n    be a high dimension tensor shape, or\n    `[timesteps, batch_size, output_size]` when `time_major` is True.\n  - Else, N-D tensor with shape `[batch_size, output_size]`, where\n    `output_size` could be a high dimension tensor shape.\n\nMasking:\n  This layer supports masking for input data with a variable number\n  of timesteps. To introduce masks to your data,\n  use an [tf.keras.layers.Embedding] layer with the `mask_zero` parameter\n  set to `True`.\n\nNote on using statefulness in RNNs:\n  You can set RNN layers to be 'stateful', which means that the states\n  computed for the samples in one batch will be reused as initial states\n  for the samples in the next batch. This assumes a one-to-one mapping\n  between samples in different successive batches.\n\n  To enable statefulness:\n    - Specify `stateful=True` in the layer constructor.\n    - Specify a fixed batch size for your model, by passing\n      If sequential model:\n        `batch_input_shape=(...)` to the first layer in your model.\n      Else for functional model with 1 or more Input layers:\n        `batch_shape=(...)` to all the first layers in your model.\n      This is the expected shape of your inputs\n      *including the batch size*.\n      It should be a tuple of integers, e.g. `(32, 10, 100)`.\n    - Specify `shuffle=False` when calling `fit()`.\n\n  To reset the states of your model, call `.reset_states()` on either\n  a specific layer, or on your entire model.\n\nNote on specifying the initial state of RNNs:\n  You can specify the initial state of RNN layers symbolically by\n  calling them with the keyword argument `initial_state`. The value of\n  `initial_state` should be a tensor or list of tensors representing\n  the initial state of the RNN layer.\n\n  You can specify the initial state of RNN layers numerically by\n  calling `reset_states` with the keyword argument `states`. The value of\n  `states` should be a numpy array or list of numpy arrays representing\n  the initial state of the RNN layer.\n\nNote on passing external constants to RNNs:\n  You can pass \"external\" constants to the cell using the `constants`\n  keyword argument of `RNN.__call__` (as well as `RNN.call`) method. This\n  requires that the `cell.call` method accepts the same keyword argument\n  `constants`. Such constants can be used to condition the cell\n  transformation on additional static inputs (not changing over time),\n  a.k.a. an attention mechanism.",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": "from keras.layers import RNN\nfrom keras import backend\n\n# First, let's define a RNN Cell, as a layer subclass.\nclass MinimalRNNCell(keras.layers.Layer):\n\n    def __init__(self, units, **kwargs):\n        self.units = units\n        self.state_size = units\n        super(MinimalRNNCell, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n                                      initializer='uniform',\n                                      name='kernel')\n        self.recurrent_kernel = self.add_weight(\n            shape=(self.units, self.units),\n            initializer='uniform',\n            name='recurrent_kernel')\n        self.built = True\n\n    def call(self, inputs, states):\n        prev_output = states[0]\n        h = backend.dot(inputs, self.kernel)\n        output = h + backend.dot(prev_output, self.recurrent_kernel)\n        return output, [output]\n\n# Let's use this cell in a RNN layer:\n\ncell = MinimalRNNCell(32)\nx = keras.Input((None, 5))\nlayer = RNN(cell)\ny = layer(x)\n\n# Here's how to use the cell to build a stacked RNN:\n\ncells = [MinimalRNNCell(32), MinimalRNNCell(64)]\nx = keras.Input((None, 5))\nlayer = RNN(cells)\ny = layer(x)"
      }
    ]
  },
  {
    "name": "SeparableConv1D",
    "module": "tensorflow.keras.layers",
    "category": "Layer",
    "description": "Depthwise separable 1D convolution.\n\nThis layer performs a depthwise convolution that acts separately on\nchannels, followed by a pointwise convolution that mixes channels.\nIf `use_bias` is True and a bias initializer is provided,\nit adds a bias vector to the output.\nIt then optionally applies an activation function to produce the final\noutput.",
    "attributes": [
      {
        "description": "Integer, the dimensionality of the output space (i.e. the number\n    of filters in the convolution).",
        "name": "filters"
      },
      {
        "description": "A single integer specifying the spatial\n    dimensions of the filters.",
        "name": "kernel_size"
      },
      {
        "description": "A single integer specifying the strides\n    of the convolution.\n    Specifying any `stride` value != 1 is incompatible with specifying\n    any `dilation_rate` value != 1.",
        "name": "strides"
      },
      {
        "description": "One of `\"valid\"`, `\"same\"`, or `\"causal\"` (case-insensitive).\n    `\"valid\"` means no padding. `\"same\"` results in padding with zeros\n    evenly to the left/right or up/down of the input such that output has\n    the same height/width dimension as the input. `\"causal\"` results in\n    causal (dilated) convolutions, e.g. `output[t]` does not depend on\n    `input[t+1:]`.",
        "name": "padding"
      },
      {
        "description": "A string, one of `channels_last` (default) or\n    `channels_first`.  The ordering of the dimensions in the inputs.\n    `channels_last` corresponds to inputs with shape\n    `(batch_size, length, channels)` while `channels_first` corresponds to\n    inputs with shape `(batch_size, channels, length)`.",
        "name": "data_format"
      },
      {
        "description": "A single integer, specifying\n    the dilation rate to use for dilated convolution.",
        "name": "dilation_rate"
      },
      {
        "description": "The number of depthwise convolution output channels for\n    each input channel. The total number of depthwise convolution output\n    channels will be equal to `num_filters_in * depth_multiplier`.",
        "name": "depth_multiplier"
      },
      {
        "description": "Activation function to use.\n    If you don't specify anything, no activation is applied\n    (see `keras.activations`).",
        "name": "activation"
      },
      {
        "description": "Boolean, whether the layer uses a bias.",
        "name": "use_bias"
      },
      {
        "description": "An initializer for the depthwise convolution kernel\n    (see `keras.initializers`). If None, then the default initializer\n    ('glorot_uniform') will be used.",
        "name": "depthwise_initializer"
      },
      {
        "description": "An initializer for the pointwise convolution kernel\n    (see `keras.initializers`). If None, then the default initializer\n    ('glorot_uniform') will be used.",
        "name": "pointwise_initializer"
      },
      {
        "description": "An initializer for the bias vector. If None, the default\n    initializer ('zeros') will be used (see `keras.initializers`).",
        "name": "bias_initializer"
      },
      {
        "description": "Optional regularizer for the depthwise\n    convolution kernel (see `keras.regularizers`).",
        "name": "depthwise_regularizer"
      },
      {
        "description": "Optional regularizer for the pointwise\n    convolution kernel (see `keras.regularizers`).",
        "name": "pointwise_regularizer"
      },
      {
        "description": "Optional regularizer for the bias vector\n    (see `keras.regularizers`).",
        "name": "bias_regularizer"
      },
      {
        "description": "Optional regularizer function for the output\n    (see `keras.regularizers`).",
        "name": "activity_regularizer"
      },
      {
        "description": "Optional projection function to be applied to the\n    depthwise kernel after being updated by an `Optimizer` (e.g. used for\n    norm constraints or value constraints for layer weights). The function\n    must take as input the unprojected variable and must return the\n    projected variable (which must have the same shape). Constraints are\n    not safe to use when doing asynchronous distributed training\n    (see `keras.constraints`).",
        "name": "depthwise_constraint"
      },
      {
        "description": "Optional projection function to be applied to the\n    pointwise kernel after being updated by an `Optimizer`\n    (see `keras.constraints`).",
        "name": "pointwise_constraint"
      },
      {
        "description": "Optional projection function to be applied to the\n    bias after being updated by an `Optimizer`\n    (see `keras.constraints`).",
        "name": "bias_constraint"
      },
      {
        "description": "Boolean, if `True` the weights of this layer will be marked as\n    trainable (and listed in `layer.trainable_weights`).",
        "name": "trainable"
      }
    ],
    "inputs": [
      {
        "description": "3D tensor with shape:\n`(batch_size, channels, steps)` if data_format='channels_first'\nor 3D tensor with shape:\n`(batch_size, steps, channels)` if data_format='channels_last'.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "3D tensor with shape:\n`(batch_size, filters, new_steps)` if data_format='channels_first'\nor 3D tensor with shape:\n`(batch_size,  new_steps, filters)` if data_format='channels_last'.\n`new_steps` value might have changed due to padding or strides.",
        "name": "output"
      }
    ]
  },
  {
    "name": "SeparableConv2D",
    "module": "tensorflow.keras.layers",
    "category": "Layer",
    "description": "Depthwise separable 2D convolution.\n\nSeparable convolutions consist of first performing\na depthwise spatial convolution\n(which acts on each input channel separately)\nfollowed by a pointwise convolution which mixes the resulting\noutput channels. The `depth_multiplier` argument controls how many\noutput channels are generated per input channel in the depthwise step.\n\nIntuitively, separable convolutions can be understood as\na way to factorize a convolution kernel into two smaller kernels,\nor as an extreme version of an Inception block.",
    "attributes": [
      {
        "default": "linear",
        "description": "Activation function to use.\n    If you don't specify anything, no activation is applied\n    (see `keras.activations`).",
        "name": "activation"
      },
      {
        "default": "valid",
        "description": "one of `\"valid\"` or `\"same\"` (case-insensitive).\n    `\"valid\"` means no padding. `\"same\"` results in padding with zeros\n    evenly to the left/right or up/down of the input such that output has\n    the same height/width dimension as the input.",
        "name": "padding"
      },
      {
        "default": true,
        "description": "Boolean, whether the layer uses a bias vector.",
        "name": "use_bias",
        "visible": false
      },
      {
        "default": "channels_last",
        "description": "A string,\n    one of `channels_last` (default) or `channels_first`.\n    The ordering of the dimensions in the inputs.\n    `channels_last` corresponds to inputs with shape\n    `(batch_size, height, width, channels)` while `channels_first`\n    corresponds to inputs with shape\n    `(batch_size, channels, height, width)`.\n    It defaults to the `image_data_format` value found in your\n    Keras config file at `~/.keras/keras.json`.\n    If you never set it, then it will be \"channels_last\".",
        "name": "data_format"
      },
      {
        "default": [
          1,
          1
        ],
        "description": "An integer or tuple/list of 2 integers,\n    specifying the strides of the convolution along the height and width.\n    Can be a single integer to specify the same value for\n    all spatial dimensions. Current implementation only supports equal\n    length strides in the row and column dimensions.\n    Specifying any stride value != 1 is incompatible with specifying\n    any `dilation_rate` value != 1.",
        "name": "strides"
      },
      {
        "default": [
          1,
          1
        ],
        "description": "An integer or tuple/list of 2 integers, specifying\n    the dilation rate to use for dilated convolution.",
        "name": "dilation_rate"
      },
      {
        "default": 1,
        "description": "The number of depthwise convolution output channels\n    for each input channel.\n    The total number of depthwise convolution output\n    channels will be equal to `filters_in * depth_multiplier`.",
        "name": "depth_multiplier"
      },
      {
        "default": {
          "class_name": "VarianceScaling",
          "config": {
            "distribution": "uniform",
            "mode": "fan_avg",
            "scale": 1,
            "seed": null
          }
        },
        "description": "An initializer for the pointwise convolution kernel\n    (see `keras.initializers`). If None, then the default initializer\n    ('glorot_uniform') will be used.",
        "name": "pointwise_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "VarianceScaling",
          "config": {
            "distribution": "uniform",
            "mode": "fan_avg",
            "scale": 1,
            "seed": null
          }
        },
        "description": "An initializer for the depthwise convolution kernel\n    (see `keras.initializers`). If None, then the default initializer\n    ('glorot_uniform') will be used.",
        "name": "depthwise_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "Zeros",
          "config": {}
        },
        "description": "An initializer for the bias vector. If None, the default\n    initializer ('zeros') will be used (see `keras.initializers`).",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "VarianceScaling",
          "config": {
            "distribution": "uniform",
            "mode": "fan_avg",
            "scale": 1,
            "seed": null
          }
        },
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "description": "Integer, the dimensionality of the output space\n    (i.e. the number of output filters in the convolution).",
        "name": "filters"
      },
      {
        "description": "An integer or tuple/list of 2 integers, specifying the\n    height and width of the 2D convolution window.\n    Can be a single integer to specify the same value for\n    all spatial dimensions.",
        "name": "kernel_size"
      },
      {
        "description": "Regularizer function applied to\n    the depthwise kernel matrix (see `keras.regularizers`).",
        "name": "depthwise_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to\n    the pointwise kernel matrix (see `keras.regularizers`).",
        "name": "pointwise_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the bias vector\n    (see `keras.regularizers`).",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to\n    the output of the layer (its \"activation\")\n    (see `keras.regularizers`).",
        "name": "activity_regularizer",
        "visible": false
      },
      {
        "description": "Constraint function applied to\n    the depthwise kernel matrix\n    (see `keras.constraints`).",
        "name": "depthwise_constraint",
        "visible": false
      },
      {
        "description": "Constraint function applied to\n    the pointwise kernel matrix\n    (see `keras.constraints`).",
        "name": "pointwise_constraint"
      },
      {
        "description": "Constraint function applied to the bias vector\n    (see `keras.constraints`).",
        "name": "bias_constraint"
      }
    ],
    "inputs": [
      {
        "description": "4D tensor with shape:\n`(batch_size, channels, rows, cols)` if data_format='channels_first'\nor 4D tensor with shape:\n`(batch_size, rows, cols, channels)` if data_format='channels_last'.",
        "name": "input"
      },
      {
        "name": "kernel"
      },
      {
        "name": "bias"
      }
    ],
    "outputs": [
      {
        "description": "4D tensor with shape:\n`(batch_size, filters, new_rows, new_cols)` if\ndata_format='channels_first'\nor 4D tensor with shape:\n`(batch_size, new_rows, new_cols, filters)` if\ndata_format='channels_last'.  `rows` and `cols` values might have changed\ndue to padding.",
        "name": "output"
      }
    ]
  },
  {
    "name": "Sigmoid",
    "category": "Activation"
  },
  {
    "name": "SimpleRNN",
    "module": "tensorflow.keras.layers",
    "category": "Layer",
    "description": "Fully-connected RNN where the output is to be fed back to input.\n\nSee [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)\nfor details about the usage of RNN API.",
    "attributes": [
      {
        "default": false,
        "description": "Boolean. Whether to return the last output\n    in the output sequence, or the full sequence. Default: `False`.",
        "name": "return_sequences"
      },
      {
        "default": false,
        "description": "Boolean. Whether to return the last state\n    in addition to the output. Default: `False`",
        "name": "return_state"
      },
      {
        "default": false,
        "description": "Boolean (default False).\n    If True, process the input sequence backwards and return the\n    reversed sequence.",
        "name": "go_backwards"
      },
      {
        "default": false,
        "description": "Boolean (default False). If True, the last state\n    for each sample at index i in a batch will be used as initial\n    state for the sample of index i in the following batch.",
        "name": "stateful"
      },
      {
        "default": false,
        "description": "Boolean (default False).\n    If True, the network will be unrolled,\n    else a symbolic loop will be used.\n    Unrolling can speed-up a RNN,\n    although it tends to be more memory-intensive.\n    Unrolling is only suitable for short sequences.",
        "name": "unroll"
      },
      {
        "default": "tanh",
        "description": "Activation function to use.",
        "name": "activation"
      },
      {
        "default": true,
        "description": "Boolean, (default `True`), whether the layer uses a bias vector.",
        "name": "use_bias",
        "visible": false
      },
      {
        "default": {
          "class_name": "VarianceScaling",
          "config": {
            "distribution": "uniform",
            "mode": "fan_avg",
            "scale": 1,
            "seed": null
          }
        },
        "description": "Initializer for the `kernel` weights matrix,\n    used for the linear transformation of the inputs. Default:\n    `glorot_uniform`.",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "Orthogonal",
          "config": {
            "gain": 1,
            "seed": null
          }
        },
        "description": "Initializer for the `recurrent_kernel`\n    weights matrix, used for the linear transformation of the recurrent\n    state.  Default: `orthogonal`.",
        "name": "recurrent_initializer",
        "visible": false
      },
      {
        "default": {
          "class_name": "Zeros",
          "config": {}
        },
        "description": "Initializer for the bias vector. Default: `zeros`.",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "default": 0,
        "description": "Float between 0 and 1.\n    Fraction of the units to drop for the linear transformation of the\n    inputs. Default: 0.",
        "name": "dropout"
      },
      {
        "default": 0,
        "description": "Float between 0 and 1.\n    Fraction of the units to drop for the linear transformation of the\n    recurrent state. Default: 0.",
        "name": "recurrent_dropout"
      },
      {
        "description": "Positive integer, dimensionality of the output space.",
        "name": "units"
      },
      {
        "description": "Regularizer function applied to the `kernel` weights\n    matrix. Default: `None`.",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the\n    `recurrent_kernel` weights matrix. Default: `None`.",
        "name": "recurrent_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the bias vector.",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the output of the\n    layer (its \"activation\"). Default: `None`.",
        "name": "activity_regularizer",
        "visible": false
      },
      {
        "description": "Constraint function applied to the `kernel` weights\n    matrix. Default: `None`.",
        "name": "kernel_constraint"
      },
      {
        "description": "Constraint function applied to the\n    `recurrent_kernel` weights matrix.  Default: `None`.",
        "name": "recurrent_constraint"
      },
      {
        "description": "Constraint function applied to the bias vector. Default:\n    `None`.",
        "name": "bias_constraint"
      },
      {
        "description": "`None`.",
        "name": "Default"
      }
    ],
    "inputs": [
      {
        "name": "input"
      },
      {
        "name": "kernel"
      },
      {
        "name": "recurrent_kernel"
      },
      {
        "name": "bias"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": "inputs = np.random.random([32, 10, 8]).astype(np.float32)\nsimple_rnn = tf.keras.layers.SimpleRNN(4)\n\noutput = simple_rnn(inputs)  # The output has shape `[32, 4]`.\n\nsimple_rnn = tf.keras.layers.SimpleRNN(\n    4, return_sequences=True, return_state=True)\n\n# whole_sequence_output has shape `[32, 10, 4]`.\n# final_state has shape `[32, 4]`.\nwhole_sequence_output, final_state = simple_rnn(inputs)"
      }
    ]
  },
  {
    "name": "SimpleRNNCell",
    "module": "tensorflow.keras.layers",
    "description": "Cell class for SimpleRNN.\n\nSee [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)\nfor details about the usage of RNN API.\n\nThis class processes one step within the whole time sequence input, whereas\n`tf.keras.layer.SimpleRNN` processes the whole sequence.",
    "attributes": [
      {
        "description": "Positive integer, dimensionality of the output space.",
        "name": "units"
      },
      {
        "description": "Activation function to use.",
        "name": "activation"
      },
      {
        "description": "Boolean, (default `True`), whether the layer uses a bias vector.",
        "name": "use_bias",
        "visible": false
      },
      {
        "description": "Initializer for the `kernel` weights matrix,\n    used for the linear transformation of the inputs. Default:\n    `glorot_uniform`.",
        "name": "kernel_initializer",
        "visible": false
      },
      {
        "description": "Initializer for the `recurrent_kernel`\n    weights matrix, used for the linear transformation of the recurrent\n    state.  Default: `orthogonal`.",
        "name": "recurrent_initializer",
        "visible": false
      },
      {
        "description": "Initializer for the bias vector. Default: `zeros`.",
        "name": "bias_initializer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the `kernel` weights\n    matrix. Default: `None`.",
        "name": "kernel_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the\n    `recurrent_kernel` weights matrix. Default: `None`.",
        "name": "recurrent_regularizer",
        "visible": false
      },
      {
        "description": "Regularizer function applied to the bias vector.",
        "name": "bias_regularizer",
        "visible": false
      },
      {
        "description": "Constraint function applied to the `kernel` weights\n    matrix. Default: `None`.",
        "name": "kernel_constraint"
      },
      {
        "description": "Constraint function applied to the\n    `recurrent_kernel` weights matrix. Default: `None`.",
        "name": "recurrent_constraint"
      },
      {
        "description": "Constraint function applied to the bias vector. Default:\n    `None`.",
        "name": "bias_constraint"
      },
      {
        "default": 0,
        "description": "Float between 0 and 1. Fraction of the units to drop for the\n    linear transformation of the inputs. Default: 0.",
        "name": "dropout"
      },
      {
        "default": 0,
        "description": "Float between 0 and 1. Fraction of the units to drop\n    for the linear transformation of the recurrent state. Default: 0.",
        "name": "recurrent_dropout"
      },
      {
        "description": "`None`.",
        "name": "Default"
      }
    ],
    "examples": [
      {
        "code": "inputs = np.random.random([32, 10, 8]).astype(np.float32)\nrnn = tf.keras.layers.RNN(tf.keras.layers.SimpleRNNCell(4))\n\noutput = rnn(inputs)  # The output has shape `[32, 4]`.\n\nrnn = tf.keras.layers.RNN(\n    tf.keras.layers.SimpleRNNCell(4),\n    return_sequences=True,\n    return_state=True)\n\n# whole_sequence_output has shape `[32, 10, 4]`.\n# final_state has shape `[32, 4]`.\nwhole_sequence_output, final_state = rnn(inputs)"
      }
    ]
  },
  {
    "name": "Softmax",
    "module": "tensorflow.keras.layers",
    "category": "Activation",
    "description": "Softmax activation function.\n\nExample without mask:\n\n```\n>>> inp = np.asarray([1., 2., 1.])\n>>> layer = tf.keras.layers.Softmax()\n>>> layer(inp).numpy()\narray([0.21194157, 0.5761169 , 0.21194157], dtype=float32)\n>>> mask = np.asarray([True, False, True], dtype=bool)\n>>> layer(inp, mask).numpy()\narray([0.5, 0. , 0.5], dtype=float32)\n```",
    "inputs": [
      {
        "name": "input",
        "description": "Arbitrary. Use the keyword argument `input_shape`\n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model."
      }
    ],
    "outputs": [
      {
        "name": "output",
        "description": "Same shape as the input."
      }
    ],
    "attributes": [
      {
        "name": "axis",
        "description": "Integer, or list of Integers, axis along which the softmax\n    normalization is applied."
      }
    ]
  },
  {
    "name": "SoftPlus",
    "category": "Activation"
  },
  {
    "name": "SoftSign",
    "category": "Activation"
  },
  {
    "name": "SpatialDropout1D",
    "module": "tensorflow.keras.layers",
    "category": "Dropout",
    "description": "Spatial 1D version of Dropout.\n\nThis version performs the same function as Dropout, however, it drops\nentire 1D feature maps instead of individual elements. If adjacent frames\nwithin feature maps are strongly correlated (as is normally the case in\nearly convolution layers) then regular dropout will not regularize the\nactivations and will otherwise just result in an effective learning rate\ndecrease. In this case, SpatialDropout1D will help promote independence\nbetween feature maps and should be used instead.",
    "attributes": [
      {
        "description": "Float between 0 and 1. Fraction of the input units to drop.",
        "name": "rate"
      }
    ],
    "inputs": [
      {
        "description": "3D tensor with shape: `(samples, timesteps, channels)`\nOutput shape: Same as input.\nReferences: - [Efficient Object Localization Using Convolutional\n    Networks](https://arxiv.org/abs/1411.4280)",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "Same as input.",
        "name": "output"
      }
    ],
    "references": [
      {
        "description": "[Efficient Object Localization Using Convolutional Networks](https://arxiv.org/abs/1411.4280)"
      }
    ]
  },
  {
    "name": "SpatialDropout2D",
    "module": "tensorflow.keras.layers",
    "category": "Dropout",
    "description": "Spatial 2D version of Dropout.\n\nThis version performs the same function as Dropout, however, it drops\nentire 2D feature maps instead of individual elements. If adjacent pixels\nwithin feature maps are strongly correlated (as is normally the case in\nearly convolution layers) then regular dropout will not regularize the\nactivations and will otherwise just result in an effective learning rate\ndecrease. In this case, SpatialDropout2D will help promote independence\nbetween feature maps and should be used instead.",
    "attributes": [
      {
        "description": "Float between 0 and 1. Fraction of the input units to drop.",
        "name": "rate"
      },
      {
        "description": "'channels_first' or 'channels_last'. In 'channels_first'\n    mode, the channels dimension (the depth) is at index 1, in\n    'channels_last' mode is it at index 3. It defaults to the\n    `image_data_format` value found in your Keras config file at\n    `~/.keras/keras.json`. If you never set it, then it will be\n    \"channels_last\".",
        "name": "data_format"
      }
    ],
    "inputs": [
      {
        "description": "4D tensor with shape: `(samples, channels, rows, cols)` if\n    data_format='channels_first'\n  or 4D tensor with shape: `(samples, rows, cols, channels)` if\n    data_format='channels_last'.\nOutput shape: Same as input.\nReferences: - [Efficient Object Localization Using Convolutional\n    Networks](https://arxiv.org/abs/1411.4280)",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "Same as input.",
        "name": "output"
      }
    ],
    "references": [
      {
        "description": "[Efficient Object Localization Using Convolutional Networks](https://arxiv.org/abs/1411.4280)"
      }
    ]
  },
  {
    "name": "SpatialDropout3D",
    "module": "tensorflow.keras.layers",
    "category": "Dropout",
    "description": "Spatial 3D version of Dropout.\n\nThis version performs the same function as Dropout, however, it drops\nentire 3D feature maps instead of individual elements. If adjacent voxels\nwithin feature maps are strongly correlated (as is normally the case in\nearly convolution layers) then regular dropout will not regularize the\nactivations and will otherwise just result in an effective learning rate\ndecrease. In this case, SpatialDropout3D will help promote independence\nbetween feature maps and should be used instead.",
    "attributes": [
      {
        "description": "Float between 0 and 1. Fraction of the input units to drop.",
        "name": "rate"
      },
      {
        "description": "'channels_first' or 'channels_last'. In 'channels_first'\n    mode, the channels dimension (the depth) is at index 1, in\n    'channels_last' mode is it at index 4. It defaults to the\n    `image_data_format` value found in your Keras config file at\n    `~/.keras/keras.json`. If you never set it, then it will be\n    \"channels_last\".",
        "name": "data_format"
      }
    ],
    "inputs": [
      {
        "description": "5D tensor with shape: `(samples, channels, dim1, dim2, dim3)` if\n    data_format='channels_first'\n  or 5D tensor with shape: `(samples, dim1, dim2, dim3, channels)` if\n    data_format='channels_last'.\nOutput shape: Same as input.\nReferences: - [Efficient Object Localization Using Convolutional\n    Networks](https://arxiv.org/abs/1411.4280)",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "Same as input.",
        "name": "output"
      }
    ],
    "references": [
      {
        "description": "[Efficient Object Localization Using Convolutional Networks](https://arxiv.org/abs/1411.4280)"
      }
    ]
  },
  {
    "name": "StackedRNNCells",
    "module": "tensorflow.keras.layers",
    "description": "Wrapper allowing a stack of RNN cells to behave as a single cell.\n\nUsed to implement efficient stacked RNNs.",
    "attributes": [
      {
        "description": "List of RNN cell instances.",
        "name": "cells"
      }
    ],
    "examples": [
      {
        "code": "batch_size = 3\nsentence_max_length = 5\nn_features = 2\nnew_shape = (batch_size, sentence_max_length, n_features)\nx = tf.constant(np.reshape(np.arange(30), new_shape), dtype = tf.float32)\n\nrnn_cells = [tf.keras.layers.LSTMCell(128) for _ in range(2)]\nstacked_lstm = tf.keras.layers.StackedRNNCells(rnn_cells)\nlstm_layer = tf.keras.layers.RNN(stacked_lstm)\n\nresult = lstm_layer(x)"
      }
    ]
  },
  {
    "name": "Subtract",
    "module": "tensorflow.keras.layers",
    "description": "Layer that subtracts two inputs.\n\nIt takes as input a list of tensors of size 2, both of the same shape, and\nreturns a single tensor, (inputs[0] - inputs[1]), also of the same shape.",
    "inputs": [
      {
        "name": "x"
      },
      {
        "name": "y"
      }
    ],
    "outputs": [
      {
        "name": "z"
      }
    ],
    "examples": [
      {
        "code": "    import keras\n\n    input1 = keras.layers.Input(shape=(16,))\n    x1 = keras.layers.Dense(8, activation='relu')(input1)\n    input2 = keras.layers.Input(shape=(32,))\n    x2 = keras.layers.Dense(8, activation='relu')(input2)\n    # Equivalent to subtracted = keras.layers.subtract([x1, x2])\n    subtracted = keras.layers.Subtract()([x1, x2])\n\n    out = keras.layers.Dense(4)(subtracted)\n    model = keras.models.Model(inputs=[input1, input2], outputs=out)"
      }
    ]
  },
  {
    "name": "TanH",
    "category": "Activation"
  },
  {
    "name": "ThresholdedReLU",
    "module": "tensorflow.keras.layers",
    "category": "Activation",
    "description": "Thresholded Rectified Linear Unit.\n\nIt follows:\n\n```\n  f(x) = x for x > theta\n  f(x) = 0 otherwise`\n```",
    "attributes": [
      {
        "description": "Float >= 0. Threshold location of activation.",
        "name": "theta"
      }
    ],
    "inputs": [
      {
        "description": "Arbitrary. Use the keyword argument `input_shape`\n(tuple of integers, does not include the samples axis)\nwhen using this layer as the first layer in a model.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "Same shape as the input.",
        "name": "output"
      }
    ],
    "references": [
      {
        "description": "[Zero-Bias Autoencoders and the Benefits of Co-Adapting Features]( https://arxiv.org/abs/1402.3337)"
      }
    ]
  },
  {
    "name": "TimeDistributed",
    "module": "tensorflow.keras.layers",
    "category": "Wrapper",
    "description": "This wrapper allows to apply a layer to every temporal slice of an input.\n\nEvery input should be at least 3D, and the dimension of index one of the\nfirst input will be considered to be the temporal dimension.\n\nConsider a batch of 32 video samples, where each sample is a 128x128 RGB\nimage with `channels_last` data format, across 10 timesteps.\nThe batch input shape is `(32, 10, 128, 128, 3)`.\n\nYou can then use `TimeDistributed` to apply the same `Conv2D` layer to each\nof the 10 timesteps, independently:\n\n```\n>>> inputs = tf.keras.Input(shape=(10, 128, 128, 3))\n>>> conv_2d_layer = tf.keras.layers.Conv2D(64, (3, 3))\n>>> outputs = tf.keras.layers.TimeDistributed(conv_2d_layer)(inputs)\n>>> outputs.shape\nTensorShape([None, 10, 126, 126, 64])\n```\n\nBecause `TimeDistributed` applies the same instance of `Conv2D` to each of\nthe timestamps, the same set of weights are used at each timestamp.",
    "attributes": [
      {
        "description": "a `tf.keras.layers.Layer` instance.",
        "name": "layer"
      }
    ],
    "inputs": [
      {
        "name": "input"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ]
  },
  {
    "name": "UpSampling1D",
    "module": "tensorflow.keras.layers",
    "category": "Layer",
    "description": "Upsampling layer for 1D inputs.\n\nRepeats each temporal step `size` times along the time axis.",
    "attributes": [
      {
        "default": "channels_last",
        "name": "data_format"
      },
      {
        "description": "Integer. Upsampling factor.",
        "name": "size"
      }
    ],
    "inputs": [
      {
        "description": "3D tensor with shape: `(batch_size, steps, features)`.",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "3D tensor with shape: `(batch_size, upsampled_steps, features)`.",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> input_shape = (2, 2, 3)\n>>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n>>> print(x)\n[[[ 0  1  2]\n  [ 3  4  5]]\n [[ 6  7  8]\n  [ 9 10 11]]]\n>>> y = tf.keras.layers.UpSampling1D(size=2)(x)\n>>> print(y)\ntf.Tensor(\n  [[[ 0  1  2]\n    [ 0  1  2]\n    [ 3  4  5]\n    [ 3  4  5]]\n   [[ 6  7  8]\n    [ 6  7  8]\n    [ 9 10 11]\n    [ 9 10 11]]], shape=(2, 4, 3), dtype=int64)"
      }
    ]
  },
  {
    "name": "UpSampling2D",
    "module": "tensorflow.keras.layers",
    "category": "Layer",
    "description": "Upsampling layer for 2D inputs.\n\nRepeats the rows and columns of the data\nby `size[0]` and `size[1]` respectively.",
    "attributes": [
      {
        "default": "channels_last",
        "description": "A string,\n    one of `channels_last` (default) or `channels_first`.\n    The ordering of the dimensions in the inputs.\n    `channels_last` corresponds to inputs with shape\n    `(batch_size, height, width, channels)` while `channels_first`\n    corresponds to inputs with shape\n    `(batch_size, channels, height, width)`.\n    It defaults to the `image_data_format` value found in your\n    Keras config file at `~/.keras/keras.json`.\n    If you never set it, then it will be \"channels_last\".",
        "name": "data_format"
      },
      {
        "description": "Int, or tuple of 2 integers.\n    The upsampling factors for rows and columns.",
        "name": "size"
      },
      {
        "description": "A string, one of `\"area\"`, `\"bicubic\"`, `\"bilinear\"`,\n    `\"gaussian\"`, `\"lanczos3\"`, `\"lanczos5\"`, `\"mitchellcubic\"`,\n    `\"nearest\"`.",
        "name": "interpolation"
      }
    ],
    "inputs": [
      {
        "description": "4D tensor with shape:\n- If `data_format` is `\"channels_last\"`:\n    `(batch_size, rows, cols, channels)`\n- If `data_format` is `\"channels_first\"`:\n    `(batch_size, channels, rows, cols)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "4D tensor with shape:\n- If `data_format` is `\"channels_last\"`:\n    `(batch_size, upsampled_rows, upsampled_cols, channels)`\n- If `data_format` is `\"channels_first\"`:\n    `(batch_size, channels, upsampled_rows, upsampled_cols)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> input_shape = (2, 2, 1, 3)\n>>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n>>> print(x)\n[[[[ 0  1  2]]\n  [[ 3  4  5]]]\n [[[ 6  7  8]]\n  [[ 9 10 11]]]]\n>>> y = tf.keras.layers.UpSampling2D(size=(1, 2))(x)\n>>> print(y)\ntf.Tensor(\n  [[[[ 0  1  2]\n     [ 0  1  2]]\n    [[ 3  4  5]\n     [ 3  4  5]]]\n   [[[ 6  7  8]\n     [ 6  7  8]]\n    [[ 9 10 11]\n     [ 9 10 11]]]], shape=(2, 2, 2, 3), dtype=int64)"
      }
    ]
  },
  {
    "name": "UpSampling3D",
    "module": "tensorflow.keras.layers",
    "category": "Layer",
    "description": "Upsampling layer for 3D inputs.\n\nRepeats the 1st, 2nd and 3rd dimensions\nof the data by `size[0]`, `size[1]` and `size[2]` respectively.",
    "attributes": [
      {
        "default": "channels_last",
        "description": "A string,\n    one of `channels_last` (default) or `channels_first`.\n    The ordering of the dimensions in the inputs.\n    `channels_last` corresponds to inputs with shape\n    `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n    while `channels_first` corresponds to inputs with shape\n    `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n    It defaults to the `image_data_format` value found in your\n    Keras config file at `~/.keras/keras.json`.\n    If you never set it, then it will be \"channels_last\".",
        "name": "data_format"
      },
      {
        "description": "Int, or tuple of 3 integers.\n    The upsampling factors for dim1, dim2 and dim3.",
        "name": "size"
      }
    ],
    "inputs": [
      {
        "description": "5D tensor with shape:\n- If `data_format` is `\"channels_last\"`:\n    `(batch_size, dim1, dim2, dim3, channels)`\n- If `data_format` is `\"channels_first\"`:\n    `(batch_size, channels, dim1, dim2, dim3)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "5D tensor with shape:\n- If `data_format` is `\"channels_last\"`:\n    `(batch_size, upsampled_dim1, upsampled_dim2, upsampled_dim3,\n    channels)`\n- If `data_format` is `\"channels_first\"`:\n    `(batch_size, channels, upsampled_dim1, upsampled_dim2,\n    upsampled_dim3)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> input_shape = (2, 1, 2, 1, 3)\n>>> x = tf.constant(1, shape=input_shape)\n>>> y = tf.keras.layers.UpSampling3D(size=2)(x)\n>>> print(y.shape)\n(2, 2, 4, 2, 3)"
      }
    ]
  },
  {
    "name": "ZeroPadding1D",
    "module": "tensorflow.keras.layers",
    "category": "Tensor",
    "description": "Zero-padding layer for 1D input (e.g. temporal sequence).",
    "attributes": [
      {
        "description": "Int, or tuple of int (length 2), or dictionary.\n        - If int:\n        How many zeros to add at the beginning and end of\n        the padding dimension (axis 1).\n        - If tuple of int (length 2):\n        How many zeros to add at the beginning and the end of\n        the padding dimension (`(left_pad, right_pad)`).",
        "name": "padding"
      }
    ],
    "inputs": [
      {
        "description": "3D tensor with shape `(batch_size, axis_to_pad, features)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "3D tensor with shape `(batch_size, padded_axis, features)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> input_shape = (2, 2, 3)\n>>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n>>> print(x)\n[[[ 0  1  2]\n  [ 3  4  5]]\n [[ 6  7  8]\n  [ 9 10 11]]]\n>>> y = tf.keras.layers.ZeroPadding1D(padding=2)(x)\n>>> print(y)\ntf.Tensor(\n  [[[ 0  0  0]\n    [ 0  0  0]\n    [ 0  1  2]\n    [ 3  4  5]\n    [ 0  0  0]\n    [ 0  0  0]]\n   [[ 0  0  0]\n    [ 0  0  0]\n    [ 6  7  8]\n    [ 9 10 11]\n    [ 0  0  0]\n    [ 0  0  0]]], shape=(2, 6, 3), dtype=int64)"
      }
    ]
  },
  {
    "name": "ZeroPadding2D",
    "module": "tensorflow.keras.layers",
    "category": "Tensor",
    "description": "Zero-padding layer for 2D input (e.g. picture).\n\nThis layer can add rows and columns of zeros\nat the top, bottom, left and right side of an image tensor.",
    "attributes": [
      {
        "description": "Int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n    - If int: the same symmetric padding\n      is applied to height and width.\n    - If tuple of 2 ints:\n      interpreted as two different\n      symmetric padding values for height and width:\n      `(symmetric_height_pad, symmetric_width_pad)`.\n    - If tuple of 2 tuples of 2 ints:\n      interpreted as\n      `((top_pad, bottom_pad), (left_pad, right_pad))`",
        "name": "padding"
      },
      {
        "description": "A string,\n    one of `channels_last` (default) or `channels_first`.\n    The ordering of the dimensions in the inputs.\n    `channels_last` corresponds to inputs with shape\n    `(batch_size, height, width, channels)` while `channels_first`\n    corresponds to inputs with shape\n    `(batch_size, channels, height, width)`.\n    It defaults to the `image_data_format` value found in your\n    Keras config file at `~/.keras/keras.json`.\n    If you never set it, then it will be \"channels_last\".",
        "name": "data_format"
      }
    ],
    "inputs": [
      {
        "description": "4D tensor with shape:\n- If `data_format` is `\"channels_last\"`:\n    `(batch_size, rows, cols, channels)`\n- If `data_format` is `\"channels_first\"`:\n    `(batch_size, channels, rows, cols)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "4D tensor with shape:\n- If `data_format` is `\"channels_last\"`:\n    `(batch_size, padded_rows, padded_cols, channels)`\n- If `data_format` is `\"channels_first\"`:\n    `(batch_size, channels, padded_rows, padded_cols)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> input_shape = (1, 1, 2, 2)\n>>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n>>> print(x)\n[[[[0 1]\n   [2 3]]]]\n>>> y = tf.keras.layers.ZeroPadding2D(padding=1)(x)\n>>> print(y)\ntf.Tensor(\n  [[[[0 0]\n     [0 0]\n     [0 0]\n     [0 0]]\n    [[0 0]\n     [0 1]\n     [2 3]\n     [0 0]]\n    [[0 0]\n     [0 0]\n     [0 0]\n     [0 0]]]], shape=(1, 3, 4, 2), dtype=int64)"
      }
    ]
  },
  {
    "name": "ZeroPadding3D",
    "module": "tensorflow.keras.layers",
    "category": "Tensor",
    "description": "Zero-padding layer for 3D data (spatial or spatio-temporal).",
    "attributes": [
      {
        "description": "Int, or tuple of 3 ints, or tuple of 3 tuples of 2 ints.\n    - If int: the same symmetric padding\n      is applied to height and width.\n    - If tuple of 3 ints:\n      interpreted as two different\n      symmetric padding values for height and width:\n      `(symmetric_dim1_pad, symmetric_dim2_pad, symmetric_dim3_pad)`.\n    - If tuple of 3 tuples of 2 ints:\n      interpreted as\n      `((left_dim1_pad, right_dim1_pad), (left_dim2_pad,\n        right_dim2_pad), (left_dim3_pad, right_dim3_pad))`",
        "name": "padding"
      },
      {
        "description": "A string,\n    one of `channels_last` (default) or `channels_first`.\n    The ordering of the dimensions in the inputs.\n    `channels_last` corresponds to inputs with shape\n    `(batch_size, spatial_dim1, spatial_dim2, spatial_dim3, channels)`\n    while `channels_first` corresponds to inputs with shape\n    `(batch_size, channels, spatial_dim1, spatial_dim2, spatial_dim3)`.\n    It defaults to the `image_data_format` value found in your\n    Keras config file at `~/.keras/keras.json`.\n    If you never set it, then it will be \"channels_last\".",
        "name": "data_format"
      }
    ],
    "inputs": [
      {
        "description": "5D tensor with shape:\n- If `data_format` is `\"channels_last\"`:\n    `(batch_size, first_axis_to_pad, second_axis_to_pad,\n    third_axis_to_pad, depth)`\n- If `data_format` is `\"channels_first\"`:\n    `(batch_size, depth, first_axis_to_pad, second_axis_to_pad,\n    third_axis_to_pad)`",
        "name": "input"
      }
    ],
    "outputs": [
      {
        "description": "5D tensor with shape:\n- If `data_format` is `\"channels_last\"`:\n    `(batch_size, first_padded_axis, second_padded_axis,\n    third_axis_to_pad, depth)`\n- If `data_format` is `\"channels_first\"`:\n    `(batch_size, depth, first_padded_axis, second_padded_axis,\n      third_axis_to_pad)`",
        "name": "output"
      }
    ],
    "examples": [
      {
        "code": ">>> input_shape = (1, 1, 2, 2, 3)\n>>> x = np.arange(np.prod(input_shape)).reshape(input_shape)\n>>> y = tf.keras.layers.ZeroPadding3D(padding=2)(x)\n>>> print(y.shape)\n(1, 5, 6, 6, 3)"
      }
    ]
  },
  {
    "name": "Attention",
    "module": "tensorflow.keras.layers",
    "inputs": [
      {
        "name": "query",
        "type": "Tensor[]"
      },
      {
        "name": "value",
        "type": "Tensor[]"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ],
    "description": "Dot-product attention layer, a.k.a. Luong-style attention.\n\nInputs are `query` tensor of shape `[batch_size, Tq, dim]`, `value` tensor\nof shape `[batch_size, Tv, dim]` and `key` tensor of shape\n`[batch_size, Tv, dim]`. The calculation follows the steps:\n\n1. Calculate scores with shape `[batch_size, Tq, Tv]` as a `query`-`key` dot\n   product: `scores = tf.matmul(query, key, transpose_b=True)`.\n2. Use scores to calculate a distribution with shape\n   `[batch_size, Tq, Tv]`: `distribution = tf.nn.softmax(scores)`.\n3. Use `distribution` to create a linear combination of `value` with\n   shape `[batch_size, Tq, dim]`:\n   `return tf.matmul(distribution, value)`.",
    "attributes": [
      {
        "name": "use_scale",
        "description": "If `True`, will create a scalar variable to scale the attention\n    scores."
      },
      {
        "name": "causal",
        "description": "Boolean. Set to `True` for decoder self-attention. Adds a mask\n    such that position `i` cannot attend to positions `j > i`. This prevents\n    the flow of information from the future towards the past.  Defaults to\n    `False`."
      },
      {
        "name": "dropout",
        "description": "Float between 0 and 1. Fraction of the units to drop for the\n    attention scores. Defaults to 0.0."
      },
      {
        "name": "inputs",
        "description": "List of the following tensors:\n    * query: Query `Tensor` of shape `[batch_size, Tq, dim]`.\n    * value: Value `Tensor` of shape `[batch_size, Tv, dim]`.\n    * key: Optional key `Tensor` of shape `[batch_size, Tv, dim]`. If not\n      given, will use `value` for both `key` and `value`, which is the\n      most common case."
      },
      {
        "name": "mask",
        "description": "List of the following tensors:\n    * query_mask: A boolean mask `Tensor` of shape `[batch_size, Tq]`.\n      If given, the output will be zero at the positions where\n      `mask==False`.\n    * value_mask: A boolean mask `Tensor` of shape `[batch_size, Tv]`.\n      If given, will apply the mask such that values at positions where\n      `mask==False` do not contribute to the result."
      },
      {
        "name": "return_attention_scores",
        "description": "bool, it `True`, returns the attention scores\n    (after masking and softmax) as an additional output argument."
      },
      {
        "name": "training",
        "description": "Python boolean indicating whether the layer should behave in\n    training mode (adding dropout) or in inference mode (no dropout)."
      },
      {
        "name": "score_mode",
        "description": "Function to use to compute attention scores, one of\n    `{\"dot\", \"concat\"}`. `\"dot\"` refers to the dot product between the query\n    and key vectors. `\"concat\"` refers to the hyperbolic tangent of the\n    concatenation of the query and key vectors.\n\nCall Args:"
      },
      {
        "name": "use_causal_mask",
        "description": "Boolean. Set to `True` for decoder self-attention. Adds a\n    mask such that position `i` cannot attend to positions `j > i`. This\n    prevents the flow of information from the future towards the past.\n    Defaults to `False`.\n\nOutput:\n\n  Attention outputs of shape `[batch_size, Tq, dim]`.\n  [Optional] Attention scores after masking and softmax with shape\n    `[batch_size, Tq, Tv]`.\n\nThe meaning of `query`, `value` and `key` depend on the application. In the\ncase of text similarity, for example, `query` is the sequence embeddings of\nthe first piece of text and `value` is the sequence embeddings of the second\npiece of text. `key` is usually the same tensor as `value`.\n\nHere is a code example for using `Attention` in a CNN+Attention network:\n\n```python\n# Variable-length int sequences.\nquery_input = tf.keras.Input(shape=(None,), dtype='int32')\nvalue_input = tf.keras.Input(shape=(None,), dtype='int32')\n\n# Embedding lookup.\ntoken_embedding = tf.keras.layers.Embedding(input_dim=1000, output_dim=64)\n# Query embeddings of shape [batch_size, Tq, dimension].\nquery_embeddings = token_embedding(query_input)\n# Value embeddings of shape [batch_size, Tv, dimension].\nvalue_embeddings = token_embedding(value_input)\n\n# CNN layer.\ncnn_layer = tf.keras.layers.Conv1D(\n    filters=100,\n    kernel_size=4,\n    # Use 'same' padding so outputs have the same shape as inputs.\n    padding='same')\n# Query encoding of shape [batch_size, Tq, filters].\nquery_seq_encoding = cnn_layer(query_embeddings)\n# Value encoding of shape [batch_size, Tv, filters].\nvalue_seq_encoding = cnn_layer(value_embeddings)\n\n# Query-value attention of shape [batch_size, Tq, filters].\nquery_value_attention_seq = tf.keras.layers.Attention()(\n    [query_seq_encoding, value_seq_encoding])\n\n# Reduce over the sequence axis to produce encodings of shape\n# [batch_size, filters].\nquery_encoding = tf.keras.layers.GlobalAveragePooling1D()(\n    query_seq_encoding)\nquery_value_attention = tf.keras.layers.GlobalAveragePooling1D()(\n    query_value_attention_seq)\n\n# Concatenate query and document encodings to produce a DNN input layer.\ninput_layer = tf.keras.layers.Concatenate()(\n    [query_encoding, query_value_attention])\n\n# Add DNN layers, and create Model.\n# ...\n```"
      }
    ]
  },
  {
    "name": "nn.relu",
    "category": "Activation",
    "inputs": [
      {
        "name": "input"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ]
  },
  {
    "name": "math.add",
    "inputs": [
      {
        "name": "x",
        "type": "Tensor"
      },
      {
        "name": "y",
        "type": "Tensor"
      }
    ],
    "outputs": [
      {
        "name": "z"
      }
    ]
  },
  {
    "name": "__operators__.add",
    "inputs": [
      {
        "name": "x",
        "type": "Tensor"
      },
      {
        "name": "y",
        "type": "Tensor"
      }
    ],
    "outputs": [
      {
        "name": "z"
      }
    ]
  },
  {
    "name": "linalg.matmul",
    "attributes": [
      {
        "name": "transpose_a",
        "type": "boolean"
      },
      {
        "name": "transpose_b",
        "type": "boolean"
      }
    ],
    "inputs": [
      {
        "name": "a",
        "type": "Tensor"
      },
      {
        "name": "b",
        "type": "Tensor"
      }
    ],
    "outputs": [
      {
        "name": "c",
        "type": "Tensor"
      }
    ]
  },
  {
    "name": "nn.abs",
    "inputs": [
      {
        "name": "input"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ]
  },
  {
    "name": "math.sigmoid",
    "category": "Activation",
    "inputs": [
      {
        "name": "input"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ]
  },
  {
    "name": "reshape",
    "category": "Shape",
    "inputs": [
      {
        "name": "input"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ]
  },
  {
    "name": "concat",
    "category": "Tensor",
    "inputs": [
      {
        "name": "inputs",
        "list": true
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ]
  },
  {
    "name": "compat.v1.transpose",
    "category": "Shape",
    "inputs": [
      {
        "name": "input"
      }
    ],
    "outputs": [
      {
        "name": "output"
      }
    ]
  }
]
